{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765405328,
  "id": "chatcmpl-Xw78kycXW61W4RqJpZYS4P0SVVJpNxLk",
  "model": "",
  "system_fingerprint": "b7089-38e2c1b41",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 0,
    "prompt_n": 864,
    "prompt_ms": 203.575,
    "prompt_per_token_ms": 0.23561921296296295,
    "prompt_per_second": 4244.136067788284,
    "predicted_n": 140,
    "predicted_ms": 832.446,
    "predicted_per_token_ms": 5.946042857142857,
    "predicted_per_second": 168.17907708127615
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 3,
    "stop": true,
    "model": "",
    "tokens_predicted": 140,
    "tokens_evaluated": 864,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-10\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are an expert coder. Ground rules:\n- Follow the user's instructions. \n- DO NOT wrap answers in markdown code blocks, which means no triple backticks like ``` nor single backtick like ` .\n- Do not explain answers, just give me code. \n- Never add comments to the end of a line. \n- Never add comments.\n- Preserve indentation. \n- If rewriting code, preserve unrelated code. \n- Prefer readable code over of comments. \n\n<|end|><|start|>user<|message|>## Recent yanks across all files in the project:\n.. yanked from auto_edit/new_silence/detector_notebook.py:\n# segs = [s for s in analysis.merged if s.start > 6 and s.start < 80]\n\n.. yanked from auto_edit/new_silence/detector_notebook.py:\n# segs = [s for s in analysis.merged if s.start > 0 and s.start < 30]\n\n<|end|><|start|>user<|message|># General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n<|end|><|start|>user<|message|># Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n<|end|><|start|>user<|message|># Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/tests/range-tests.py:0-1\nfrom auto_edit.ranges import FrameRange, ContentRange, SilenceRange\n\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect_tests.py:232-234\ndef test_bounce_with_trailing_rising_edge_too__labels(self):\n        # TODO half of W test\n        pass\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/ranges.py:45-46\ndef __contains__(self, frame):\n        return self.start_frame <= frame < self.end_frame\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/tests/raw-tests.py:0-1\nfrom auto_edit.silences.detect_raw import RawSilencePeriod\n\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect.py:0-19\nfrom io import StringIO\nfrom rich.console import Console\nfrom rich.text import Text\nfrom traitlets.config.configurable import SingletonConfigurable\nfrom auto_edit.tests.test_files import gptoss\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom numpy.typing import NDArray\nfrom pathlib import Path\nfrom typing import Any\nimport cv2\nimport librosa\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport rich\nimport scipy.signal as sps\nimport sounddevice as sd\n\nMonoAudioSamplesArray = NDArray[np.float32]\n\n<|end|><|start|>user<|message|>can I intercept an event for mouse over a plot item?\nHere is code I selected (with carefully preserved indentation) from auto_edit/new_silence/plot_helpers.py:\n    fig.canvas.mpl_connect(\"key_press_event\", on_key)\n    fig.canvas.mpl_connect(\"button_press_event\", on_click)\n    fig.canvas.mpl_connect(\"close_event\", on_close)<|end|><|start|>assistant",
    "has_new_line": true,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 1003,
    "timings": {
      "cache_n": 0,
      "prompt_n": 864,
      "prompt_ms": 203.575,
      "prompt_per_token_ms": 0.23561921296296295,
      "prompt_per_second": 4244.136067788284,
      "predicted_n": 140,
      "predicted_ms": 832.446,
      "predicted_per_token_ms": 5.946042857142857,
      "predicted_per_second": 168.17907708127615
    }
  }
}
