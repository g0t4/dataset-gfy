{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765416689,
  "id": "chatcmpl-CHj52AyGsigyfgNjkaLFSRirTgzDmXFw",
  "model": "gpt-oss:120b",
  "system_fingerprint": "b7089-38e2c1b41",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 1240,
    "prompt_n": 333,
    "prompt_ms": 134.268,
    "prompt_per_token_ms": 0.4032072072072072,
    "prompt_per_second": 2480.114398069533,
    "predicted_n": 550,
    "predicted_ms": 2289.87,
    "predicted_per_token_ms": 4.1634,
    "predicted_per_second": 240.18830763318442
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 3,
    "stop": true,
    "model": "gpt-oss:120b",
    "tokens_predicted": 550,
    "tokens_evaluated": 1573,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-10\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n\n\n<|end|><|start|>user<|message|>Here is context that's automatically provided, that MAY be relevant.\nrepo: dotfiles\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n## Recent yanks across all files in the project:\n.. yanked from .config/nvim/lua/non-plugins/werkspaces/init.lua:\nrequire('non-plugins.werkspaces.werkspace')\n\n\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Lua Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Prefer EmmyLua/LuaLS style annotations\n- Always annotate when type inference would be ambiguous, or for public APIs.\n\nExamples:\n---@param names string[]\n---@param checker fun(name: string): boolean\n---@return table<string, integer>\nfunction process_names(names, checker) end\n\n---@class WindowController\n---@field window hs.axuielement\n---@field title? string\n---@field size { w: number, h: number }\nlocal WindowController = {}\n\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/dotfiles/.config/nvim/lua/plugins/ai/copilot.lua:581-600\n            endpoint = \"http://llama-vim-fim:8012/infill\",\n            -- \\ 'api_key':            '',\n\n            -- defaults:\n            -- \\ 'n_prefix':           256,\n            -- \\ 'n_suffix':           64,\n            -- \\ 'n_predict':          128,\n            -- TODO is it canceling completions, is that why I get nothing?\n            -- \\ 't_max_prompt_ms':    500,\n            -- \\ 't_max_predict_ms':   1000,\n            -- \\ 'auto_fim':           v:true,\n            --\n            -- how much of the end of the current line (after cursor) will be FIM'd (else FIM won't happen)\n            max_line_suffix = 10, -- default = 8 -- FYI 100 way too much!\n            --  FYI part of the issue might be when in smaller windowws and it appers to clobber what comes after your cursor but it's not clobbered...  but you cannot tell if you say tab and do clobber it vs don't\n            --\n            -- \\ 'max_cache_keys':     250,\n            -- \\ 'ring_n_chunks':      16,\n            -- \\ 'ring_chunk_size':    64,\n            -- \\ 'ring_scope':         1024,\n\n\n## ~/repos/github/g0t4/dotfiles/.config/nvim/lua/plugins/ai/copilot.lua:198-217\n            -- llm_load_print_meta: EOG token        = 151663 '<|repo_name|>'\n            -- llm_load_print_meta: EOG token        = 151664 '<|file_sep|>'\n            -- llm_load_print_meta: max token length = 256\n            -- FAST RESPONSES... so if I can fix token params this is gonna be what I want (faster than even CodeGPT used this same model)\n            tokens_to_clear = { \"<|endoftext|>\" },\n            fim = {\n                enabled = true,\n                prefix = \"<|fim_prefix|>\",\n                middle = \"<|fim_middle|>\",\n                suffix = \"<|fim_suffix|>\",\n            },\n            -- context_window = 1024, -- 4096,\n            -- -- tokenizer = {\n            -- --     repository = \"codellama/CodeLlama-13b-hf\",\n            -- -- },\n            -- -- END codellamaj\n            -- FYI I get completions that summarize this file!!! wow.. cool... and it tells me about each plugin... that is at least not noise\n            -- OK AND LOOK IN THE ollama logs... shows request made... and I can see how it filled out the template! GOOD ... now, is this right? it seems to be not doing what I want with code completion...  smth with fim is not quite what it expected... are those wrong?\n\n\n\n\n## ~/repos/github/g0t4/dotfiles/.config/hammerspoon/config/windows.lua:3-6\nfunction()\n    -- leave this as right only, no bounce... only so I can see if I start using right... cuz I bet with bounce I will just use left exclusively since that's all I was using before\n    spoon.WinWin:moveToScreen(\"right\")\nend\n\n## ~/repos/github/g0t4/dotfiles/.config/nvim/lua/plugins/debugging/dap.lua:66-67\n)  -- <F5>?\n            vim.keymap.set('n', '<leader>so', \n\n## ~/repos/github/g0t4/dotfiles/.config/hammerspoon/config/learn/upvalues.lua:58-60\nfunction newfoo()\n            count = count + 1\n        end\n<|end|><|start|>user<|message|>Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\n-- each werkspace can have a .vim dir nested in the root directory (i.e. repo root)\n-- I will load and run whatever customizations from that directory so I can create commands and other specific customizations that only apply to that repo!\n-- and I keep the code for it colocated with the code it is meant to serve!\n-- i.e. I want to act on segments in my auto_edit repo... when I find a list of segments, and I have that in ipython in a terminal window b/c of iron.nvim\n--    then I want to click one and have it play that segment! (for example)\n--    so I'll add a <|fim_middle|>\n<|end|><|start|>assistant",
    "has_new_line": true,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 2122,
    "timings": {
      "cache_n": 1240,
      "prompt_n": 333,
      "prompt_ms": 134.268,
      "prompt_per_token_ms": 0.4032072072072072,
      "prompt_per_second": 2480.114398069533,
      "predicted_n": 550,
      "predicted_ms": 2289.87,
      "predicted_per_token_ms": 4.1634,
      "predicted_per_second": 240.18830763318442
    }
  }
}
