{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765622483,
  "id": "chatcmpl-HprUeKbHnI00tESnCEPiDnPLVrZFauOS",
  "model": "gpt-oss:120b",
  "system_fingerprint": "b7089-38e2c1b41",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 0,
    "prompt_n": 2587,
    "prompt_ms": 432.62,
    "prompt_per_token_ms": 0.16722844994201777,
    "prompt_per_second": 5979.843742776571,
    "predicted_n": 47,
    "predicted_ms": 231.904,
    "predicted_per_token_ms": 4.934127659574468,
    "predicted_per_second": 202.67007037394785
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 3,
    "stop": true,
    "model": "gpt-oss:120b",
    "tokens_predicted": 47,
    "tokens_evaluated": 2587,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-13\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n\n\n<|end|><|start|>user<|message|>Here is context that's automatically provided, that MAY be relevant.\nrepo: private-auto-edit-suggests\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n## Recent yanks across all files in the project:\n.. yanked from auto_edit/new_silence/tests/integration_tests.py:\nVIDEO_FPS\n\n\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/silences/align.py:39-58\n\n\ndef align_silences_to_frame_boundaries_asymmetric_pad_WIP(silences: list[RawSilencePeriod], fps, left_padding_frames=1) -> list[AlignedSilencePeriod]:\n\n    silences = merge_tiny_gaps(silences, fps)\n\n    aligned_silences = []\n    for silence in silences:\n        exact_start_frame = silence.start_seconds * fps\n        exact_end_frame = silence.end_seconds * fps\n        if exact_start_frame > 1:\n            frame_after_start = math.ceil(exact_start_frame)\n        else:\n            rich.print(\"[white bold]FYI! silence starts before first frame, rounding to first frame (zero)[/]\")\n            frame_after_start = 0  # avoid start content sliver due to padding (at start of video!)\n\n        frame_before_end = math.floor(exact_end_frame)  # FYI leaving end sliver case for all_ranges logic b/c it is not as straight forward as start sliver\n\n        print(f\"{silence} seconds // frames {round(exact_start_frame,2)}➜{round(exact_end_frame,2)}\")\n        print(f\"  {left_padding_frames=}\")\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/tests/aligned-tests.py:0-14\nimport subprocess\nimport pytest\nimport os\nimport rich\nfrom pathlib import Path\nfrom types import SimpleNamespace\nfrom auto_edit.silences.align import AlignedSilencePeriod, align_silences_to_frame_boundaries_asymmetric_pad_WIP\nfrom auto_edit.silences.detect_raw import ffmpeg_detect_silence_raw\nfrom auto_edit.tests.test_files import gptoss_fim_video, gptoss_fim_examples\nfrom auto_edit.new_silence.detect import VIDEO_FPS\n\n#   TODO! add unit test of combination behavior\n\n# TODO! setup unit tests of AlignedSilencePeriod too\n\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/tests/aligned-tests.py:77-99\nclass TestAlignedSilencePeriodGeneral:\n\n    def test_constructor(self):\n        aligned = AlignedSilencePeriod(10, 20)\n        assert aligned.start_frames == 10\n        assert aligned.end_frames == 20\n\n    def test_str_and_repr(self):\n        aligned = AlignedSilencePeriod(5, 15)\n        assert str(aligned) == \"AlignedSilence[5➜15)\"\n        assert repr(aligned) == \"AlignedSilence[5➜15)\"\n\n    def test_duration_frames(self):\n        aligned = AlignedSilencePeriod(30, 45)\n        assert aligned.duration_frames() == 15\n\n    def test_zero_length_duration_frames(self):\n        aligned = AlignedSilencePeriod(100, 100)\n        assert aligned.duration_frames() == 0\n\n    def test_negative_duration_frames(self):\n        aligned = AlignedSilencePeriod(50, 40)\n        assert aligned.duration_frames() == -10\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/silences/align.py:41-74\ndef align_silences_to_frame_boundaries_asymmetric_pad_WIP(silences: list[RawSilencePeriod], fps, left_padding_frames=1) -> list[AlignedSilencePeriod]:\n\n    silences = merge_tiny_gaps(silences, fps)\n\n    aligned_silences = []\n    for silence in silences:\n        exact_start_frame = silence.start_seconds * fps\n        exact_end_frame = silence.end_seconds * fps\n        if exact_start_frame > 1:\n            frame_after_start = math.ceil(exact_start_frame)\n        else:\n            rich.print(\"[white bold]FYI! silence starts before first frame, rounding to first frame (zero)[/]\")\n            frame_after_start = 0  # avoid start content sliver due to padding (at start of video!)\n\n        frame_before_end = math.floor(exact_end_frame)  # FYI leaving end sliver case for all_ranges logic b/c it is not as straight forward as start sliver\n\n        print(f\"{silence} seconds // frames {round(exact_start_frame,2)}➜{round(exact_end_frame,2)}\")\n        print(f\"  {left_padding_frames=}\")\n\n        # show gap for debugging only (saves time calculating when > 0.5)\n        start_gap = frame_after_start - exact_start_frame\n        end_gap = exact_end_frame - frame_before_end\n        print(f\"  gaps (frames): start={round(start_gap,2)}, end={round(end_gap,2)}\")\n\n        print(f\"  pre-padding: {frame_after_start}➜{frame_before_end}\")\n        # FYI a bit of testing shows there are cases where end is trimmed too early if I don't have padding to push left inward... but I have to quantify how often padding also casues issues (leaves click from breathing!)...\n        #   also might need to fix silence threshold (relative to clip volume, not absolute?) ... that might be issue too\n        aligned_start_frame = frame_after_start + left_padding_frames if exact_start_frame > 1 else 0  # avoid start sliver\n        aligned_end_frame = frame_before_end\n        aligned = AlignedSilencePeriod(aligned_start_frame, aligned_end_frame)\n        print(f\"  {aligned}\")\n        aligned_silences.append(aligned)\n\n    return aligned_silences\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/tests/aligned-tests.py:53-72\n        # rich.print(f\"{gap=}\")\n        assert gap == pytest.approx(0.000021)\n\n        # WOW in this case it's a blip of 30us (micro seconds)\n        #   IMO best course of action is, if there's a non-silence for < 1 frame, surrounded by two silence ranges... then merge them\n        #   BTW IIRC this is a rare occurence to have the split... more common to just miss a breathing b/c it is all above threshold (or enough is that there's no minimum silence of 0.15s detected)\n\n        aligned = align_silences_to_frame_boundaries_asymmetric_pad_WIP(raw_silences, VIDEO_FPS, left_padding_frames=0)\n        assert len(aligned) == 1\n        # TODO make this work! need to join small gaps\n\n        # raise RuntimeError(\"NOT YET IMPLEMENTED\")\n\n        #\n        # # Example alignment call – replace with actual parameters as needed\n        # aligned = align_silences_to_frame_boundaries_asymmetric_pad_WIP(\n        #     raw_silences, fps=VIDEO_FPS, frame_offset=0\n        # )\n        # assert isinstance(aligned, list)\n        # assert all(hasattr(s, \"start_frames\") and hasattr(s, \"end_frames\") for s in aligned)\n\n<|end|><|start|>user<|message|>Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\nimport subprocess\nimport pytest\nimport os\nimport rich\nfrom pathlib import Path\nfrom types import SimpleNamespace\nfrom auto_edit.silences.align import AlignedSilencePeriod, align_silences_to_frame_boundaries_asymmetric_pad_WIP\n<|fim_middle|>\nfrom auto_edit.silences.detect_raw import ffmpeg_detect_silence_raw\nfrom auto_edit.tests.test_files import gptoss_fim_video, gptoss_fim_examples\n\nclass TestsIntegration:\n\n    def test_detect_split_breathing_into_two_silences(self):\n\n        # TODO port to use new_silence detection\n\n        raw_silences = ffmpeg_detect_silence_raw(\n            gptoss_fim_video.split_breathing,\n            silence_threshold=-28,\n            silence_duration=0.15,\n        )\n        assert len(raw_silences) == 2\n\n        print()  # \\n\n        [rich.print(silence) for silence in raw_silences]\n        # Raw[0.794542➜0.963646)\n        # Raw[0.963667➜1.314271)\n\n        left = raw_silences[0]\n        right = raw_silences[1]\n\n        gap = right.start_seconds - left.end_seconds\n        # rich.print(f\"{gap=}\")\n        assert gap == pytest.approx(0.000021)\n\n        # WOW in this case it's a blip of 30us (micro seconds)\n        #   IMO best course of action is, if there's a non-silence for < 1 frame, surrounded by two silence ranges... then merge them\n        #   BTW IIRC this is a rare occurence to have the split... more common to just miss a breathing b/c it is all above threshold (or enough is that there's no minimum silence of 0.15s detected)\n\n        aligned = align_silences_to_frame_boundaries_asymmetric_pad_WIP(raw_silences, VIDEO_FPS, left_padding_frames=0)\n        assert len(aligned) == 1\n        # TODO make this work! need to join small gaps\n\n        # raise RuntimeError(\"NOT YET IMPLEMENTED\")\n\n        #\n        # # Example alignment call – replace with actual parameters as needed\n        # aligned = align_silences_to_frame_boundaries_asymmetric_pad_WIP(\n        #     raw_silences, fps=VIDEO_FPS, frame_offset=0\n        # )\n        # assert isinstance(aligned, list)\n        # assert all(hasattr(s, \"start_frames\") and hasattr(s, \"end_frames\") for s in aligned)<|end|><|start|>assistant",
    "has_new_line": false,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 2633,
    "timings": {
      "cache_n": 0,
      "prompt_n": 2587,
      "prompt_ms": 432.62,
      "prompt_per_token_ms": 0.16722844994201777,
      "prompt_per_second": 5979.843742776571,
      "predicted_n": 47,
      "predicted_ms": 231.904,
      "predicted_per_token_ms": 4.934127659574468,
      "predicted_per_second": 202.67007037394785
    }
  }
}
