{
  "raw": false,
  "stream": true,
  "model": "gpt-oss:120b",
  "max_tokens": 4096,
  "temperature": 1,
  "options": [],
  "chat_template_kwargs": {
    "reasoning_effort": "low"
  },
  "top_p": 1,
  "messages": [
    {
      "content": "You are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n",
      "role": "developer"
    },
    {
      "content": "Here is context that's automatically provided, that MAY be relevant.\nrepo: private-auto-edit-suggests\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n## Recent yanks across all files in the project:\n.. yanked from auto_edit/new_silence/gaps_tests.py:\n           left_speech=start(-20).flat(882),\n\n.. yanked from auto_edit/new_silence/gaps_tests.py:\nTestLabelingGaps\n\n.. yanked from auto_edit/new_silence/gaps_tests.py:\ntest_double_dip_breath_finds__first_min__and__last_min\n\n.. yanked from auto_edit/new_silence/gaps.py:\ncreate_gap\n\n.. yanked from auto_edit/new_silence/gaps.py:\ncreate_gap\n\n\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/gaps.py:15-34\ndef create_gap(windowed: list[_TempSegmentGroup], analysis: AudioAnalysisResult):\n\n    left_speech = None\n    if windowed[0] and windowed[0].is_speech:\n        left_speech = windowed[0].segments[0]\n        assert len(windowed[0].segments) == 1, \"Expected only one left speech segment\"\n\n    right_speech = None\n    if windowed[2] and windowed[2].is_speech:\n        right_speech = windowed[2].segments[0]\n        assert len(windowed[2].segments) == 1, \"Expected only one right speech segment\"\n\n    gap_window = GapWindow(\n        left_speech=left_speech,\n        gap=NonSpeechGap(segments=windowed[1].segments),\n        right_speech=right_speech,\n    )\n\n    mark_safe_speech_boundaries(gap_window, analysis)\n    return gap_window\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/ranges_tests.py:174-189\ndef test_window_with_no_speech(self):\n        # this is not really that useful...\n        # why would I have a recording with no speaking? and then want to edit it?\n        # certainly I wouldn't need careful silence gap analysis and segmenting...\n        # if anything, I'd want segmenting based on visual changes (visual equivalent of silence splitting)\n        # nonetheless, good edge case to consider (doesn't pressure anything not already covered in other tests)\n\n        win = GapWindow(\n            left_speech=None,\n            gap=NonSpeechGap(segments=[silence_seg(1, 2)]),\n            right_speech=None,\n        )\n        wins = [win]\n        ranges = get_ranges(wins, VIDEO_FPS)\n        assert ranges[0].start_frame == 30\n        assert ranges[0].end_frame == 60\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/ranges_tests.py:44-66\ndef test_one_window(self):\n        win = GapWindow(\n            left_speech=speech_seg(0, 1.5),\n            gap=NonSpeechGap(segments=[silence_seg(1.5, 2.1)]),\n            right_speech=speech_seg(2.1, 3),\n            first_min=SimpleNamespace(seconds_frame_aligned=1.5),\n            last_min=SimpleNamespace(seconds_frame_aligned=2.1),\n        )\n        wins = [win]\n        ranges = get_ranges(wins, VIDEO_FPS)\n\n        # assert len(ranges) == 3\n        assert ranges[0].start_frame == 0\n        assert ranges[0].end_frame == 45\n        assert type(ranges[0]) == ContentRange\n\n        assert ranges[1].start_frame == 45\n        assert ranges[1].end_frame == 63\n        assert type(ranges[1]) == SilenceRange\n\n        assert ranges[2].start_frame == 63\n        assert ranges[2].end_frame == 90\n        assert type(ranges[2]) == ContentRange\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/ranges_tests.py:155-172\ndef test_window_without_right_speech(self):\n        win = GapWindow(\n            left_speech=speech_seg(0, 1),\n            gap=NonSpeechGap(segments=[silence_seg(1, 2)]),\n            right_speech=None,\n            first_min=SimpleNamespace(seconds_frame_aligned=1),\n            last_min=SimpleNamespace(seconds_frame_aligned=2),\n        )\n        wins = [win]\n        ranges = get_ranges(wins, VIDEO_FPS)\n        # speech at the start\n        assert ranges[0].start_frame == 0\n        assert ranges[0].end_frame == 30\n        assert type(ranges[0]) == ContentRange\n        # following silence segment\n        assert ranges[1].start_frame == 30\n        assert ranges[1].end_frame == 60\n        assert type(ranges[1]) == SilenceRange\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/ranges_tests.py:38-57\n\n\nclass TestNewSilenceToRanges:\n\n    # TODO what if only partial gap_window? (i.e. leading silence at start of video, or end, plus then at start you have speech after, or at end speech is only before)\n\n    def test_one_window(self):\n        win = GapWindow(\n            left_speech=speech_seg(0, 1.5),\n            gap=NonSpeechGap(segments=[silence_seg(1.5, 2.1)]),\n            right_speech=speech_seg(2.1, 3),\n            first_min=SimpleNamespace(seconds_frame_aligned=1.5),\n            last_min=SimpleNamespace(seconds_frame_aligned=2.1),\n        )\n        wins = [win]\n        ranges = get_ranges(wins, VIDEO_FPS)\n\n        # assert len(ranges) == 3\n        assert ranges[0].start_frame == 0\n        assert ranges[0].end_frame == 45\n\n",
      "role": "user"
    },
    {
      "content": "Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\n\n    def last(self) -> np.float64:\n        return self.values[-1]\n\n    def up(self, count):\n        deltas = np.arange(1, count + 1, 1)\n        return self.add(deltas)\n\n    def flat(self, count):\n        deltas = np.zeros(count)\n        return self.add(deltas)\n\n    def down(self, count):\n        deltas = -np.arange(1, count + 1, 1)\n        return self.add(deltas)\n\n    def add(self, deltas: NDArray[np.float64]):\n        batch = self.last() + deltas\n\n        if DEBUG or self.debug_me:\n            name_of_calling_function = inspect.stack()[1].function\n            # FYI rich.print here is a convenient way to verify each batch of numbers added to segment, showing min/max values to verify expectations, can be commented out\n            rich.print(f\"{name_of_calling_function}({len(batch)}): {batch}\")\n\n        self.values = np.concatenate([self.values, batch])\n        return self\n\n    def plot(self):\n        # generate a quick and dirty matplotlib plot of the segment values\n        import matplotlib.pyplot as plt\n        plt.figure()\n        plt.plot(self.values, marker=\"o\")\n        plt.title(\"Test Segment Values\")\n        plt.xlabel(\"Frame\")\n        plt.ylabel(\"Amplitude\")\n        plt.grid(True)\n        plt.show()\n        return self\n\ndef start(at: int | float, debug_me=False) -> SegmentBuilderForTesting:\n    if DEBUG or debug_me:\n        rich.print(\"starting at\", at)\n    return SegmentBuilderForTesting(np.array([at], dtype=np.float64), debug_me)\n\ndef win(left_speech: SegmentBuilderForTesting, gap: SegmentBuilderForTesting, right_speech: SegmentBuilderForTesting):\n\n    # rms_db_values = np.concatenate([\n    #     left_speech.values,\n    #     gap.values,\n    #     right_speech.values,\n    # ]).tolist()\n\n    # if isinstance(gap, SegmentBuilderForTesting):\n    #     rms_values = gap.values\n    # else:\n    #     rms_values = np.concatenate(gap, dtype=np.float64).tolist()\n    #     raise RuntimeError(\"I DO NOT THINK THIS IS USED\")\n\n    # FYI fill in more values only as needed...\n    #   honestly this is why I'd prefer to have integration tests for key scenarios than mock all this up\n    analysis = AudioAnalysisResult(\n        audio_samples=[],  # PRN set from segment\n        sample_rate=22050,\n        rms_db=rms_db_values,\n        time_stamps=[],  # PRN\n        thresholds=DEFAULT_THRESHOLDS,\n    )\n\n    # not necessary, but I am calculating end off of sample count and hop_len:\n    start = 1\n    #\n    TESTING_RMS_HOP_LENGTH = 25  # set this so I know the value doesn't change, even if I change it in the actual code this is testing\n    rms_sample_duration_seconds = TESTING_RMS_HOP_LENGTH / analysis.sample_rate\n    num_rms_samples = len(rms_db_values)\n    end = start + num_rms_samples * rms_sample_duration_seconds\n    #\n    only_gap_segment = gap_segment(rms_db_values, start=start, end=end)\n\n    # TODO how about run actual splitter on the rms_values and not mock the output here?\n    #  TODO! call create_gap(windowed[] w/ 3 items, analysis)\n    win = reate_gap(<|fim_middle|>\n    win = GapWindow(\n        left_speech=None, # TODO\n        gap=NonSpeechGap(segments=[only_gap_segment]),\n        right_speech=None, # TODO\n    )\n    return win, analysis\n\ndef compute_speech_boundaries(\n    left_speech: SegmentBuilderForTesting,\n    gap: SegmentBuilderForTesting,\n    right_speech: SegmentBuilderForTesting,\n    up_db=3,\n):\n    window, analysis = win(left_speech, gap, right_speech)\n    mark_safe_speech_boundaries(window, analysis, up_db=up_db)\n    return window\n\nclass TestLabelingGaps:\n\n    def test_segment_builder_with_breathing_curve(self):\n        # FYI if I want to simulate curves better (not just linear)...\n        #   i.e. simulate breathing bounce/curve (rise somewhat quick, level off and stay high a few frames, then drop off )\n        count = 10\n        half = int(count / 2)\n        speaking_taper = -np.arange(0, 5, dtype=np.float64)**2\n        breathing = -(np.arange(-half, half + 1, 1) / 2)**(2) + 6.25  # formula: -(x/2)^2 for x in [-half, half]\n\n        test = start(-10, debug_me=False).add(speaking_taper).add(np.array(breathing))\n        # test.plot() # FYI! plot segment\n        # assert test.values == [-15, -16, -17, -18, -19, -20, \\\n\n        assert test.values == [-10, \\\n                               -10, -11, -14, -19, -26, # speaking taper\n                               -26.0, -23.75, -22.0, -20.75, -20.0, # breathing starts\n                               -19.75, # peak\n                               -20.0, -20.75, -22.0, -23.75, -26.0 # breathing taper\n                               # PRN add speaking rampup:\n                               ]\n\n    def test_segment_builder(self):\n        # FYI \\ plus () is placed to allow for multi line chaining... and comments to explain each part's purpose... the \\ blocks the formatter from messing with this (at all)\n        #  lolz yapf dies if \\ is after wards, on its own line right before closing )\n        items = ( \\\n            start(-20)\n                .down(5) # speech taper\n                .up(3).down(3) # breathing bounce\n                .up(4) # speech rampup\n        )\n\n        assert items.values == [ \\\n            -20,\n            -21, -22, -23, -24, -25, # speech taper\n            -24, -23, -22, # breathing starts\n            -23, -24, -25, # breathing tapers\n            -24, -23, -22, -21 # speech rampup\n        ]\n        # FYI \\ again is for splitting across lines, to stop formatter from putting shit back on one line\n\n    def test_double_dip_breath_finds__first_min__and__last_min(self):\n        # so far all breathing looks like this double dip pattern\n        # and that makes sense given when I edit the waveform, I always see the bounce w/ empty dips on each side\n        # and I always move boundary between clips so its over the dip time... and then mute the breathing gap\n        # so this all checks out intuitively\n        # only real variation is going to be the degree of bounce and how well I can detect the dips (timing wise)\n        #    and then positioning frame rounding over this region (using rms_values if needed to pick a winning frame to round up/down)\n\n        window = compute_speech_boundaries( \\\n           left_speech=start(-20).flat(881),\n           gap= start(-20)\n               .down(25) # speech taper\n               .up(10).down(8) # breathing bounce\n               .up(10), # speech rampup\n           right_speech=start(-20).flat(881),\n        )\n\n        assert window.first_min\n        assert window.first_min.rms == -45\n        assert window.first_min.seconds == pytest.approx(1.0 + 25 / 882)  # 1.0 sec + 25 hops * 1/882 sec/hop ==> seconds of first_min\n        # start == 1.0s\n        # 22050 samples/sec",
      "role": "user"
    }
  ]
}
