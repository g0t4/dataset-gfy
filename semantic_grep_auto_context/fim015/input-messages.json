{
  "chat_template_kwargs": {
    "reasoning_effort": "low"
  },
  "top_p": 1,
  "temperature": 1,
  "stream": true,
  "options": [],
  "messages": [
    {
      "content": "You are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n",
      "role": "developer"
    },
    {
      "content": "Here is context that's automatically provided, that MAY be relevant.\nrepo: private-auto-edit-suggests\n\n## General project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n\n## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n\n## Python Code Preferences\n\nNaming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\nType Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player/clipper.py:5-52\ndef clip_gap_only(\n    message: str,\n    analysis: AudioAnalysisResult,\n    window: GapWindow,\n) -> str | None:\n\n    input_file = analysis.path\n    assert input_file\n    parent = input_file.parent\n\n    output_dir = parent / \"clips\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    start_str = f\"{window.gap.start_seconds():.2f}\".replace(\".\", \"_\")\n    end_str = f\"{window.gap.end_seconds():.2f}\".replace(\".\", \"_\")\n    output_mp4 = output_dir / f\"clip_{start_str}_to_{end_str}.mp4\"\n    output_txt = output_dir / f\"clip_{start_str}_to_{end_str}.txt\"\n\n    command = [\n        \"ffmpeg\",\n        \"-i\",\n        input_file,\n        \"-ss\",\n        str(window.gap.start_seconds()),\n        \"-to\",\n        str(window.gap.end_seconds()),\n        # FYI I am not setting -y unless I find I want that in the future\n        # FYI DO NOT COPY the file ... that can cause havoc for timing offsets .. allow re-encode\n        #    ... yes that might change the audio in some small but noticeable way\n        #       I will handle that if/when it matters\n        #       right now I wanna avoid massive timing mistakes b/c PTS offsets were screwed up in an export\n        str(output_mp4),\n    ]\n\n    result = subprocess.run(\n        command,\n        capture_output=True,\n        text=True,\n    )\n    rich.inspect(result)\n\n    if result.returncode == 0:\n        # TODO dump other helpful bits like a copyable chunk of python code I can plop into an integration test?\n        output_txt.write_text(message)\n        return str(output_mp4)\n\n    if result.returncode != 0:\n        return None\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player/clipper.py:15-34\n    output_dir = parent / \"clips\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    start_str = f\"{window.gap.start_seconds():.2f}\".replace(\".\", \"_\")\n    end_str = f\"{window.gap.end_seconds():.2f}\".replace(\".\", \"_\")\n    output_mp4 = output_dir / f\"clip_{start_str}_to_{end_str}.mp4\"\n    output_txt = output_dir / f\"clip_{start_str}_to_{end_str}.txt\"\n\n    command = [\n        \"ffmpeg\",\n        \"-i\",\n        input_file,\n        \"-ss\",\n        str(window.gap.start_seconds()),\n        \"-to\",\n        str(window.gap.end_seconds()),\n        # FYI I am not setting -y unless I find I want that in the future\n        # FYI DO NOT COPY the file ... that can cause havoc for timing offsets .. allow re-encode\n        #    ... yes that might change the audio in some small but noticeable way\n        #       I will handle that if/when it matters\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player/clipper.py:0-19\nimport rich\nimport subprocess\n\nfrom auto_edit.new_silence.detects.segments import AudioAnalysisResult, GapWindow\n\ndef clip_gap_only(\n    message: str,\n    analysis: AudioAnalysisResult,\n    window: GapWindow,\n) -> str | None:\n\n    input_file = analysis.path\n    assert input_file\n    parent = input_file.parent\n\n    output_dir = parent / \"clips\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    start_str = f\"{window.gap.start_seconds():.2f}\".replace(\".\", \"_\")\n    end_str = f\"{window.gap.end_seconds():.2f}\".replace(\".\", \"_\")\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/plot_helpers.py:0-14\nimport subprocess\nimport rich\nimport sounddevice as sd\nfrom matplotlib.axes import Axes\nfrom matplotlib.backend_bases import MouseEvent\nfrom matplotlib.collections import PathCollection\nfrom matplotlib.figure import Figure\nfrom matplotlib.lines import Line2D\n\nfrom auto_edit.new_silence.detects.humanize import seconds_to_timecode\nfrom auto_edit.new_silence.detects.segments import VIDEO_FPS\n\ndef setup_events(seg_plot: \"SegmentPlotter\", fig: Figure, ax: Axes, on_click):\n\n    \n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/fcpxml/builder.py:0-8\nimport os\nimport rich\nimport xml.dom.minidom\nimport xml.etree.ElementTree as ET\nfrom auto_edit.ranges import ContentRange, SilenceRange\nfrom auto_edit.transcribe import WhisperSegment\nfrom moviepy.editor import VideoFileClip\nfrom pathlib import Path\n\n\n",
      "role": "user"
    },
    {
      "content": "Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\n\n        self.setup_ticks()\n\n        for seg in self.segments:\n            times = np.linspace(seg.start_seconds, seg.end_seconds, len(seg.rms_values))\n            if len(seg.rms_values) == 1:\n                self.ax.scatter(\n                    times,\n                    seg.rms_values,\n                    color=seg.plot_color(),\n                    label=seg.get_plot_message(self.analysis.fps),\n                    s=10,\n                )\n            else:\n                self.ax.plot(\n                    times,\n                    seg.rms_values,\n                    color=seg.plot_color(),\n                    label=seg.get_plot_message(self.analysis.fps),\n                    linewidth=0.5,\n                )\n\n        if self.windows:\n            for win in self.windows:\n                start_seconds = win.start_seconds()\n                end_seconds = win.end_seconds()\n                if start_seconds is None or end_seconds is None:\n                    continue\n                self.ax.axvspan(\n                    start_seconds,\n                    end_seconds,\n                    color=\"orange\",\n                    alpha=0.3,\n                    label=\"Window Gap\" if \"Window Gap\" not in self.ax.get_legend_handles_labels()[1] else None,\n                )\n\n                # * show detected minima inside the window as vertical lines\n                if win.first_min:\n                    self.add_annotation_arrow(win.first_min.seconds, win.first_min.rms)\n                    self.mark_aligned_frame(win.first_min.frame_aligned_at_seconds, win.first_min.rms)\n                    # rms is for _min.seconds, not min.frame_aligned_at_seconds, but, use it for both\n                if win.last_min:\n                    self.add_annotation_arrow(win.last_min.seconds, win.last_min.rms)\n                    self.mark_aligned_frame(win.last_min.frame_aligned_at_seconds, win.last_min.rms)\n\n        self.ax.set_xlabel(\"Time (s)\")\n        self.ax.set_ylabel(\"RMS dB\")\n        self.ax.set_title(f\"RMS Segments {self.analysis.title_addon()}\")\n\n    def get_window_at(self, seconds) -> GapWindow | None:\n        for window in self.windows:\n            if window.start_seconds() <= seconds <= window.end_seconds():\n                return window\n\n    def _on_click(self, event) -> None:\n        if event.inaxes != self.ax:\n            return\n\n        clicked_at_seconds = event.xdata\n        if is_shift(event):\n            # * play GapWindow (under cursor)\n            window = self.get_window_at(clicked_at_seconds)\n            if not window:\n                return\n\n            if window.gap.start_seconds() <= clicked_at_seconds <= window.gap.end_seconds():\n                # play gap (silence)\n                self._play_segment(window.gap.start_seconds(), window.gap.end_seconds())\n            else:\n                # play full window\n                self._play_segment(window.start_seconds(), window.end_seconds())\n\n        elif is_alt(event):\n            rich.inspect(event)\n            window = self.get_window_at(clicked_at_seconds)\n            if not window:\n                return\n            explain = applescript_prompt(f\"Enter description for the selected silence/gap at {clicked_at_seconds:.2f}s\")\n            if explain is None:\n                print(\"no explanation, canceling\")\n                return\n            # save mp4 clip\n            <|fim_middle|>\n\n        else:\n            # * play a single segment (under cursor)\n            for seg in self.segments:\n                if seg.start_seconds <= clicked_at_seconds <= seg.end_seconds:\n                    self._play_segment(seg.start_seconds, seg.end_seconds)\n\n    def _connect_events(self) -> None:\n        setup_events(self, self.fig, self.ax, self._on_click, self.analysis.fps)\n\n    def show(self) -> None:\n        self.fig.tight_layout(pad=0.5)  # thin margins around the axes (plot)... less wasted whitespace margins!\n        plt.ion()  # else won't show new plots after initial call to plt.show()\n        plt.show()\n\n    def add_segments(self, new_segments: list[DetectedSegment]) -> None:\n        self.segments.extend(new_segments)\n        for seg in new_segments:\n            times = np.linspace(seg.start_seconds, seg.end_seconds, len(seg.rms_values))\n            self.ax.plot(\n                times,\n                seg.rms_values,\n                color=seg.plot_color(),\n                linewidth=0.5,\n            )\n        # self.fig.canvas.draw()\n        # self.fig.canvas.flush_events()\n\n    def mark_aligned_frame(self, time_point: float, arrow_y: float) -> None:\n\n        # * vertical line (hopefully cross through the RMS plot... but not guarnateed right now)\n        line_height = 6\n        lines = self.ax.plot(\n            [time_point, time_point],\n            [arrow_y, arrow_y + line_height],\n            color=\"blue\",\n            linewidth=1,\n        )\n\n        frames = time_point * self.analysis.fps\n        frames_text = f\"{int(frames)}f\"\n\n        # * time label\n        label = f\"{time_point:.2f}s\\n{frames_text}\"\n        text = self.ax.text(\n            time_point,\n            arrow_y + line_height + 2,\n            label,\n            ha=\"center\",\n            va=\"bottom\",\n            color=\"blue\",\n        )\n\n        self.aligned_markers.append(AlignedMarker(lines, text=text))\n\n        self.fig.canvas.draw_idle()\n\n    def add_annotation_arrow(self, time_point: float, arrow_y: float) -> None:\n\n        self.ax = plt.gca()\n\n        annotation = self.ax.annotate(\n            \"\",\n            xy=(time_point, arrow_y),\n            xytext=(time_point, arrow_y - 6),\n            ha=\"center\",\n            va=\"bottom\",\n            color=\"red\",\n            arrowprops=dict(\n                arrowstyle=\"->\",\n                color=\"red\",\n                linewidth=1.5,\n            ),\n        )\n        self.arrows.append(annotation)\n\n        self.fig.canvas.draw_idle()",
      "role": "user"
    }
  ],
  "max_tokens": 4096,
  "model": "gpt-oss:120b",
  "raw": false
}
