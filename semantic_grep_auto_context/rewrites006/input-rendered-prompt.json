{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1766935550,
  "id": "chatcmpl-bxuGDQfgtCURNWDnojAjyUB5QMycubLO",
  "model": "ggml-org/gpt-oss-120b-GGUF",
  "system_fingerprint": "b7453-8faa87db0",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 215,
    "prompt_n": 753,
    "prompt_ms": 154.402,
    "prompt_per_token_ms": 0.20504913678618855,
    "prompt_per_second": 4876.879833162783,
    "predicted_n": 189,
    "predicted_ms": 816.192,
    "predicted_per_token_ms": 4.318476190476191,
    "predicted_per_second": 231.5631616090332
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 3,
    "stop": true,
    "model": "ggml-org/gpt-oss-120b-GGUF",
    "tokens_predicted": 189,
    "tokens_evaluated": 968,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-28\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are an expert coder. Ground rules:\n- Follow the user's instructions. \n- DO NOT wrap answers in markdown code blocks, which means no triple backticks like ``` nor single backtick like ` .\n- Do not explain answers, just give me code. \n- Never add comments to the end of a line. \n- Never add comments.\n- Preserve indentation. \n- If rewriting code, preserve unrelated code. \n- Prefer readable code over of comments. \n\n<|end|><|start|>user<|message|>## Recent yanks across all files in the project:\n.. yanked from .config.fish:\n--capture=no --log-cli-level=INFO\n\n.. yanked from .config.fish:\n  --capture=no --log-cli-level=INFO\n\n.. yanked from .config.fish:\nfunction ptw_path --argument path\n    set common \"--capture=no --log-cli-level=INFO\"\n    ptw --clear -- $path $common\nend\n\n\n.. yanked from .config.fish:\nfunction ptw_path --argument path\n    set common \"--capture=no --log-cli-level=INFO\"\n    ptw --clear -- $path $common\nend\n\n<|end|><|start|>user<|message|>## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n<|end|><|start|>user<|message|># Semantic Grep matches: 3\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/run-ptw-one-test-example.fish:0-6\n#!/usr/bin/env fish\n\n# pass pytest args after --\n#   make sure the args work with pytest directly\n#   pytest ____\n\nptw --  auto_edit/tests/aligned-tests.py::TestIntegration::test_detect_split_breathing_into_two_silences --capture=no --log-cli-level=INFO\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/run-all-tests.fish:0-4\n#!/usr/bin/env fish\n\n# use --capture=no to see print() output\n# use --log-cli-level=___ to set pytest's root logger level\nptw auto_edit/**/*.py -- --capture=no --log-cli-level=INFO\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/research/gen_video_frame_numbers.fish:0-10\n#!/usr/bin/env fish\n\nset frame_count 500\nset fps 25\nset duration (math $frame_count / $fps)\n\nffmpeg -f lavfi -i \"color=c=black:s=1920x1080:d=$duration\" \\\n    -vf \"drawtext=fontfile=/path/to/font.ttf:fontsize=72:fontcolor=white:x=(w-text_w)/2:y=(h-text_h)/2:text='%{n}':rate=$fps\" \\\n    -frames:v $frame_count -r $fps \\\n    numbered-$frame_count-fps$fps.mp4\n# compliments gpt-4o\n\n<|end|><|start|>user<|message|>use new ptw_path \nHere is code I selected (with carefully preserved indentation) from .config.fish:\nabbr ptw_ranges \"ptw --clear  -- auto_edit/new_silence/ranges_tests.py $common\"\nabbr ptw_gaps \"ptw --clear  -- auto_edit/new_silence/gaps_tests.py $common\"\nabbr ptw_detect \"ptw --clear  -- auto_edit/new_silence/detect_tests.py $common\"\nabbr ptw_humanize \"ptw --clear  -- auto_edit/new_silence/detects/humanize_tests.py $common\"\nabbr ptw_all_new \"ptw --clear  -- auto_edit/new_silence/**/*_tests.py $common\"\n\n# * integration (slow, to video files) tests\nabbr ptw_integration \"ptw --clear -- auto_edit/new_silence/tests/integration_tests.py $common\"\nabbr ptw_integration_one \"ptw --clear -- auto_edit/new_silence/tests/integration_tests.py::TestsIntegration::test_detect_split_breathing_into_two_silences $common\"<|end|><|start|>assistant",
    "has_new_line": true,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 1156,
    "timings": {
      "cache_n": 215,
      "prompt_n": 753,
      "prompt_ms": 154.402,
      "prompt_per_token_ms": 0.20504913678618855,
      "prompt_per_second": 4876.879833162783,
      "predicted_n": 189,
      "predicted_ms": 816.192,
      "predicted_per_token_ms": 4.318476190476191,
      "predicted_per_second": 231.5631616090332
    }
  }
}
