{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1766934688,
  "id": "chatcmpl-hiQ4ECbJwcTVwmb5QkDhQacX1OLtZIVu",
  "model": "ggml-org/gpt-oss-120b-GGUF",
  "system_fingerprint": "b7453-8faa87db0",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 0,
    "prompt_n": 1423,
    "prompt_ms": 220.716,
    "prompt_per_token_ms": 0.15510611384399156,
    "prompt_per_second": 6447.199115605575,
    "predicted_n": 122,
    "predicted_ms": 611.28,
    "predicted_per_token_ms": 5.010491803278688,
    "predicted_per_second": 199.58120664834448
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 3,
    "stop": true,
    "model": "ggml-org/gpt-oss-120b-GGUF",
    "tokens_predicted": 122,
    "tokens_evaluated": 1423,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-28\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are an expert coder. Ground rules:\n- Follow the user's instructions. \n- DO NOT wrap answers in markdown code blocks, which means no triple backticks like ``` nor single backtick like ` .\n- Do not explain answers, just give me code. \n- Never add comments to the end of a line. \n- Never add comments.\n- Preserve indentation. \n- If rewriting code, preserve unrelated code. \n- Prefer readable code over of comments. \n\n<|end|><|start|>user<|message|>## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n<|end|><|start|>user<|message|>## Python Code Preferences\n\nNaming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\nType Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n<|end|><|start|>user<|message|># Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/tests/aligned-tests.py:37-56\n            silence_threshold=-28,\n            silence_duration=0.15,\n        )\n        assert len(raw_silences) == 2\n\n        import rich\n        print()  # \\n\n        [rich.print(silence) for silence in raw_silences]\n        # Raw[0.794542➜0.963646)\n        # Raw[0.963667➜1.314271)\n\n        left = raw_silences[0]\n        right = raw_silences[1]\n\n        gap = right.start_seconds - left.end_seconds\n        # rich.print(f\"{gap=}\")\n        assert gap == pytest.approx(0.000021)\n\n        # WOW in this case it's a blip of 30us (micro seconds)\n        #   IMO best course of action is, if there's a non-silence for < 1 frame, surrounded by two silence ranges... then merge them\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/timer.py:21-40\n@contextmanager\ndef DurationPrinter(section: str, only_if_slow_ms: Optional[int] = None) -> None:\n\n    start_time: float = time.time()\n    try:\n        yield\n    finally:\n        end_time: float = time.time()\n        elapsed_seconds = end_time - start_time\n        elapsed_ms = elapsed_seconds * 1000\n\n        always_log = only_if_slow_ms is None\n        if always_log or elapsed_ms > only_if_slow_ms:\n\n            if elapsed_seconds < 1.0:\n                formatted_time = f\"{elapsed_ms:.2f}ms\"\n            else:\n                formatted_time = f\"{elapsed_seconds:.3f}s\"\n\n            rich.print(f\"Completed {section=} in [bold cyan]{formatted_time}[/]\")\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/segments.py:141-167\n@dataclass\nclass GapWindow:\n    left_speech: DetectedSegment | None\n    gap: NonSpeechGap\n    right_speech: DetectedSegment | None\n\n    first_min: MinMeasures | None = None\n    last_min: MinMeasures | None = None\n\n    def all_segments(self) -> list[DetectedSegment]:\n        segments: list[DetectedSegment] = []\n        if self.left_speech:\n            segments.append(self.left_speech)\n        segments.extend(self.gap.segments)\n        if self.right_speech:\n            segments.append(self.right_speech)\n        return segments\n\n    def start_seconds(self) -> float:\n        if self.left_speech:\n            return self.left_speech.start_seconds\n        return self.gap.segments[0].start_seconds\n\n    def end_seconds(self) -> float:\n        if self.right_speech:\n            return self.right_speech.end_seconds\n        return self.gap.segments[-1].end_seconds\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/test_humanize.py:0-19\nimport pytest\n\nfrom auto_edit.new_silence.detects.humanize import seconds_to_timecode\n\n@pytest.mark.parametrize(\n    \"seconds, fps, expected\",\n    [\n        # Simple seconds without minutes, no fractional frames\n        (5, 30, \"05:00\"),\n        #\n        # fractional seconds of 0.5 => maps to exact frame count of 15\n        (5.5, 30, \"05:15\"),\n        #\n        # fraction of frame shows as decimal\n        (5.61, 30, \"05:18.30\"),\n        #\n        # Minutes present\n        (125, 24, \"02:05:00\"),\n        #\n        # Minutes with frames (due to fraction of a second)\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/segments.py:108-129\n@dataclass\nclass NonSpeechGap:\n    segments: list[DetectedSegment]\n\n    def __len__(self) -> int:\n        return len(self.segments)\n\n    def __iter__(self):\n        return iter(self.segments)\n\n    def start_seconds(self) -> float:\n        return self.segments[0].start_seconds\n\n    def end_seconds(self) -> float:\n        return self.segments[-1].end_seconds\n\n    def duration_seconds(self) -> float:\n        return self.end_seconds() - self.start_seconds()\n\n    def __repr__(self) -> str:\n        segs = \", \".join(str(s.id) for s in self.segments)\n        return f\"NonSpeechGap(segments=[{segs}])\"\n<|end|><|start|>user<|message|>use my humanize.py module to show seconds nicely\nHere is code I selected (with carefully preserved indentation) from auto_edit/new_silence/detects/breathing.py:\n        rich.print(f\"gap: {win.gap.start_seconds()}=>{win.gap.end_seconds()}\")<|end|><|start|>assistant",
    "has_new_line": true,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 1544,
    "timings": {
      "cache_n": 0,
      "prompt_n": 1423,
      "prompt_ms": 220.716,
      "prompt_per_token_ms": 0.15510611384399156,
      "prompt_per_second": 6447.199115605575,
      "predicted_n": 122,
      "predicted_ms": 611.28,
      "predicted_per_token_ms": 5.010491803278688,
      "predicted_per_second": 199.58120664834448
    }
  }
}
