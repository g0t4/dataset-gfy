{
  "chat_template_kwargs": {
    "reasoning_effort": "low"
  },
  "stream": true,
  "max_tokens": 4096,
  "options": [],
  "raw": false,
  "model": "gpt-oss:120b",
  "top_p": 1,
  "temperature": 1,
  "messages": [
    {
      "content": "You are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n",
      "role": "developer"
    },
    {
      "content": "Here is context that's automatically provided, that MAY be relevant.\nrepo: private-auto-edit-suggests\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n",
      "role": "user"
    },
    {
      "content": "Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\n\n<|fim_middle|>\nclass Standalone:\n\n    @staticmethod\n    def play_to_frame(analysis: AudioAnalysisResult, segment: DetectedSegment) -> None:\n        # FYI this is currently unused... could be part of gap analysis... get rid of this if you dont need it\n\n        def play_samples(analysis: AudioAnalysisResult, start_sample, end_sample):\n            samples = analysis.audio.samples[start_sample:end_sample]\n\n            print(f\"playing samples={start_sample}-{end_sample}\")\n            sd.play(samples, analysis.sample_rate)\n            sd.wait()\n\n        def play_frames(analysis: AudioAnalysisResult, start_frame, end_frame):\n            start_sample = int(start_frame / analysis.fps * analysis.sample_rate)\n            end_sample = int(end_frame / analysis.fps * analysis.sample_rate)\n            play_samples(analysis, start_sample, end_sample)\n\n        print(f'{segment=}')\n        start_seconds = segment.start_seconds\n        end_seconds = segment.end_seconds\n\n        # * play literal audio samples without any frame rounding\n\n        start_sample = int(start_seconds * analysis.sample_rate)\n        end_sample = int(end_seconds * analysis.sample_rate)\n        play_samples(analysis, start_sample, end_sample)\n        time.sleep(1)\n\n        start_frame = start_seconds * analysis.fps\n        start_frame_before = math.floor(start_frame)\n        start_frame_after = math.ceil(start_frame)\n        rich.print(f\"{start_frame_before=}, {start_frame=}, {start_frame_after=}\")\n\n        end_frame = end_seconds * analysis.fps\n        end_frame_before = math.floor(end_frame)\n        end_frame_after = math.ceil(end_frame)\n        rich.print(f\"{end_frame_before=}, {end_frame=}, {end_frame_after=}\")\n\n        # does start frame matter? before/after => BOTH SOUND GREAT\n        print(\"start BEFORE\")\n        play_frames(analysis, start_frame_before, end_frame)\n        time.sleep(0.5)\n        print(\"start AFTER\")\n        play_frames(analysis, start_frame_after, end_frame)\n        time.sleep(0.5)\n\n        # what about end frame? before/after?\n        print(\"end BEFORE\")\n        play_frames(analysis, start_frame, end_frame_before)\n        time.sleep(0.5)\n\n        print(\"end AFTER\")\n        play_frames(analysis, start_frame, end_frame_after)\n        time.sleep(0.5)\n\ndef play_segments(analysis: AudioAnalysisResult, segments: list[DetectedSegment]) -> None:\n    combined = []\n    for segment in segments:\n        start = int(segment.start_seconds * analysis.sample_rate)\n        end = int(segment.end_seconds * analysis.sample_rate)\n        combined.append(analysis.audio.samples[start:end])\n    if combined:\n        audio = np.concatenate(combined)\n        sd.play(audio, analysis.sample_rate)\n        sd.wait()\n\ndef mute_and_play_segments(analysis: AudioAnalysisResult, segments: list[DetectedSegment]) -> None:\n    combined = []\n    for segment in segments:\n        start = int(segment.start_seconds * analysis.sample_rate)\n        end = int(segment.end_seconds * analysis.sample_rate)\n        if segment.label in (SegmentLabel.SILENCE, SegmentLabel.BREATH):\n            # combined.append(analysis.audio.samples[start:end])\n            # continue\n            last_sample = combined[-1][-1] if combined else 0\n            # cannot drop to zero... must fade down?! wtf?\n            # mute_slice = [-40 for r in segment.rms_values]\n            mute_slice = [last_sample for r in segment.rms_values]\n            print(mute_slice)\n            # return\n            # mute_slice = np.full(end - start, -70.0, dtype=analysis.audio.samples.dtype)\n            combined.append(mute_slice)\n        else:\n            combined.append(analysis.audio.samples[start:end])\n    if combined:\n        audio = np.concatenate(combined)\n        print(f'{len(audio)=}')\n        sd.play(audio, analysis.sample_rate)\n        sd.wait()",
      "role": "user"
    }
  ]
}
