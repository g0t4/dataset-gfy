{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1766450654,
  "id": "chatcmpl-P8JitlzORR3cbVPkLhVmfs7xNWWYQgER",
  "model": "ggml-org/gpt-oss-120b-GGUF",
  "system_fingerprint": "b7453-8faa87db0",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 574,
    "prompt_n": 2861,
    "prompt_ms": 734.894,
    "prompt_per_token_ms": 0.25686613072352327,
    "prompt_per_second": 3893.0784575734733,
    "predicted_n": 82,
    "predicted_ms": 510.379,
    "predicted_per_token_ms": 6.224134146341464,
    "predicted_per_second": 160.66491763963643
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 2,
    "stop": true,
    "model": "ggml-org/gpt-oss-120b-GGUF",
    "tokens_predicted": 82,
    "tokens_evaluated": 3435,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-22\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n\n\n<|end|><|start|>user<|message|>Here is context that's automatically provided, that MAY be relevant.\nrepo: ask-openai.nvim\n\n## General project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n\n## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n\n## Lua Code Preferences\n\nNaming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\nType Hints\n- Prefer EmmyLua/LuaLS style annotations\n- Always annotate when type inference would be ambiguous, or for public APIs.\n\nExamples:\n---@param names string[]\n---@param checker fun(name: string): boolean\n---@return table<string, integer>\nfunction process_names(names, checker) end\n\n---@class WindowController\n---@field window hs.axuielement\n---@field title? string\n---@field size { w: number, h: number }\nlocal WindowController = {}\n\n\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/predictions/context/matching_ctags.tests.lua:0-6\nrequire('ask-openai.helpers.testing')\nlocal ctags = require(\"ask-openai.predictions.context.ctags\")\nlocal matching_ctags = require(\"ask-openai.predictions.context.matching_ctags\")\nlocal should = require(\"devtools.tests.should\")\n\ndescribe(\"matching_ctags\", function()\n    it(\"requires\", \n\n## ~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/predictions/context/matching_ctags.tests.lua:5-52\nfunction()\n    it(\"requires\", function()\n        local maps_to = matching_ctags._require_for_file_path(\"lua/foo/bar.lua\")\n        should.be_equal(maps_to, \"require('foo.bar')\")\n    end)\n\n    it(\"get_context_item()\", function()\n        local item = matching_ctags.get_context_item_for(\"get_context_items\", \"lua\")\n        -- vim.print(item.content)\n\n        local hardcoded = [[\nlua/ask-openai/prediction/context/git_diff.lua\n    function M.get_context_items()\nlua/ask-openai/prediction/context/yanks.lua\n    function M.get_context_item()\nlua/ask-openai/prediction/context/matching_ctags.lua\n    function M.get_context_item()\n    function M.get_context_item_for(word, language)\nlua/ask-openai/prediction/context/project.lua\n    function M.get_context_items()\n]]\n\n        -- COOL!... now hopefully this helps suggest to use the requires!\n        local hard_git_diff_with_require = [[\nrequire('ask-openai.predictions.context.git_diff')\n    function M.get_context_items()]]\n        -- FYI end of [[]] needs to not have extra newlines / chars\n        assert.is.not_nil(string.find(item.content, hard_git_diff_with_require, 1, true))\n\n        local hard_git_diff = [[\nlua/ask-openai/prediction/context/git_diff.lua\n    function M.get_context_items()]]\n        -- assert.is.not_nil(string.find(item.content, hard_git_diff, 1, true))\n    end)\n\n    -- FYI ALTERNATIVES for REQUIRES:\n    -- separtely distill all requires into a list (not filtered)\n    it(\"matches on file_name too\", function()\n        local item = matching_ctags.get_context_item_for(\"messages\", \"lua\")\n        -- vim.print(item.content)\n\n        local hard_git_diff_with_require = [[\nrequire('devtools.messages')]]\n        -- FYI end of [[]] needs to not have extra newlines / chars\n\n        assert.is.not_nil(string.find(item.content, hard_git_diff_with_require, 1, true))\n    end)\nend\n\n## ~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/predictions/context/matching_ctags.tests.lua:6-9\nfunction()\n        local maps_to = matching_ctags._require_for_file_path(\"lua/foo/bar.lua\")\n        should.be_equal(maps_to, \"require('foo.bar')\")\n    end\n\n## ~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/predictions/context/matching_ctags.tests.lua:42-51\nfunction()\n        local item = matching_ctags.get_context_item_for(\"messages\", \"lua\")\n        -- vim.print(item.content)\n\n        local hard_git_diff_with_require = [[\nrequire('devtools.messages')]]\n        -- FYI end of [[]] needs to not have extra newlines / chars\n\n        assert.is.not_nil(string.find(item.content, hard_git_diff_with_require, 1, true))\n    end\n\n## ~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/predictions/context/matching_ctags.tests.lua:11-38\nfunction()\n        local item = matching_ctags.get_context_item_for(\"get_context_items\", \"lua\")\n        -- vim.print(item.content)\n\n        local hardcoded = [[\nlua/ask-openai/prediction/context/git_diff.lua\n    function M.get_context_items()\nlua/ask-openai/prediction/context/yanks.lua\n    function M.get_context_item()\nlua/ask-openai/prediction/context/matching_ctags.lua\n    function M.get_context_item()\n    function M.get_context_item_for(word, language)\nlua/ask-openai/prediction/context/project.lua\n    function M.get_context_items()\n]]\n\n        -- COOL!... now hopefully this helps suggest to use the requires!\n        local hard_git_diff_with_require = [[\nrequire('ask-openai.predictions.context.git_diff')\n    function M.get_context_items()]]\n        -- FYI end of [[]] needs to not have extra newlines / chars\n        assert.is.not_nil(string.find(item.content, hard_git_diff_with_require, 1, true))\n\n        local hard_git_diff = [[\nlua/ask-openai/prediction/context/git_diff.lua\n    function M.get_context_items()]]\n        -- assert.is.not_nil(string.find(item.content, hard_git_diff, 1, true))\n    end\n<|end|><|start|>user<|message|>Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\nrequire('ask-openai.helpers.testing')\nlocal ctags = require(\"ask-openai.predictions.context.ctags\")\nlocal should = require(\"devtools.tests.should\")\n<|fim_middle|>\n\ndescribe(\"integration test tags file\", function()\n    it(\"find_tag_file PLACEHOLDER\", function()\n        -- TODO placeholder for when I need something more sophisticated than just \"tags\"\n        local file = ctags.find_tags_file_for_this_workspace()\n        should.be_equal(\"tags\", file)\n    end)\n\n    it(\"get_tag_lines\", function()\n        local lines = files.read_file_lines(\"tags\")\n        local num_tags = #lines -- use for expect which only handles showing primitives (not tables nor operations)\n        print(\"original tag count: \" .. tostring(num_tags))\n        expect(num_tags > 0)\n\n        local filtered = ctags.parse_tag_lines(lines, \"lua\")\n        print(\"filtered count: \" .. tostring(#filtered))\n        expect(#filtered > 0)\n\n        -- dump reassembled to file to inspect manually\n        local reassembled = ctags.reassemble_tags(filtered)\n        local filename = \"tmp/reassembled_tags.txt\"\n        local handle = io.open(filename, \"w\")\n        handle:write(reassembled)\n        handle:close()\n    end)\nend)\n\ndescribe(\"u-ctags format\", function()\n    -- right now assuming u-ctags format, could add more in future\n    -- https://docs.ctags.io/en/latest/man/tags.5.html#tags-5\n\n    describe(\"parse_ctags\", function()\n        it(\"splits on \\t\", function()\n            local lines = {\n                \"on_delete\tlua/devtools/diff/weslcs.lua\t/^    function builder:on_delete(_token)$/;\\\"\tf\tunknown:builder\",\n                \"on_delete\tlua/devtools/diff/weslcs.lua\t/^    function builder:on_delete(token)$/;\\\"\tf\tunknown:builder}\",\n                \"sort\tlua/devtools/super_iter.lua\t/^    iter.sort = function(self, cmp_fn)$/;\\\"\tf\tunknown:iter\",\n                \"sorted\tlua/devtools/super_iter.tests.lua\t/^        local sorted = super_iter(unsorted):sort(function(a, b) return a > b end):totable()$/;\\\"\tf\",\n            }\n            local tags = ctags.parse_tag_lines(lines, \"lua\")\n            local second = tags[2]\n\n            -- https://docs.ctags.io/en/latest/man/ctags.1.html\n            -- u-ctags format\n            -- <tag_name><TAB><file_name><TAB><ex_cmd>;\"<TAB><extension_fields>\n\n            local expected = {\n                tag_name = \"on_delete\",\n                file_name = \"lua/devtools/diff/weslcs.lua\",\n                -- make sure to strip delimiter ;\" at the end of the ex_command\n                ex_command = \"/^    function builder:on_delete(token)$/\",\n                -- FOR NOW I am not gonna use extras... so skip it\n            }\n            should.be_same(expected, second)\n        end)\n\n\n        -- LUA specific:\n        --  drop local functions/vars/etc (only those in the current file, in the PSM already... will matter)\n        --     /^local function simulate_rewrite_instant_one_chunk(opts)$/;\"\n        --     /^            local tool_header = \"**\" .. (call[\"function\"].name or \"\") .. \"**\"$/;\"\n        --\n        describe(\"filter tag lines\", function()\n            it(\"removes local symbols\", function()\n                local lines = {\n                    -- strip these:\n                    \"split_lines_to_table\tlua/ask-openai/prediction/prediction.lua\t/^local function split_lines_to_table(text)$/;\\\"\tf\",\n                    \"tool_header\tlua/ask-openai/questions/ask.lua\t/^            local tool_header = \\\"**\\\" .. (call[\\\"function\\\"].name or \\\"\\\") .. \\\"**\\\"$/;\\\"\tf\",\n                    -- keep lines:\n                    \"on_delete\tlua/devtools/diff/weslcs.lua\t/^    function builder:on_delete(_token)$/;\\\"\tf\tunknown:builder\",\n                }\n                local tags = ctags.parse_tag_lines(lines, \"lua\")\n                expect(#tags == 1)\n                local only = tags[1]\n                -- FYI this is not a test of parsing, so only verify the one item looks approx right\n                should.be_same(only.tag_name, \"on_delete\")\n            end)\n\n            it(\"excludes pseudo tags / metadata lines (starts with !) and comments\", function()\n                local lines = {\n                    \"#_TAG_EXTRA_DESCRIPTION\",\n                    \"function1\tlua/ask-openai/prediction/prediction.lua\t/^function split_lines_to_table(text)$/;\\\"\tf\",\n                    \"!_TAG_FIELD_DESCRIPTION\",\n                    \"function2\tlua/ask-openai/prediction/prediction.lua\t/^function split_lines_to_table(text)$/;\\\"\tf\",\n                }\n                local tags = ctags.parse_tag_lines(lines, \"lua\")\n                expect(#tags == 2)\n                local first = tags[1]\n                local second = tags[2]\n                should.be_same(first.tag_name, \"function1\")\n                should.be_same(second.tag_name, \"function2\")\n            end)\n\n            it(\"excludes files with .tests. in name\", function()\n                local lines = {\n                    \"sort\tlua/devtools/super_iter.lua\t/^    iter.sort = function(self, cmp_fn)$/;\\\"\tf\tunknown:iter\",\n                    \"sorted\tlua/devtools/super_iter.tests.lua\t/^        local sorted = super_iter(unsorted):sort(function(a, b) return a > b end):totable()$/;\\\"\tf\",\n                }\n                local tags = ctags.parse_tag_lines(lines, \"lua\")\n                expect(#tags == 1)\n                local first = tags[1]\n                should.be_same(first.tag_name, \"sort\")\n            end)\n\n            it(\"excludes non-lua files when language=lua\", function()\n                local lines = {\n                    \"sort\tlua/devtools/super_iter.lua\t/^function(self, cmp_fn)$/;\\\"\tf\tunknown:iter\",\n                    \"sort\tlua/devtools/super_iter.py\t/^function(self, cmp_fn)$/;\\\"\tf\tunknown:iter\",\n                }\n                local tags = ctags.parse_tag_lines(lines, \"lua\")\n                expect(#tags == 1)\n                local first = tags[1]\n                should.be_same(first.tag_name, \"sort\")\n            end)\n\n            -- TODO! filter by language of file completing in\n            --\n            --\n            -- *** in dotfiles...\n            -- nvim / hammerspoon s/b separated for tags\n            --   architectually... I should probably only generate a tags file in the parent most dir related and name by language then\n            --    OR I need a config mechanism to NOT just use global tags\n            -- cat tags | grep \"nvim.*\\.lua\" | wordcount\n        end)\n\n\n        describe(\"re-assemble SPIKE\", function()\n            it(\"try this\", function()\n                local lines = {\n                    \"on_delete\tlua/devtools/diff/weslcs.lua\t/^    function builder:on_delete(_token)$/;\\\"\tf\tunknown:builder\",\n                    \"on_delete\tlua/devtools/diff/weslcs.lua\t/^    function builder:on_delete(token)$/;\\\"\tf\tunknown:builder}\",\n                    \"sort\tlua/devtools/super_iter.lua\t/^    iter.sort = function(self, cmp_fn)$/;\\\"\tf\tunknown:iter\",\n                }\n\n                local expected_linesA = {\n                    \"lua/devtools/diff/weslcs.lua\",\n                    \"    function builder:on_delete(_token)\",\n                    \"    function builder:on_delete(token)\",\n                    \"lua/devtools/super_iter.lua\",\n                    \"    iter.sort = function(self, cmp_fn)\",\n                }\n\n                local expected_linesB = {\n                    \"lua/devtools/super_iter.lua\",\n                    \"    iter.sort = function(self, cmp_fn)\",\n                    \"lua/devtools/diff/weslcs.lua\",\n                    \"    function builder:on_delete(_token)\",\n                    \"    function builder:on_delete(token)\",\n                }\n\n                local tags = ctags.parse_tag_lines(lines, \"lua\")\n                local assembled = ctags.reassemble_tags(tags)\n\n                -- FYI right now I cannot guarantee the order of the two groups is the same\n                --   so I check that either way, the corresponding lines match per group\n                --   PRN... any way to make the order predictable for the tests w/o altering the impl?\n                --   OR, should I sort keys (filenames) or?<|end|><|start|>assistant",
    "has_new_line": false,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 3516,
    "timings": {
      "cache_n": 574,
      "prompt_n": 2861,
      "prompt_ms": 734.894,
      "prompt_per_token_ms": 0.25686613072352327,
      "prompt_per_second": 3893.0784575734733,
      "predicted_n": 82,
      "predicted_ms": 510.379,
      "predicted_per_token_ms": 6.224134146341464,
      "predicted_per_second": 160.66491763963643
    }
  }
}
