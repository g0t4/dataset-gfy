{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765963987,
  "id": "chatcmpl-saCm9ZmgySEdhXGSJHhvkJuNFZLkfSdK",
  "model": "gpt-oss:120b",
  "system_fingerprint": "b7089-38e2c1b41",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 2503,
    "prompt_n": 1,
    "prompt_ms": 15.041,
    "prompt_per_token_ms": 15.041,
    "prompt_per_second": 66.48494116082708,
    "predicted_n": 81,
    "predicted_ms": 516.927,
    "predicted_per_token_ms": 6.381814814814815,
    "predicted_per_second": 156.69523936648693
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 1,
    "stop": true,
    "model": "gpt-oss:120b",
    "tokens_predicted": 81,
    "tokens_evaluated": 2504,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-17\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n\n\n<|end|><|start|>user<|message|>Here is context that's automatically provided, that MAY be relevant.\nrepo: private-auto-edit-suggests\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/segments.py:52-65\n# 128 ~= 5.80ms (5.68 per video frame)\n# 256 ~= 11.61ms (2.84 per video frame)\n# 512 ~= 23.22ms (1.42 per video frame)\n#\n# FYI video FPS = 30 ==> 33.333ms per frame (at least want to sample once per frame... => hop_length=734.999265 (once per frame)\n#   but lower helps smooth out sharp changes (nearly instantaneous in waveform, i.e. when start talking)... so I will use much smaller so I can see the full \"power form\" (think waveform but for RMS dB)...\n#   b/c I use transition shapes to find bounce/breathing sections reliably (so far!)\n# PRN do a timing analysis of perf difference w/ smaller hop_length values vs bigger (closer to 512)\n#\n# REASONS I LIKE SMALLER HOP_LENGTH\n# - more points == easier to see breathing bounce\n# - fewer segments in final analysis\n#    often very clear when breathing from a glance!\n\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/segments.py:37-56\n# ** RMS params\n#  * (use constants so I can set once I am happy with them... and then I can tweak and read these values elsewhere too which helps explore what differences they have... i.e. to take screencaps of varying hop_len and then flip preview through them to see impact like an animated gif!)\nUSE_MEDFILT_SMOOTHING = False  # I prefer not smoothing here b/c it eats away at extremes like breathing dips!!! so NO!\n#\nRMS_FRAME_LENGTH = 2048  # helps tamp down local thrashing - definitively smooths TOO\n#\nRMS_HOP_LENGTH = 25  # I really liked smaller numbers! will take longer but meh!\n#  FYI hop_length/sample_rate = ms per RMS dB sample\n#  25 ~= 1.134ms per RMS dB sample (~29.11 per video frame) use if odd and want really small! this is 3x more than 73's\n#   ? use 24 if even is better\n#\n#  ?? is even or odd better? and any concerns beyond perf for small values like 72 or even 25?\n#  72 ~= 3.265ms (10.11 per video frame) .. use if even is best\n#  73 ~= 3.31ms (9.97 per video frame) ... use this if odd number is good b/c of centering and then even points around center\n#\n# 128 ~= 5.80ms (5.68 per video frame)\n# 256 ~= 11.61ms (2.84 per video frame)\n# 512 ~= 23.22ms (1.42 per video frame)\n#\n# FYI video FPS = 30 ==> 33.333ms per frame (at least want to sample once per frame... => hop_length=734.999265 (once per frame)\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/librosa_rms.py:0-19\nimport math\nimport librosa\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom auto_edit.tests.test_files import gptoss_fim_video\n\nsplit_breathing_wav = gptoss_fim_video.split_breathing_wav\n\naudio_samples, sample_rate = librosa.load(split_breathing_wav, mono=True)\nframe_length = int(0.03 * sample_rate)  # 30 ms\nhop_length = int(0.01 * sample_rate)  # 10 ms\nsample_rate\nlen(audio_samples)\n\nrms = librosa.feature.rms(\n    y=audio_samples,\n    frame_length=frame_length,\n    hop_length=hop_length,\n)[0]\nprint(len(rms))\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/tests/raw-tests.py:4-6\ndef test_duration(self):\n        silence = RawSilencePeriod(100, 200)\n        assert silence.duration() == 100\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/segments.py:22-41\n\n\n# ** THRESHOLDS\nDEFAULT_THRESHOLDS = DetectThresholds(\n    # > -22 == speech segments\n    breath=np.float64(-22.0),\n    # > -40 == breathe segments (possible breathing, also keystrokes)\n    silence=np.float64(-40.0),\n    # < -40 == silence segment\n)\n\n# ** HARDCODES\n# PRN throw if load a video with a diff frame rate? That way I know to fix this hardcoded assumption?\nVIDEO_FPS = 30\n\n# ** RMS params\n#  * (use constants so I can set once I am happy with them... and then I can tweak and read these values elsewhere too which helps explore what differences they have... i.e. to take screencaps of varying hop_len and then flip preview through them to see impact like an animated gif!)\nUSE_MEDFILT_SMOOTHING = False  # I prefer not smoothing here b/c it eats away at extremes like breathing dips!!! so NO!\n#\nRMS_FRAME_LENGTH = 2048  # helps tamp down local thrashing - definitively smooths TOO\n\n<|end|><|start|>user<|message|>Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\n# TODO tests of:\n# - start is silence (common)\n# - start is speech (rare but possible)\n# - end is silence (common)\n# - end is speech (also rare)\n\n# minute1:\n#   end => around 58s:24f\n#     6 frames deep\n#     double dip breathing\n#     but, the increase after dip on the right is not quite 3dB? or it didn't trip my code\n#       about 2.12dB increase before falls to legit first_min\n#       => thus start/end end up on same start time (first_min == last_min)\n#       could drop 3 to 2dB\n#       or, only when first_min==last_min\n#          => redo last_min search with 2dB (same on first_min)... if different then use that\n#           ? any other verification needed to try 2dB fallback?\n#\n#\n#\n#\n#\n\n# TODO! if you want to use it, use the following for testing your gap labeling (of first_min/last_min)... this is the perfect format for a test:\n# grab real readings and hard code so you don't waste time loading video files?\nimport pytest\nimport rich\nfrom auto_edit.new_silence.detects.segments import DEFAULT_THRESHOLDS, AudioAnalysisResult, DetectedSegment, GapWindow, NonSpeechGap, SegmentLabel\nimport numpy as np\n\nfrom auto_edit.new_silence.gaps import mark_safe_speech_boundaries\n\ndef win(only_gap_segment: DetectedSegment):\n    # FYI fill in more values only as needed...\n    #   honestly this is why I'd prefer to have integration tests for key scenarios than mock all this up\n    analysis = AudioAnalysisResult(\n        audio_samples=[],  # PRN set from segment\n        sample_rate=22050,\n        rms_db=only_gap_segment.rms_values,\n        time_stamps=[],  # PRN\n        thresholds=DEFAULT_THRESHOLDS,\n    )\n\n    win = GapWindow(\n        left_speech=None,\n        gap=NonSpeechGap(segments=[only_gap_segment]),\n        right_speech=None,\n    )\n    return win, analysis\n\nup25 = np.arange(0, 25, 1)\ndown25 = -up25\nup10 = np.arange(0, 10, 1)\nup8 = np.arange(0, 8, 1)\n\ndown10 = -up10\ndown8 = -up8\n\nclass TestLabelingGaps:\n\n    def test_gap_with_double_dip_breathing(self):\n\n        rms_db_list = [\n            -20 + down25,\n            -45 + up10,\n            -35 + down8,\n            -43 + up10,\n        ]\n\n        seg = DetectedSegment(\n            id=1,\n            start_seconds=1.0,\n            end_seconds=2.0,\n            label=SegmentLabel.BREATH,\n            rms_values=np.concatenate(rms_db_list, dtype=np.float64).tolist(),\n        )\n\n        window, analysis = win(seg)\n\n        mark_safe_speech_boundaries(window, analysis)\n        # rich.print(window)\n\n        assert window.first_min_rms == -45\n        assert window.first_min_seconds, pytest.approx(1.02834467)  # 1.0 sec + 25 hops ==>\n        # start == 1.0s\n        # 22050 samples/sec\n        # hop_len == 25  (take 25 at a time)\n        # (22050 samples/sec) / (25 samples) = 882 hops/sec\n        # hop_duration = 1/882 ~= <|fim_middle|>\n        assert window.last_min_rms == -43<|end|><|start|>assistant",
    "has_new_line": false,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 2584,
    "timings": {
      "cache_n": 2503,
      "prompt_n": 1,
      "prompt_ms": 15.041,
      "prompt_per_token_ms": 15.041,
      "prompt_per_second": 66.48494116082708,
      "predicted_n": 81,
      "predicted_ms": 516.927,
      "predicted_per_token_ms": 6.381814814814815,
      "predicted_per_second": 156.69523936648693
    }
  }
}
