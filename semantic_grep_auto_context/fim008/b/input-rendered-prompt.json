{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765996064,
  "id": "chatcmpl-wARV27741hYFV2Lllp5Vw6v3AO2j7CVa",
  "model": "ggml-org/gpt-oss-120b-GGUF",
  "system_fingerprint": "b7453-8faa87db0",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 507,
    "prompt_n": 1795,
    "prompt_ms": 247.678,
    "prompt_per_token_ms": 0.13798217270194985,
    "prompt_per_second": 7247.313043548479,
    "predicted_n": 539,
    "predicted_ms": 2372.731,
    "predicted_per_token_ms": 4.402098330241188,
    "predicted_per_second": 227.16439410957244
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 0,
    "stop": true,
    "model": "ggml-org/gpt-oss-120b-GGUF",
    "tokens_predicted": 539,
    "tokens_evaluated": 2302,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-17\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n\n\n<|end|><|start|>user<|message|>Here is context that's automatically provided, that MAY be relevant.\nrepo: private-auto-edit-suggests\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n<|end|><|start|>user<|message|>Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\nclass TestSegmentBuilder:\n    values: list[float]\n    debug_me: bool = False\n\n    def last(self):\n        return self.values[-1]\n\n    def up(self, count):\n        deltas = np.arange(1, count + 1, 1)\n        return self.add(deltas)\n\n    def down(self, count):\n        deltas = -np.arange(1, count + 1, 1)\n        return self.add(deltas)\n\n    # FYI if I want to simulate curves better (not just linear)...\n    #   i.e. simulate breathing bounce/curve (rise somewhat quick, level off and stay high a few frames, then drop off )\n    def breath_bounce(self, count: int):\n        half = int(count / 2)\n        deltas = -(np.arange(-half, half + 1, 1) / 2)**2  # formula: -(x/2)^2 for x in [-half, half]\n        return self.add(np.array(deltas))\n\n    def add(self, deltas):\n        batch = self.last() + deltas\n\n        if DEBUG or self.debug_me:\n            name_of_calling_function = inspect.stack()[1].function\n            # FYI rich.print here is a convenient way to verify each batch of numbers added to segment, showing min/max values to verify expectations, can be commented out\n            rich.print(f\"{name_of_calling_function}({len(batch)}): {batch}\")\n\n        self.values += batch.tolist()\n        return self\n\ndef start(at, debug_me=False) -> TestSegmentBuilder:\n    if DEBUG or debug_me:\n        rich.print(\"starting at\", at)\n    return TestSegmentBuilder([at], debug_me)\n\ndef win(rms_db: list[np.ndarray] | TestSegmentBuilder):\n    if isinstance(rms_db, TestSegmentBuilder):\n        rms_values = rms_db.values\n    else:\n        rms_values = np.concatenate(rms_db, dtype=np.float64).tolist()\n\n    # FYI fill in more values only as needed...\n    #   honestly this is why I'd prefer to have integration tests for key scenarios than mock all this up\n    analysis = AudioAnalysisResult(\n        audio_samples=[],  # PRN set from segment\n        sample_rate=22050,\n        rms_db=rms_values,\n        time_stamps=[],  # PRN\n        thresholds=DEFAULT_THRESHOLDS,\n    )\n\n    # not necessary, but I am calculating end off of sample count and hop_len:\n    start = 1\n    #\n    TESTING_RMS_HOP_LENGTH = 25  # set this so I know the value doesn't change, even if I change it in the actual code this is testing\n    rms_sample_duration_seconds = TESTING_RMS_HOP_LENGTH / analysis.sample_rate\n    num_rms_samples = len(rms_values)\n    end = start + num_rms_samples * rms_sample_duration_seconds\n    #\n    only_gap_segment = gap_segment(rms_values, start=start, end=end)\n\n    win = GapWindow(\n        left_speech=None,\n        gap=NonSpeechGap(segments=[only_gap_segment]),\n        right_speech=None,\n    )\n    return win, analysis\n\ndef compute_speech_boundaries(rms_values, up_db=3):\n    window, analysis = win(rms_values)\n    mark_safe_speech_boundaries(window, analysis, up_db=up_db)\n    return window\n\nclass TestLabelingGaps:\n\n    def test_segment_builder_with_breathing_curve(self):\n        test = start(10, debug_me=True).breath_bounce(10)\n        assert <|fim_middle|>\n\n    def test_segment_builder(self):\n        # FYI \\ plus () is placed to allow for multi line chaining... and comments to explain each part's purpose... the \\ blocks the formatter from messing with this (at all)\n        #  lolz yapf dies if \\ is after wards, on its own line right before closing )\n        items = ( \\\n            start(-20)\n                .down(5) # speech taper\n                .up(3).down(3) # breathing bounce\n                .up(4) # speech rampup\n        )\n\n        assert items.values == [ \\\n            -20,\n            -21, -22, -23, -24, -25, # speech taper\n            -24, -23, -22, # breathing starts\n            -23, -24, -25, # breathing tapers\n            -24, -23, -22, -21 # speech rampup\n        ]\n        # FYI \\ again is for splitting across lines, to stop formatter from putting shit back on one line\n\n    def test_double_dip_breath_finds__first_min__and__last_min(self):\n        # so far all breathing looks like this double dip pattern\n        # and that makes sense given when I edit the waveform, I always see the bounce w/ empty dips on each side\n        # and I always move boundary between clips so its over the dip time... and then mute the breathing gap\n        # so this all checks out intuitively\n        # only real variation is going to be the degree of bounce and how well I can detect the dips (timing wise)\n        #    and then positioning frame rounding over this region (using rms_values if needed to pick a winning frame to round up/down)\n\n        window = compute_speech_boundaries( \\\n            start(-20)\n                .down(25) # speech taper\n                .up(10).down(8) # breathing bounce\n                .up(10) # speech rampup\n        )\n\n        assert window.first_min_rms == -45\n        assert window.first_min_seconds == pytest.approx(1.0 + 25 / 882)  # 1.0 sec + 25 hops * 1/882 sec/hop ==> seconds of first_min\n        # start == 1.0s\n        # 22050 samples/sec\n        # hop_len == 25  (take 25 at a time)\n        # (22050 samples/sec) / (25 samples) = 882 hops/sec\n        # hop_duration = 1/882 ~= 0.0011337868480725624\n        # 0.0011337868480725624 * 25 (samples) == 0.02834467\n        assert window.last_min_rms == -43\n        assert window.last_min_seconds == pytest.approx(1.0 + 43 / 882)  # 1.0 sec + 43 hops/ 882 hops (note just coincidence -43 is value, they are not the same thing here)\n\n    # PRN flat segment?\n    # PRN first_min == last_min (but when re-run using up_db=2 then it finds breathing bounce with different last_min)... accept in this case?\n    #    ONLY if breathing bounce is obviously in-between?\n\n    # TODO some integration tests too with real video files\n\n    def test_breathing_bounce_with_2dB_on_last_min(self):\n        # FYI edge case of (drop == up_db)\n        #    FYI convention of saying \"drop\" for this test case is by virtue of left to right (time based) reading of segment behavior\n\n        # minute1 example at end, 2dB breathing jump (decline technically into last_min)\n        # I might make a special use case for this or just generally speaking lower my threshold from 3 to 2\n\n        window = compute_speech_boundaries( \\\n            start(-20)\n                .down(25) # speech taper\n                .up(10).down(2) # breathing bounce\n                .up(10), # speech rampup\n            up_db=2\n        )\n\n        assert window.first_min_rms == -45\n        assert window.first_min_seconds == pytest.approx(1.0 + 25 / 882)  # 1.0 sec + 25 hops * 1/882 sec/hop ==> seconds of first_min\n\n        assert window.last_min_rms == -37\n        assert window.last_min_seconds == pytest.approx(1.0 + 37 / 882)  # 37/882\n        #\n        # OR not use 2dB? and instead this will match first_min?\n        # assert window.last_min_rms == window.first_min_rms\n        # assert window.last_min_seconds == window.first_min_seconds\n\n    def test_breathing_bounce_with_2dB_on_first_min(self):\n        # FYI edge case of (jump == up_db)\n<|end|><|start|>assistant",
    "has_new_line": false,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 2840,
    "timings": {
      "cache_n": 507,
      "prompt_n": 1795,
      "prompt_ms": 247.678,
      "prompt_per_token_ms": 0.13798217270194985,
      "prompt_per_second": 7247.313043548479,
      "predicted_n": 539,
      "predicted_ms": 2372.731,
      "predicted_per_token_ms": 4.402098330241188,
      "predicted_per_second": 227.16439410957244
    }
  }
}
