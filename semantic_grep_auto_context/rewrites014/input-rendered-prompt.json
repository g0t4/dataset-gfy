{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1767162252,
  "id": "chatcmpl-wtm7OWuNyj2KyWSYQTueLRMoJnH8RjRO",
  "model": "ggml-org/gpt-oss-120b-GGUF",
  "system_fingerprint": "b7453-8faa87db0",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 350,
    "prompt_n": 863,
    "prompt_ms": 374.596,
    "prompt_per_token_ms": 0.4340625724217845,
    "prompt_per_second": 2303.815310361029,
    "predicted_n": 38,
    "predicted_ms": 196.72,
    "predicted_per_token_ms": 5.176842105263158,
    "predicted_per_second": 193.1679544530297
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 0,
    "stop": true,
    "model": "ggml-org/gpt-oss-120b-GGUF",
    "tokens_predicted": 38,
    "tokens_evaluated": 1213,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-31\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are an expert coder. Ground rules:\n- Follow the user's instructions. \n- DO NOT wrap answers in markdown code blocks, which means no triple backticks like ``` nor single backtick like ` .\n- Do not explain answers, just give me code. \n- Never add comments to the end of a line. \n- Never add comments.\n- Preserve indentation. \n- If rewriting code, preserve unrelated code. \n- Prefer readable code over of comments. \n\n<|end|><|start|>user<|message|>## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n<|end|><|start|>user<|message|>## Python Code Preferences\n\nNaming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\nType Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n<|end|><|start|>user<|message|># Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/time_series.py:0-11\nimport numpy as np\nfrom dataclasses import dataclass\nfrom matplotlib.lines import Line2D\nfrom scipy.ndimage import uniform_filter1d\nfrom .breathing_state import plot, text_label\n\n@dataclass\nclass TimeSeriesDTO:\n    values: np.ndarray\n    times: np.ndarray\n\n    \n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/time_series.py:6-55\n@dataclass\nclass TimeSeriesDTO:\n    values: np.ndarray\n    times: np.ndarray\n\n    def copy_values(self):\n        return TimeSeriesDTO(values=self.values.copy(), times=self.times)\n\n    def plot(self, shift: float | int | None = None, label_end: str | None = None, **kwargs) -> list[Line2D]:\n        return plot(self.times, self.values, shift=shift, label_end=label_end, **kwargs)\n\n    def plot_sign_and_smooth_sign(self, shift, color, label_end):\n        self.sign().plot(color=color, linewidth=1, shift=shift, label_end=label_end)\n        self.smooth().sign().plot(color=\"black\", linewidth=1, shift=shift)\n\n    def smooth(self, size: int = 25) -> \"TimeSeriesDTO\":\n        return TimeSeriesDTO(values=uniform_filter1d(self.values, size=size), times=self.times)\n\n    def sign(self) -> \"TimeSeriesDTO\":\n        return TimeSeriesDTO(values=np.sign(self.values), times=self.times)\n\n    def stepped(self, step_size=2) -> \"TimeSeriesDTO\":\n        return TimeSeriesDTO(\n            values=self.values[::step_size],\n            times=self.times[::step_size],\n        )\n\n    def diff(self, align: str = \"right\") -> \"TimeSeriesDTO\":\n        \"\"\"Return the first‑order difference.\n\n        ``align`` determines how timestamps are generated:\n        * ``\"right\"`` (default) – timestamps correspond to the right sample of the\n          pair, matching the historic behaviour.\n        * ``\"mid\"`` – timestamps are placed at the midpoint between the two\n          samples used to compute each difference.\n        \"\"\"\n        values = np.diff(self.values)\n        if align == \"mid\":\n            times = 0.5 * (self.times[1:] + self.times[:-1])\n        else:  # right‑aligned fallback\n            times = self.times[1:]\n        return TimeSeriesDTO(values=values, times=times)\n\n    def mark_rejected(self, why: str):\n        text_label(\n            x_pos=self.times[len(self.times) // 2],\n            y_pos=self.values.max() + 3,\n            text=why,\n        )\n        self.plot(color=\"pink\", linewidth=1)\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/time_series.py:27-31\ndef stepped(self, step_size=2) -> \"TimeSeriesDTO\":\n        return TimeSeriesDTO(\n            values=self.values[::step_size],\n            times=self.times[::step_size],\n        )\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/time_series.py:11-12\ndef copy_values(self):\n        return TimeSeriesDTO(values=self.values.copy(), times=self.times)\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect_tests.py:26-36\ndef silence_seg(start, end):\n    global id_counter\n    seg = DetectedSegment(\n        id=id_counter,\n        start_seconds=start,\n        end_seconds=end,\n        label=SegmentLabel.SILENCE,\n        rms_values=np.array([id_counter]),\n    )\n    id_counter += 1\n    return seg\n<|end|><|start|>user<|message|>use abs import\nHere is code I selected (with carefully preserved indentation) from auto_edit/new_silence/detects/segments.py:\nfrom .time_series import TimeSeriesDTO<|end|><|start|>assistant",
    "has_new_line": false,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 1250,
    "timings": {
      "cache_n": 350,
      "prompt_n": 863,
      "prompt_ms": 374.596,
      "prompt_per_token_ms": 0.4340625724217845,
      "prompt_per_second": 2303.815310361029,
      "predicted_n": 38,
      "predicted_ms": 196.72,
      "predicted_per_token_ms": 5.176842105263158,
      "predicted_per_second": 193.1679544530297
    }
  }
}
