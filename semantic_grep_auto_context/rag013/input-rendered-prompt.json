{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765387249,
  "id": "chatcmpl-gXYyohxw5DEWXogRQiLGjRm7DG2FhcEy",
  "model": "gpt-oss:120b",
  "system_fingerprint": "b7089-38e2c1b41",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 522,
    "prompt_n": 1193,
    "prompt_ms": 210.34,
    "prompt_per_token_ms": 0.17631181894383907,
    "prompt_per_second": 5671.76951602168,
    "predicted_n": 69,
    "predicted_ms": 292.305,
    "predicted_per_token_ms": 4.236304347826087,
    "predicted_per_second": 236.05480576794784
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 2,
    "stop": true,
    "model": "gpt-oss:120b",
    "tokens_predicted": 69,
    "tokens_evaluated": 1715,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-10\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n\n\n<|end|><|start|>user<|message|>Here is context that's automatically provided, that MAY be relevant.\nrepo: private-auto-edit-suggests\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player.py:51-95\nclass SegmentPlotter:\n    def __init__(self, analysis: AudioAnalysisResult, segments: list[DetectedSegment] | None = None):\n        self.analysis = analysis\n        self.segments = segments or analysis.segments\n        self.fig, self.ax = plt.subplots(figsize=(20, 10))\n        self._setup_plot()\n        self._connect_events()\n\n    def _play_segment(self, start: float, end: float) -> None:\n        sr = self.analysis.sample_rate\n        audio = self.analysis.audio_samples\n        start_idx = int(start * sr)\n        end_idx = int(end * sr)\n        segment = audio[start_idx:end_idx]\n        sd.play(segment, sr)\n\n    def _setup_plot(self) -> None:\n        for seg in self.segments:\n            times = np.linspace(seg.start, seg.end, len(seg.rms_segment))\n            self.ax.plot(times, seg.rms_segment, color=seg.plot_color())\n        self.ax.set_xlabel(\"Time (s)\")\n        self.ax.set_ylabel(\"Amplitude\")\n        self.ax.set_title(\"RMS Segments – click to play\")\n\n    def _on_click(self, event) -> None:\n        if event.inaxes != self.ax:\n            return\n        click_time = event.xdata\n        for seg in self.segments:\n            if seg.start <= click_time <= seg.end:\n                self._play_segment(seg.start, seg.end)\n                break\n\n    def _connect_events(self) -> None:\n        setup_events(self.fig, self.ax, self._on_click)\n\n    def show(self) -> None:\n        plt.show()\n\n    def add_segments(self, new_segments: list[DetectedSegment]) -> None:\n        self.segments.extend(new_segments)\n        for seg in new_segments:\n            times = np.linspace(seg.start, seg.end, len(seg.rms_segment))\n            self.ax.plot(times, seg.rms_segment, color=seg.plot_color())\n        self.fig.canvas.draw_idle()\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player.py:67-73\ndef _setup_plot(self) -> None:\n        for seg in self.segments:\n            times = np.linspace(seg.start, seg.end, len(seg.rms_segment))\n            self.ax.plot(times, seg.rms_segment, color=seg.plot_color())\n        self.ax.set_xlabel(\"Time (s)\")\n        self.ax.set_ylabel(\"Amplitude\")\n        self.ax.set_title(\"RMS Segments – click to play\")\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player.py:52-57\ndef __init__(self, analysis: AudioAnalysisResult, segments: list[DetectedSegment] | None = None):\n        self.analysis = analysis\n        self.segments = segments or analysis.segments\n        self.fig, self.ax = plt.subplots(figsize=(20, 10))\n        self._setup_plot()\n        self._connect_events()\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect.py:108-113\ndef __str__(self) -> str:\n\n        label = colorize(self.label.value.lower(), self.plot_color())\n\n        # 4 for left padding id\n        return f\"{self.id:4} {label}: [{self.start:.3f}->{self.end:.3f}) {self.duration:.3f}s {self.rms_summary}\"\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player.py:90-95\ndef add_segments(self, new_segments: list[DetectedSegment]) -> None:\n        self.segments.extend(new_segments)\n        for seg in new_segments:\n            times = np.linspace(seg.start, seg.end, len(seg.rms_segment))\n            self.ax.plot(times, seg.rms_segment, color=seg.plot_color())\n        self.fig.canvas.draw_idle()\n<|end|><|start|>user<|message|>Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\nfrom auto_edit.new_silence.detect import *\nfrom auto_edit.new_silence.player import plot_segments, play_segments\nfrom auto_edit.tests.test_files import gptoss\nfrom numpy.typing import NDArray\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport rich\nimport sounddevice as sd\n\n# what_file = gptoss.minute1\nwhat_file = gptoss.full\n\n# %%\n\nthresholds = DetectThresholds(silence=np.float64(-40.0), breath=np.float64(-22.0))\n\nanalysis = speech_analysis(what_file, thresholds)\n\nanalysis.merged = merge_close_speech_segments(analysis, max_gap=0.1)\n\n# %%\n\n# for s in analysis.merged:\n#     if \"bounce\" in s.labels:\n#         rich.print(s.rms_segment)\nrich.print(analysis.merged)\n# %%\n\n# analysis.list_by_label(SegmentLabel.SILENCE)\n\n# play_merged_segments_by_id_range(analysis, 5909, 5911)\n# plot_segments(analysis, analysis.merged[50:100])\n# play_time_range(43.2, 43.6)\n# play_segments(analysis, [s for s in analysis.merged if s.label == SegmentLabel.SILENCE and s.duration < 0.03])\n# mute_and_play_segments(analysis, [s for s in analysis.merged if s.start > 7 and s.start < 14])\n\nsegs = [s for s in analysis.merged if s.start > 6 and s.start < 80]\nplotter = <|fim_middle|>\n\n\n<|end|><|start|>assistant",
    "has_new_line": false,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 1783,
    "timings": {
      "cache_n": 522,
      "prompt_n": 1193,
      "prompt_ms": 210.34,
      "prompt_per_token_ms": 0.17631181894383907,
      "prompt_per_second": 5671.76951602168,
      "predicted_n": 69,
      "predicted_ms": 292.305,
      "predicted_per_token_ms": 4.236304347826087,
      "predicted_per_second": 236.05480576794784
    }
  }
}
