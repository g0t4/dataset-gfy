{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1767220567,
  "id": "chatcmpl-WMIpXD3FegFbbnQH4MxEfRiC5cRhzaOi",
  "model": "ggml-org/gpt-oss-120b-GGUF",
  "system_fingerprint": "b7453-8faa87db0",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 0,
    "prompt_n": 2122,
    "prompt_ms": 311.34,
    "prompt_per_token_ms": 0.1467200754005655,
    "prompt_per_second": 6815.6998779469395,
    "predicted_n": 175,
    "predicted_ms": 856.283,
    "predicted_per_token_ms": 4.893045714285714,
    "predicted_per_second": 204.37168552920005
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 1,
    "stop": true,
    "model": "ggml-org/gpt-oss-120b-GGUF",
    "tokens_predicted": 175,
    "tokens_evaluated": 2122,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-31\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are an expert coder. Ground rules:\n- Follow the user's instructions. \n- DO NOT wrap answers in markdown code blocks, which means no triple backticks like ``` nor single backtick like ` .\n- Do not explain answers, just give me code. \n- Never add comments to the end of a line. \n- Never add comments.\n- Preserve indentation. \n- If rewriting code, preserve unrelated code. \n- Prefer readable code over of comments. \n\n<|end|><|start|>user<|message|>FYI, here is my current buffer in Neovim. Use this as context for my request.\n```auto_edit/new_silence/detects/time_series.py\n\nimport numpy as np\nfrom dataclasses import dataclass\nfrom matplotlib.lines import Line2D\nfrom scipy.ndimage import uniform_filter1d\nfrom auto_edit.new_silence.detects.breathing_state import plot, text_label\n\n@dataclass\nclass TimeSeries:\n    \"\"\"Key purpose is to store a sequence of sampled values aligned with timestamps.\n\n    Also, to support common calculations such as diff, smooth, sign, etc... with transparent and consistent values and times.\n    And, some common plot operations to quickly visualize sequences.\n\n    This helps avoid an explosion of two variables _values/_times for every intermediate series!\n    And, you can pass both values/times as a single unit.\n    \"\"\"\n    values: np.ndarray\n    times: np.ndarray\n\n    def copy_values(self):\n        return TimeSeries(values=self.values.copy(), times=self.times)\n\n    def plot(self, shift: float | int | None = None, label_end: str | None = None, **kwargs) -> list[Line2D]:\n        return plot(self.times, self.values, shift=shift, label_end=label_end, **kwargs)\n\n    def plot_sign_and_smooth_sign(self, shift, color, label_end):\n        self.sign().plot(color=color, linewidth=1, shift=shift, label_end=label_end)\n        self.smooth().sign().plot(color=\"black\", linewidth=1, shift=shift)\n\n    def smooth(self, size: int = 25) -> \"TimeSeries\":\n        return TimeSeries(values=uniform_filter1d(self.values, size=size), times=self.times)\n\n    def sign(self) -> \"TimeSeries\":\n        return TimeSeries(values=np.sign(self.values), times=self.times)\n\n\n\n    def stride(self, step_by=2) -> \"TimeSeries\":\n        return TimeSeries(\n            values=self.values[::step_by],\n            times=self.times[::step_by],\n        )\n\n    def diff(self, align: str = \"right\") -> \"TimeSeries\":\n        \"\"\"Return the first‑order difference.\n\n        ``align`` determines how timestamps are generated:\n        * ``\"right\"`` (default) – timestamps correspond to the right sample of the\n          pair, matching the historic behaviour.\n        * ``\"mid\"`` – timestamps are placed at the midpoint between the two\n          samples used to compute each difference.\n        \"\"\"\n        values = np.diff(self.values)\n        if align == \"mid\":\n            times = 0.5 * (self.times[1:] + self.times[:-1])\n        else:  # right‑aligned fallback\n            times = self.times[1:]\n        return TimeSeries(values=values, times=times)\n\n    def mark_rejected(self, why: str):\n        text_label(\n            x_pos=self.times[len(self.times) // 2],\n            y_pos=self.values.max() + 3,\n            text=why,\n        )\n        self.plot(color=\"pink\", linewidth=1)\n\n```<|end|><|start|>user<|message|>## Recent yanks across all files in the project:\n.. yanked from auto_edit/new_silence/detects/breathing.py:\n            diff_stride2_gated = diff_stride2.copy_values()\n            diff_stride2_gated.values[(neg_to_zero < diff_stride2_gated.values) & (diff_stride2_gated.values < pos_to_zero)] = 0\n\n<|end|><|start|>user<|message|>## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n<|end|><|start|>user<|message|>## Python Code Preferences\n\nNaming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\nType Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n<|end|><|start|>user<|message|># Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/silences/detect_raw.py:3-50\nclass RawSilencePeriod:\n\n    def __init__(self, start_seconds: float, end_seconds: float):\n        self.start_seconds = start_seconds\n        self.end_seconds = end_seconds\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __str__(self) -> str:\n        # TODO! confirm end is not inclusive\n        return f\"Raw[{self.start_seconds}➜{self.end_seconds})\"\n\n    def duration(self) -> float:\n        # TODO testing\n        return self.end_seconds - self.start_seconds\n\n    def subtract(self, remove: 'RawSilencePeriod') -> list['RawSilencePeriod']:\n        original = self\n        if original.end_seconds <= remove.start_seconds:\n            return [original]\n        if remove.end_seconds <= original.start_seconds:\n            return [original]\n        if original.start_seconds <= remove.start_seconds and remove.end_seconds <= original.end_seconds:\n            # remove is within original => results in 2 silence periods (possibly, if non zero duration)\n            before = RawSilencePeriod(original.start_seconds, remove.start_seconds)\n            result = []\n            if before.start_seconds != before.end_seconds:\n                result.append(before)\n            after = RawSilencePeriod(remove.end_seconds, original.end_seconds)\n            if after.start_seconds != after.end_seconds:\n                result.append(after)\n            return result\n        if remove.start_seconds <= original.start_seconds:\n            # starts before original => ends in middle => 1 silence periods\n            new_range = RawSilencePeriod(remove.end_seconds, original.end_seconds)\n            if new_range.start_seconds < new_range.end_seconds:\n                return [new_range]\n            return []\n        # starts in middle of original => ends after original => 1 silence periods\n        return [RawSilencePeriod(original.start_seconds, remove.start_seconds)]\n\n    def __eq__(self, other):\n        # IIUC __ne__ => not __eq__ # unless implemented otherwise\n        # !!! TODO is this gonna cause any issues??? => look for times when I compare periods for object equality only...\n        if isinstance(other, RawSilencePeriod):\n            return self.start_seconds == other.start_seconds and self.end_seconds == other.end_seconds\n        return False\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detects/segments.py:269-270\ndef rms_slice(self, start_hop: int, end_hop: int) -> TimeSeries:\n        return TimeSeries(values=self.rms_db[start_hop:end_hop], times=self.time_stamps[start_hop:end_hop])\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player/plot_helpers.py:170-183\ndef clamp_xlim(new_start: float, new_end: float) -> tuple[float, float]:\n        \"\"\"Clamp the new x limits to the data bounds.\n        Returns a tuple (start, end) respecting the overall segment range.\n        \"\"\"\n        data_start = plotter.segments[0].start_seconds\n        data_end = plotter.segments[-1].end_seconds\n        # ensure we don't exceed bounds\n        if new_start < data_start:\n            new_start = data_start\n            new_end = data_start + (new_end - new_start)\n        if new_end > data_end:\n            new_end = data_end\n            new_start = data_end - (new_end - new_start)\n        return new_start, new_end\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/silences/align.py:8-12\ndef __init__(self, start_frame: int, end_frame: int):\n        super().__init__(start_frame, end_frame)\n        # stopgap include plural start_frames/end_frames b/c I named differently in SilenceRange\n        self.start_frames = start_frame\n        self.end_frames = end_frame\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/ranges.py:72-88\nclass SilenceRange(FrameRange):\n\n    dampen: bool = True  # reduce audio level of entire clip, defaults to True for legacy silence detect approach\n\n    def __str__(self):\n        result = f\"Silence[{self.start_frame}➜{self.end_frame})\"\n        if self.dampen:\n            result += f\" dampen\"\n        return result\n\n    def __copy__(self):\n        return self.__deepcopy__()\n\n    def __deepcopy__(self, memo=None):\n        new = SilenceRange(self.start_frame, self.end_frame)\n        new.dampen = self.dampen\n        return new\n<|end|><|start|>user<|message|>add a method on TimeSeries for gate(lower, upper) ... feel free to pick better names if there's a more technical way to refer to the args\nHere is code I selected (with carefully preserved indentation) from auto_edit/new_silence/detects/time_series.py:\n\n<|end|><|start|>assistant",
    "has_new_line": true,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 2296,
    "timings": {
      "cache_n": 0,
      "prompt_n": 2122,
      "prompt_ms": 311.34,
      "prompt_per_token_ms": 0.1467200754005655,
      "prompt_per_second": 6815.6998779469395,
      "predicted_n": 175,
      "predicted_ms": 856.283,
      "predicted_per_token_ms": 4.893045714285714,
      "predicted_per_second": 204.37168552920005
    }
  }
}
