{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765214645,
  "id": "chatcmpl-ei6Bpx43bjNXLOvNYvtsITZLq7jaXqVV",
  "model": "gpt-oss:120b",
  "system_fingerprint": "b7089-38e2c1b41",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 0,
    "prompt_n": 2034,
    "prompt_ms": 305.049,
    "prompt_per_token_ms": 0.1499749262536873,
    "prompt_per_second": 6667.781241702153,
    "predicted_n": 188,
    "predicted_ms": 1123.374,
    "predicted_per_token_ms": 5.975393617021277,
    "predicted_per_second": 167.35299196883673
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 0,
    "stop": true,
    "model": "gpt-oss:120b",
    "tokens_predicted": 188,
    "tokens_evaluated": 2034,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-08\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n\n\n<|end|><|start|>user<|message|>Here is context that's automatically provided, that MAY be relevant.\nrepo: private-auto-edit-suggests\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/tests/test_files.py:0-12\nfrom pathlib import Path\nimport os\nfrom types import SimpleNamespace\n\ndropbox_sync_dir = Path(os.getenv('HOME') or '') / 'dbox/'\ntest_videos_dir = dropbox_sync_dir / 'auto-edit-videos' / 'pytest_samples'\n\ngptoss_fim_examples = test_videos_dir / '01-gpt-oss-fim'\n\ngptoss = SimpleNamespace(\n    full=gptoss_fim_examples / \"full.mp4\",\n    split_breathing=gptoss_fim_examples / \"breathing-split-silence.mp4\",\n)\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/tests/aligned-tests.py:0-13\nimport subprocess\nimport pytest\nimport os\nimport rich\nfrom pathlib import Path\nfrom types import SimpleNamespace\nfrom auto_edit.silences.align import AlignedSilencePeriod, align_silences_to_frame_boundaries_asymmetric_pad_WIP\nfrom auto_edit.silences.detect_raw import ffmpeg_detect_silence_raw\nfrom auto_edit.tests.test_files import gptoss, gptoss_fim_examples\n\n#   TODO! add unit test of combination behavior\n\n# TODO! setup unit tests of AlignedSilencePeriod too\n\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/tests/aligned-tests.py:98-117\n\n\n# %%\n\nraw = ffmpeg_detect_silence_raw(gptoss.full)\nrich.print(raw)\n\n# %%\n\nout_dir = gptoss_fim_examples / \"1_raw_silence_detect_ranges\"\nsubprocess.run([\"mkdir\", \"-p\", f\"{out_dir}\"])\nfor index, r in enumerate(raw):\n    if index < 2:\n        continue\n    rich.print(f\"{index}: {r}\")\n    new_name = out_dir / f\"silence_{index:03d}.mp4\"\n    command = ['ffmpeg', '-y', '-i', gptoss.full, '-ss', str(r.start_seconds), '-to', str(r.end_seconds), str(new_name)]\n    result = subprocess.run(command, stderr=subprocess.PIPE, universal_newlines=True, check=True)\n    output = result.stderr\n    # break\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/samples.py:10-31\nclass files:\n    COPILOT_STREAMDECK_BUTTON_FULL = f\"{ORIGINALS_DIR}/copilot-streamdeck-parts/full.mp4\"\n    COPILOT_STREAMDECK_BUTTON_FIRST30 = f\"{ORIGINALS_DIR}/copilot-streamdeck-parts/first30seconds.mp4\"\n    DOIT01_RETAKE6X = f\"{ORIGINALS_DIR}/doit01/retake6x-30s.mp4\"\n    DOIT01_RETAKE6X_WAV = f\"{ORIGINALS_DIR}/doit01/retake6x-30s.mp4.wav\"\n    DOIT01_FULL = f\"{ORIGINALS_DIR}/doit01/full.mp4\"\n\n    RETIME_LONG_SILENT_START_and_END_24s = f\"{ORIGINALS_DIR}/retime/first24s-long-silence-start-and-end.mp4\"\n    RETIME_LONG_SILENT_START_FULL = f\"{ORIGINALS_DIR}/retime/full.mp4\"\n\n    OBS_RECORDINGS = HOME + 'dbox/renders/obs-recordings'\n    OBS_01_JUPYTER_NB_ONE_TIME_HIT_BEST_TAKE = f\"{OBS_RECORDINGS}/01-jupyter-notebook-one-time-hit/best-take3.mkv.mp4\"\n    #\n    # make numbered:\n    #       ffmpeg -i best-take3.mkv.mp4 -vf \"drawtext=fontfile=/path/to/font.ttf: text='%{frame_num}': x=(w-tw)/2: y=(h-th)/2: fontsize=250: fontcolor=white: box=1: boxcolor=black@0.5\" -codec:a copy best-take3.numbered.mp4\n    OBS_01_JUPTYER_NB_ONE_TIME_HIT_BEST_TAKE_NUMBERED = f\"{OBS_RECORDINGS}/01-jupyter-notebook-one-time-hit/best-take3.numbered.mp4\"\n    #\n\n    ORIGINALS_UNEDITED_DIR = HOME + 'dbox/auto-edit-files/originals-unedited'\n    NUMBERED_FRAMES_50_FPS25 = f'{ORIGINALS_UNEDITED_DIR}/numbered-frames/numbered-50-fps25.mp4'\n    NUMBERED_FRAMES_500_FPS25 = f'{ORIGINALS_UNEDITED_DIR}/numbered-frames/numbered-500-fps25.mp4'\n    NUMBERED_STEPPED_AUDIO_WAV = f'{ORIGINALS_UNEDITED_DIR}/numbered-frames/stepped-audio-waveform.wav'\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/samples.py:0-19\nimport os\n\n\n# dir for samples\nHOME = os.getenv('HOME')\nAUTO_EDIT_DIR = HOME + 'dbox/auto-edit-files'\nORIGINALS_DIR = f\"{AUTO_EDIT_DIR}/originals-unedited\"\n\n\n# export files under one object:\nclass files:\n    COPILOT_STREAMDECK_BUTTON_FULL = f\"{ORIGINALS_DIR}/copilot-streamdeck-parts/full.mp4\"\n    COPILOT_STREAMDECK_BUTTON_FIRST30 = f\"{ORIGINALS_DIR}/copilot-streamdeck-parts/first30seconds.mp4\"\n    DOIT01_RETAKE6X = f\"{ORIGINALS_DIR}/doit01/retake6x-30s.mp4\"\n    DOIT01_RETAKE6X_WAV = f\"{ORIGINALS_DIR}/doit01/retake6x-30s.mp4.wav\"\n    DOIT01_FULL = f\"{ORIGINALS_DIR}/doit01/full.mp4\"\n\n    RETIME_LONG_SILENT_START_and_END_24s = f\"{ORIGINALS_DIR}/retime/first24s-long-silence-start-and-end.mp4\"\n    RETIME_LONG_SILENT_START_FULL = f\"{ORIGINALS_DIR}/retime/full.mp4\"\n\n\n<|end|><|start|>user<|message|>Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\n\nimport librosa\nimport numpy as np\nfrom auto_edit.tests.test_files import gptoss_fim_examples\n\n<|fim_middle|>\n\ny, sr = librosa.load(split_breathing, mono=True)\nframe_length = int(0.03 * sr)   # 30 ms\nhop_length   = int(0.01 * sr)   # 10 ms\n\nrms = librosa.feature.rms(\n    y=y,\n    frame_length=frame_length,\n    hop_length=hop_length,\n)[0]\n\ndb = librosa.amplitude_to_db(rms, ref=np.max)\n<|end|><|start|>assistant",
    "has_new_line": true,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 2221,
    "timings": {
      "cache_n": 0,
      "prompt_n": 2034,
      "prompt_ms": 305.049,
      "prompt_per_token_ms": 0.1499749262536873,
      "prompt_per_second": 6667.781241702153,
      "predicted_n": 188,
      "predicted_ms": 1123.374,
      "predicted_per_token_ms": 5.975393617021277,
      "predicted_per_second": 167.35299196883673
    }
  }
}
