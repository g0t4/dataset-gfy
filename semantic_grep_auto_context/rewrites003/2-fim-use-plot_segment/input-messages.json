{
  "max_tokens": 4096,
  "messages": [
    {
      "role": "developer",
      "content": "You are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n"
    },
    {
      "role": "user",
      "content": "Here is context that's automatically provided, that MAY be relevant.\nrepo: private-auto-edit-suggests\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n## Recent yanks across all files in the project:\n.. yanked from auto_edit/new_silence/detector_notebook.py:\nplotter = SegmentPlotter(analysis, segs, title_addon=title_addon)\n\n.. yanked from auto_edit/new_silence/detector_notebook.py:\nplotter = SegmentPlotter(analysis, segs, title_addon=title_addon)\nplotter.show()\n\n\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player.py:51-141\nclass SegmentPlotter:\n\n    def __init__(\n        self,\n        analysis: AudioAnalysisResult,\n        segments: list[DetectedSegment] | None = None,\n        title_addon: str | None = None,\n    ):\n        self.analysis = analysis\n        self.segments = segments or analysis.segments\n        self.fig, self.ax = plt.subplots(figsize=(20, 10))\n        self.title_addon = title_addon or \"\"\n        self._setup_plot()\n        self._connect_events()\n\n    def _play_segment(self, start: float, end: float) -> None:\n        sr = self.analysis.sample_rate\n        audio = self.analysis.audio_samples\n        start_idx = int(start * sr)\n        end_idx = int(end * sr)\n        segment = audio[start_idx:end_idx]\n        sd.play(segment, sr)\n\n    def _setup_plot(self) -> None:\n        for seg in self.segments:\n            times = np.linspace(seg.start, seg.end, len(seg.rms_segment))\n            if len(seg.rms_segment) == 1:\n                self.ax.scatter(\n                    times,\n                    seg.rms_segment,\n                    color=seg.plot_color(),\n                    label=seg.get_plot_message(),\n                )\n            else:\n                self.ax.plot(\n                    times,\n                    seg.rms_segment,\n                    color=seg.plot_color(),\n                    label=seg.get_plot_message(),\n                )\n\n        self.ax.set_xlabel(\"Time (s)\")\n        self.ax.set_ylabel(\"Amplitude\")\n        self.ax.set_title(f\"RMS Segments {self.title_addon}\")\n\n    def _on_click(self, event) -> None:\n        if event.inaxes != self.ax:\n            return\n        click_time = event.xdata\n        for seg in self.segments:\n            if seg.start <= click_time <= seg.end:\n                self._play_segment(seg.start, seg.end)\n                break\n\n    def _connect_events(self) -> None:\n        setup_events(self.fig, self.ax, self._on_click)\n\n    def show(self) -> None:\n        plt.ion()  # else won't show new plots after initial call to plt.show()\n        plt.show()\n\n    def add_segments(self, new_segments: list[DetectedSegment]) -> None:\n        self.segments.extend(new_segments)\n        for seg in new_segments:\n            times = np.linspace(seg.start, seg.end, len(seg.rms_segment))\n            self.ax.plot(times, seg.rms_segment, color=seg.plot_color())\n        # self.fig.canvas.draw()\n        # self.fig.canvas.flush_events()\n\n    @staticmethod\n    def plot_segment(segment: DetectedSegment) -> None:\n        \"\"\"Display a plot of the RMS values for a single DetectedSegment.\"\"\"\n        # Extract RMS data and time axis\n        rms = segment.rms_segment\n        if rms.ndim != 1:\n            rms = rms.squeeze()\n        fps = 30  # assumed frame rate for time conversion\n        hop_len = RMS_HOP_LENGTH\n        frame_len = RMS_FRAME_LENGTH\n        # Compute time per sample based on hop length\n        times = np.arange(len(rms)) * hop_len / fps\n        # Create the plot\n        plt.figure(figsize=(8, 3))\n        plt.plot(times, rms, label=f\"Segment {segment.id} ({segment.label.value})\")\n        plt.xlabel(\"Time (seconds)\")\n        plt.ylabel(\"RMS\")\n        plt.title(f\"RMS Plot for Segment {segment.id}\")\n        plt.legend()\n        plt.grid(True)\n        plt.tight_layout()\n        plt.show()\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player.py:120-141\n@staticmethod\n    def plot_segment(segment: DetectedSegment) -> None:\n        \"\"\"Display a plot of the RMS values for a single DetectedSegment.\"\"\"\n        # Extract RMS data and time axis\n        rms = segment.rms_segment\n        if rms.ndim != 1:\n            rms = rms.squeeze()\n        fps = 30  # assumed frame rate for time conversion\n        hop_len = RMS_HOP_LENGTH\n        frame_len = RMS_FRAME_LENGTH\n        # Compute time per sample based on hop length\n        times = np.arange(len(rms)) * hop_len / fps\n        # Create the plot\n        plt.figure(figsize=(8, 3))\n        plt.plot(times, rms, label=f\"Segment {segment.id} ({segment.label.value})\")\n        plt.xlabel(\"Time (seconds)\")\n        plt.ylabel(\"RMS\")\n        plt.title(f\"RMS Plot for Segment {segment.id}\")\n        plt.legend()\n        plt.grid(True)\n        plt.tight_layout()\n        plt.show()\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player.py:118-137\n\n\n    @staticmethod\n    def plot_segment(segment: DetectedSegment) -> None:\n        \"\"\"Display a plot of the RMS values for a single DetectedSegment.\"\"\"\n        # Extract RMS data and time axis\n        rms = segment.rms_segment\n        if rms.ndim != 1:\n            rms = rms.squeeze()\n        fps = 30  # assumed frame rate for time conversion\n        hop_len = RMS_HOP_LENGTH\n        frame_len = RMS_FRAME_LENGTH\n        # Compute time per sample based on hop length\n        times = np.arange(len(rms)) * hop_len / fps\n        # Create the plot\n        plt.figure(figsize=(8, 3))\n        plt.plot(times, rms, label=f\"Segment {segment.id} ({segment.label.value})\")\n        plt.xlabel(\"Time (seconds)\")\n        plt.ylabel(\"RMS\")\n        plt.title(f\"RMS Plot for Segment {segment.id}\")\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player.py:133-141\n        plt.figure(figsize=(8, 3))\n        plt.plot(times, rms, label=f\"Segment {segment.id} ({segment.label.value})\")\n        plt.xlabel(\"Time (seconds)\")\n        plt.ylabel(\"RMS\")\n        plt.title(f\"RMS Plot for Segment {segment.id}\")\n        plt.legend()\n        plt.grid(True)\n        plt.tight_layout()\n        plt.show()\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/player.py:112-118\ndef add_segments(self, new_segments: list[DetectedSegment]) -> None:\n        self.segments.extend(new_segments)\n        for seg in new_segments:\n            times = np.linspace(seg.start, seg.end, len(seg.rms_segment))\n            self.ax.plot(times, seg.rms_segment, color=seg.plot_color())\n        # self.fig.canvas.draw()\n        # self.fig.canvas.flush_events()\n"
    },
    {
      "role": "user",
      "content": "Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\nfrom more_itertools import windowed\nfrom operator import attrgetter\nfrom dataclasses import dataclass\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport rich\nimport sounddevice as sd\nimport time\n\nwhat_file = gptoss_fim_video.minute1\n\n# %%\n\ntitle_addon = f\"rms(frame_len={RMS_FRAME_LENGTH},hop_len={RMS_HOP_LENGTH},medfilt={USE_MEDFILT_SMOOTHING})\"\n\nanalysis = full_analysis(what_file)\n\nrich.print(analysis.merged[0:10])\n\n# %%\n\ndef grouped(segments):\n\n    @dataclass(frozen=True)\n    class SegmentGroup:\n        is_speech: bool\n        segments: list[DetectedSegment]\n\n    # return GAP(1+ segments), SPEECH(1 segment), GAP(segs), SPEECH(seg), â€¦\n    for is_speech, segments in groupby(segments, key=lambda seg: seg.label == SegmentLabel.SPEECH):\n        yield SegmentGroup(is_speech=is_speech, segments=list(segments))\n\n@dataclass(frozen=True)\nclass NonSpeechGap:\n    segments: list[DetectedSegment]\n\n@dataclass(frozen=True)\nclass GapWindow:\n    left_speech: DetectedSegment | None\n    gap: NonSpeechGap\n    right_speech: DetectedSegment | None\n\ndef build_gap_decisions(segments: list[DetectedSegment]):\n\n    # TODO tests of:\n    # - start is silence (common)\n    # - start is speech (rare but possible)\n    # - end is silence (common)\n    # - end is speech (also rare)\n\n    def gap(window):\n\n        left_speech = None\n        if window[0] and window[0].is_speech:\n            left_speech = window[0].segments[0]\n            assert len(window[0].segments) == 1, \"Expected only one left speech segment\"\n\n        right_speech = None\n        if window[2] and window[2].is_speech:\n            right_speech = window[2].segments[0]\n            assert len(window[2].segments) == 1, \"Expected only one right speech segment\"\n\n        return GapWindow(\n            left_speech=left_speech,\n            gap=NonSpeechGap(segments=window[1].segments),\n            right_speech=right_speech,\n        )\n\n\n    windows = [\n        gap(w) for w in windowed(grouped(segments), 3) \\\n            if w[1] and not w[1].is_speech\n    ]\n\n    return windows\n\n# list(_as_blocks(analysis.merged))\nwindows = build_gap_decisions(analysis.merged)\nrich.print(list(windows))\nfirst = windows[0]\nSegmentPlotter.plot_segment(<|fim_middle|>)\n\n# %% frame rounding around speech segments\n# FYI not sure you can even discern this w/o first finding an issue in FCPX and testing it here\ndef play_samples(start_sample, end_sample):\n    samples = analysis.audio_samples[start_sample:end_sample]\n\n    print(f\"playing samples={start_sample}-{end_sample}\")\n    sd.play(samples, analysis.sample_rate)\n    sd.wait()\n\nVIDEO_FPS = 30  # HARDCODED\n\ndef play_frames(start_frame, end_frame):\n    start_sample = int(start_frame / VIDEO_FPS * analysis.sample_rate)\n    end_sample = int(end_frame / VIDEO_FPS * analysis.sample_rate)\n    play_samples(start_sample, end_sample)\n\ndef play_to_frame(analysis: AudioAnalysisResult, segment: DetectedSegment) -> None:\n\n    print(f'{segment=}')\n    start_seconds = segment.start\n    end_seconds = segment.end\n\n    # * play literal audio samples without any frame rounding\n\n    start_sample = int(start_seconds * analysis.sample_rate)\n    end_sample = int(end_seconds * analysis.sample_rate)\n    play_samples(start_sample, end_sample)\n    time.sleep(1)\n\n    start_frame = start_seconds * VIDEO_FPS\n    start_frame_before = math.floor(start_frame)\n    start_frame_after = math.ceil(start_frame)\n    rich.print(f\"{start_frame_before=}, {start_frame=}, {start_frame_after=}\")\n\n    end_frame = end_seconds * VIDEO_FPS\n    end_frame_before = math.floor(end_frame)\n    end_frame_after = math.ceil(end_frame)\n    rich.print(f\"{end_frame_before=}, {end_frame=}, {end_frame_after=}\")\n\n    # does start frame matter? before/after => BOTH SOUND GREAT\n    print(\"start BEFORE\")\n    play_frames(start_frame_before, end_frame)\n    time.sleep(0.5)\n    print(\"start AFTER\")\n    play_frames(start_frame_after, end_frame)\n    time.sleep(0.5)\n\n    # what about end frame? before/after?\n    print(\"end BEFORE\")\n    play_frames(start_frame, end_frame_before)\n    time.sleep(0.5)\n\n    print(\"end AFTER\")\n    play_frames(start_frame, end_frame_after)\n    time.sleep(0.5)\n\ntime.sleep(0.5)\nsegment_id = 17\n# play_to_frame(analysis, [s for s in analysis.merged if s.id == segment_id][0])\n\n# %%\n\n# for s in analysis.merged:\n#     if \"bounce\" in s.labels:\n#         rich.print(s.rms_segment)\nrich.print(analysis.merged[0:10])\n# %%\n\n#\n#\n# print(f'{analysis.sample_rate=}') # 22,050\n# %% PLOT:\n\n# segs = [s for s in analysis.merged if s.start >= 60 and s.start < 120]\nsegs = [s for s in analysis.merged if s.start < 30]\nplotter = SegmentPlotter(analysis, segs, title_addon=title_addon)\nplotter.show()\n\n# image_filename = f\"RMS frame_len={RMS_FRAME_LENGTH} hop_len={RMS_HOP_LENGTH}\""
    }
  ],
  "chat_template_kwargs": {
    "reasoning_effort": "low"
  },
  "raw": false,
  "top_p": 1,
  "model": "gpt-oss:120b",
  "stream": true,
  "temperature": 1,
  "options": []
}
