{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765615525,
  "id": "chatcmpl-FkdAOQMPkKoPlLcgwaorhBU0DmECJI8J",
  "model": "",
  "system_fingerprint": "b7089-38e2c1b41",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 0,
    "prompt_n": 1588,
    "prompt_ms": 267.257,
    "prompt_per_token_ms": 0.1682978589420655,
    "prompt_per_second": 5941.846237890869,
    "predicted_n": 257,
    "predicted_ms": 1276.89,
    "predicted_per_token_ms": 4.968443579766538,
    "predicted_per_second": 201.27027386853996
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 0,
    "stop": true,
    "model": "",
    "tokens_predicted": 257,
    "tokens_evaluated": 1588,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-13\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are an expert coder. Ground rules:\n- Follow the user's instructions. \n- DO NOT wrap answers in markdown code blocks, which means no triple backticks like ``` nor single backtick like ` .\n- Do not explain answers, just give me code. \n- Never add comments to the end of a line. \n- Never add comments.\n- Preserve indentation. \n- If rewriting code, preserve unrelated code. \n- Prefer readable code over of comments. \n\n<|end|><|start|>user<|message|>## Recent yanks across all files in the project:\n.. yanked from auto_edit/new_silence/detector_notebook.py:\nplotter = SegmentPlotter(analysis, segs, title_addon=title_addon)\n\n.. yanked from auto_edit/new_silence/detector_notebook.py:\nplotter = SegmentPlotter(analysis, segs, title_addon=title_addon)\nplotter.show()\n\n<|end|><|start|>user<|message|># General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n<|end|><|start|>user<|message|># Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n<|end|><|start|>user<|message|># Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect.py:133-187\n@dataclass(frozen=True)\nclass DetectedSegment:\n    id: int\n    start: float\n    end: float\n    label: SegmentLabel\n    rms_segment: RMSSamplesArray\n    labels: list[str] = field(default_factory=list)\n\n    @property\n    def duration(self) -> float:\n        return self.end - self.start\n\n    @property\n    def rms_summary(self) -> str:\n        rms = self.rms_segment\n        min_val = float(rms.min())\n        mean_val = float(rms.mean())\n        max_val = float(rms.max())\n        # 5.1 ==> b/c one digit for - sign, two for tens/ones before decimal, one for decimal and one after decimal == 5 chars padding (notably to left pad single digit dB values so columns line up across segments when list is printed)\n        return f\"len={len(rms)} min={round(min_val, 1):5.1f} mean={round(mean_val, 1):5.1f} max={round(max_val, 1):5.1f}\"\n\n    def __repr__(self) -> str:\n        return self.__str__()\n\n    def __str__(self, no_color=False) -> str:\n\n        label = self.label.value.lower()\n        if not no_color:\n            label = colorize(self.label.value.lower(), self.plot_color())\n\n        # 4 for left padding id\n        return f\"{self.id:4} {label}: [{self.start:.3f}->{self.end:.3f}) {self.duration:.3f}s {self.rms_summary}\"\n\n    def get_plot_message(self) -> str:\n        fps = 30  # hardcode for now is fine # PRN pass later\n        start_frame = round(self.start * fps, 2)\n        end_frame = round(self.end * fps, 2)\n        return self.__str__(no_color=True) + f'(frames: {start_frame}-{end_frame})'\n\n    def plot_color(self) -> str:\n        if \"bounce\" in self.labels:\n            return \"yellow\"\n        return label_color_map.get(self.label, \"green\")\n\n    def dump_code_to_recreate_me(self) -> str:\n        parts = [\n            f\"id={self.id}\",\n            f\"start={self.start}\",\n            f\"end={self.end}\",\n            f\"label=SegmentLabel.{self.label.name}\",\n            f\"rms_segment=np.array({self.rms_segment.tolist()})\",\n            f\"labels={self.labels!r}\",\n        ]\n        return f\"DetectedSegment({', '.join(parts)})\"\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect_tests.py:54-64\ndef speech_seg(start, end):\n    global id_counter\n    seg = DetectedSegment(\n        id=id_counter,\n        start=start,\n        end=end,\n        label=SegmentLabel.SPEECH,\n        rms_segment=np.array([id_counter]),  # make the samples identifiable is all I need for now\n    )\n    id_counter += 1\n    return seg\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detector_notebook.py:0-19\nfrom auto_edit.new_silence.detect import *\nfrom auto_edit.new_silence.player import SegmentPlotter, play_segments\nfrom auto_edit.new_silence.timer import DurationPrinter\nfrom auto_edit.tests.test_files import gptoss_fim_video\nfrom numpy.typing import NDArray\nfrom itertools import filterfalse, groupby, chain\nfrom more_itertools import windowed\nfrom operator import attrgetter\nfrom dataclasses import dataclass\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport rich\nimport sounddevice as sd\nimport time\n\nwhat_file = gptoss_fim_video.minute1\n\n# %%\n\ntitle_addon = f\"rms(frame_len={RMS_FRAME_LENGTH},hop_len={RMS_HOP_LENGTH},medfilt={USE_MEDFILT_SMOOTHING})\"\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect_tests.py:42-52\ndef silence_seg(start, end):\n    global id_counter\n    seg = DetectedSegment(\n        id=id_counter,\n        start=start,\n        end=end,\n        label=SegmentLabel.SILENCE,\n        rms_segment=np.array([id_counter]),\n    )\n    id_counter += 1\n    return seg\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect.py:125-142\n\n\nlabel_color_map = {\n    SegmentLabel.SILENCE: \"blue\",\n    SegmentLabel.BREATH: \"magenta\",\n    SegmentLabel.SPEECH: \"red\",\n}\n\n@dataclass(frozen=True)\nclass DetectedSegment:\n    id: int\n    start: float\n    end: float\n    label: SegmentLabel\n    rms_segment: RMSSamplesArray\n    labels: list[str] = field(default_factory=list)\n\n    \n<|end|><|start|>user<|message|>make a static method plot_segment(segment)  for showing only a single segment... basically I want to see its RMS values alone\nHere is code I selected (with carefully preserved indentation) from auto_edit/new_silence/player.py:\n\n    <|end|><|start|>assistant",
    "has_new_line": true,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 1844,
    "timings": {
      "cache_n": 0,
      "prompt_n": 1588,
      "prompt_ms": 267.257,
      "prompt_per_token_ms": 0.1682978589420655,
      "prompt_per_second": 5941.846237890869,
      "predicted_n": 257,
      "predicted_ms": 1276.89,
      "predicted_per_token_ms": 4.968443579766538,
      "predicted_per_second": 201.27027386853996
    }
  }
}
