{
  "last_sse":{
    "system_fingerprint":"b7616-18ddaea2a",
    "model":"ggml-org/gpt-oss-120b-GGUF",
    "timings":{
      "prompt_ms":185.27,
      "prompt_per_token_ms":0.11644877435575,
      "predicted_ms":1239.26,
      "predicted_per_token_ms":4.6414232209738,
      "prompt_n":1591,
      "predicted_per_second":215.45115633523,
      "prompt_per_second":8587.4669401414,
      "predicted_n":267,
      "cache_n":609
    },
    "object":"chat.completion.chunk",
    "choices":[{
        "index":0,
        "finish_reason":"stop",
        "delta":[]
      }],
    "created":1768754098,
    "id":"chatcmpl-QPGoKVBk92BAuMzgdPNNFm4V7xLgxKwV"
  },
  "response_message":{
    "role":"assistant",
    "content":"local message = prompts.semantic_grep_user_message(rag_matches)\nreturn message",
    "finish_reason":"stop",
    "reasoning_content":"We need to fill code at <|fim_middle|> inside function HarmonyFimPromptBuilder.context_semantic_grep. Likely should build a message similar to earlier context_user_msg. Look at usage: request.rag_matches. Should create messages variable? Search earlier snippet: at top user had \"local context_lines = ...\" but here we need something else. Probably return a string summarizing rag matches. Maybe similar to other code: In earlier context, they used prompts.semantic_grep_user_message(rag_matches). So likely need to require that. Implement:\n\nlocal message = prompts.semantic_grep_user_message(rag_matches)\nreturn message\n\nBut function expects to return something used later? In fim_prompt they use request.rag_matches only in context_semantic_grep maybe for adding to parts later. Probably should add to self._parts? Actually function returns something used by builder? Search elsewhere but time. Probably should return a string message.\n\nImplement:\n\nlocal message = prompts.semantic_grep_user_message(rag_matches)\nreturn message\n\nAdd nil check already. So:\n\nlocal message = prompts.semantic_grep_user_message(rag_matches)\nif not message then return nil end\nreturn message\n\nWe'll just return message."
  },
  "request_body":{
    "max_tokens":4096,
    "model":"gpt-oss:120b",
    "options":[],
    "messages":[{
        "role":"developer",
        "content":"You are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n"
      },{
        "role":"user",
        "content":"Here is context that's automatically provided, that MAY be relevant.\nrepo: ask-openai.nvim\n\n## General project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n\n## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n\n## Lua Code Preferences\n\nNaming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\nType Hints\n- Prefer EmmyLua/LuaLS style annotations\n- Always annotate when type inference would be ambiguous, or for public APIs.\n\nExamples:\n---@param names string[]\n---@param checker fun(name: string): boolean\n---@return table<string, integer>\nfunction process_names(names, checker) end\n\n---@class WindowController\n---@field window hs.axuielement\n---@field title? string\n---@field size { w: number, h: number }\nlocal WindowController = {}\n\n\n\n## Recent yanks across all files in the project:\n.. yanked from lua/ask-openai/questions/frontend.lua:\n            local message = prompts.semantic_grep_user_message(rag_matches)\n            table.insert(messages, TxChatMessage:user_context(message))\n\n"
      },{
        "role":"user",
        "content":"Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\n\nHarmonyFimPromptBuilder.developer_message = vim.trim([[\nYou are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: ]] .. qwen.FIM_MIDDLE .. [[\n\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near ]] .. qwen.FIM_MIDDLE .. [[\nDo NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the ]] .. qwen.FIM_MIDDLE .. [[ position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return ]] .. qwen.FIM_MIDDLE .. [[ + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\n]])\n\n--- developer message (harmony spec):\n--- - instructions for the model (what is normally considered the “system prompt”)\n--- - and available function tools\n---@return HarmonyFimPromptBuilder self\nfunction HarmonyFimPromptBuilder:developer()\n    table.insert(self._parts, harmony.START .. \"developer\" .. harmony.MESSAGE .. HarmonyFimPromptBuilder.developer_message .. harmony.END)\n    return self\nend\n\n---@param request FimBackend\nfunction HarmonyFimPromptBuilder.context_user_msg(request)\n    local context_lines = {\n        \"Here is context that's automatically provided, that MAY be relevant.\",\n        \"repo: \" .. request:get_repo_name(),\n        \"\",\n        vim.trim([[\n## General project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n]]),\n    }\n    local function add_blank_line()\n        table.insert(context_lines, \"\")\n    end\n\n    local context = request.context\n    if context.includes.project and context.project then\n        vim.iter(context.project)\n            :each(function(value)\n                add_blank_line()\n                table.insert(context_lines, value.content)\n            end)\n    end\n\n    if context.includes.yanks and context.yanks then\n        add_blank_line()\n        table.insert(context_lines, context.yanks.content)\n    end\n\n    -- if context.includes.matching_ctags and context.matching_ctags then\n    --     add_blank_line()\n    --     table.insert(context_lines, context.matching_ctags.content)\n    -- end\n\n    return table.concat(context_lines, \"\\n\")\nend\n\nfunction HarmonyFimPromptBuilder.context_semantic_grep(request)\n    local rag_matches = request.rag_matches\n    if not rag_matches or #rag_matches == 0 then\n        return nil\n    end\n\n    <|fim_middle|>\nend\n\n---@param request FimBackend\nfunction HarmonyFimPromptBuilder.fim_prompt(request)\n    -- * user message\n    local current_file_relative_path = request.inject_file_path_test_seam()\n    local file_prefix = \"\"\n    if current_file_relative_path == nil then\n        log:warn(\"current_file_name is nil\")\n        current_file_relative_path = \"\"\n        file_prefix = \"I am editing this file: \" .. current_file_relative_path .. \"\\n\\n\"\n    end\n\n    --  TODO try PSM format anyways! I think it might help with repeating the suffix?\n    --    might want to find a fine tune too that actually has training for PSM/SPM\n    --    would need to reword some instructions above (including examples)\n    local fim_user_message = file_prefix\n        .. \"Please complete \" .. qwen.FIM_MIDDLE .. \" in the following code (which has carefully preserved indentation):\\n\"\n        .. request.ps_chunk.prefix\n        .. qwen.FIM_MIDDLE\n        .. request.ps_chunk.suffix\n    return fim_user_message\nend\n\n--- user message (harmony spec):\n--- - Typically representing the input to the model\n---@param message string\n---@return HarmonyFimPromptBuilder self\nfunction HarmonyFimPromptBuilder:user(message)\n    if not message then\n        -- don't add an empty message\n        return self\n    end\n\n    table.insert(self._parts, harmony.START .. \"user\" .. harmony.MESSAGE .. message .. harmony.END)\n    return self\nend\n\n-- * deep_thoughts_about_fim\n-- TODO try qwen25coder format? and thinking to explain it?\n--   The user is asking for a FIM completion. Likely for code they are writing.\n--   And it looks like they are providing a qwen2.5-coder compatible FIM prompt.\n--   I should response like Qwen2.5-Coder would respond.\n--   I will fill-in-the-middles in the most awesome way!\n\n-- FYI these are NOT instructions, INSTEAD they are the model's observations!\n-- - So you can use them as instructions just word them appropriately\n-- - What do you want the model to have observed?\n-- ?? should I get gptoss to do this without myself and copy its style instead of wording them myself?\n--\n-- PRN add after I test context (and it feels like the model isn't paying attention to it)\n--   \"Do not forget, the neovim plugin automaticaly collected context to consider. It's included above, in a previous message. I won't blindly repeat it.\"\n--\n-- vim.trim - strip leading/trailing whitespace so I can format my [[ ]] literal as I see fit\n-- - also harmony has no \\n between messages, \\n should only come within a message text field\nHarmonyFimPromptBuilder.deep_thoughts_about_fim = vim.trim([[\nThe user is asking for a code completion.\nThey provided the existing code with a ]] .. qwen.FIM_MIDDLE .. [[ tag where their cursor is currently located. Whatever I provide will replace ]] .. qwen.FIM_MIDDLE .. [[\nTo clarify, the code before ]] .. qwen.FIM_MIDDLE .. [[ is the prefix. The code after is the suffix.\nI am not changing the prefix nor the suffix.\nI will NOT wrap my response in ``` markdown blocks.\nI will not explain anything.\nThey also carefully preserved indentation, so I need to carefully consider indentation in my response.\nI will fill-in-the-middles in the most awesome way!\n]])\n-- FYI adding blurb about no ``` and markdown worked well to stop that!\n-- TODO! detect line break before/after (qwen.FIM_MIDDLE) and adjust the thought about modifying an existing line of code accordingly?\n--   present this as a reflective thought from the model:\n--     If there's no line break before (qwen.FIM_MIDDLE) and/or after, then that means I am completing code on a line of existing code. Do not repeat the rest of the line either!\n-- YES! repeat the CURRENT LINE HERE as an observation!!! And maybe even state what I shouldn't duplicate! (this might help with repeating on same line (almost always right now when there's code on same line after cursor)\n--   MAYBE mention its indentation too instead of other indentation comments above (I can say this line has X indent so I need to respect that)\n--   IF there's code before and after the cursor on the current line, reflect that this is likely just a fill in the middle of this line only, not a multi line response (not likely anyways)\n\n---@return HarmonyFimPromptBuilder self\nfunction HarmonyFimPromptBuilder:set_thinking()\n    table.insert(self._parts,\n        harmony.msg_assistant_analysis(HarmonyFimPromptBuilder.deep_thoughts_about_fim))\n    return self\nend\n"
      }],
    "temperature":1,
    "stream":true,
    "top_p":1,
    "raw":false,
    "chat_template_kwargs":{
      "reasoning_effort":"low"
    }
  }
}