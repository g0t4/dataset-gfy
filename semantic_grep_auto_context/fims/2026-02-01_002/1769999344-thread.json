{
  "request_body":{
    "options":[],
    "raw":false,
    "model":"gpt-oss:120b",
    "top_p":1,
    "temperature":1,
    "chat_template_kwargs":{
      "reasoning_effort":"low"
    },
    "messages":[{
        "content":"You are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position: <|fim_middle|>\n\nThe surrounding code is limited, it may not be the full file. Focus on the code near <|fim_middle|>\nDo NOT explain your decisions. Do NOT return markdown blocks ```\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace. Especially on the cursor line!\nYOU ARE ONLY INSERTING CODE. DO NOT REPEAT PREFIX. DO NOT REPEAT SUFFIX.\nComplete as little or as much code as is necessary to help the user. That means part of a line, a full line or even multiple lines! Goal is to help the user as much as is possible and reasonable.\n\nHere are a few examples of tricky completions:\n\n## Example: suggest middle of line (cursor has existing code before and after it)\n\n```python\ndef area(width, height):\n    return <|fim_middle|> * height\n```\n\nSay this is your desired result:\n```python\ndef area(width, height):\n    return width * height\n```\n\n1. then the CORRECT completion is (do not include backticks, those are just to delimit included whitespace):\n`width`\n\n2. WRONG (because repeats the suffix):\n`width * height`\nresults in:\n`    return width * height * height`\n\n3. WRONG (because repeats both suffix and prefix):\n`    return width * height`\nresults in:\n`    return     return width * height * height`\n\n\n## Example: cursor is indented\n\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n    <|fim_middle|>\n    end\nend\n```\n\n*Keep in mind, the indent will be there before the suggested code too.*\n\nSay this is your desired result:\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n    else\n        print(\"Non‑positive\")\n    end\nend\n```\n\n1. then the CORRECT completion is:\n```lua\nelse\n        print(\"Non‑positive\")\n```\n\n2. WRONG (`else` ends up double indented when it should be single):\n```lua\n    else\n        print(\"Non‑positive\")\n```\nresults in:\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n        else\n        print(\"Non‑positive\")\n    end\nend\n```\n\n3. WRONG (`print` ends up single indented when it should be double):\n```lua\nelse\n    print(\"Non‑positive\")\n```\nresults in:\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n    else\n    print(\"Non‑positive\")\n    end\nend\n```\n\n\n",
        "role":"developer"
      },{
        "content":"Here is context that's automatically provided, that MAY be relevant.\nrepo: practice\n\n## General project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n\n## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n\n## Python Code Preferences\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer `list[]` over `List[]` to mimimize imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n",
        "role":"user"
      },{
        "content":"Please suggest text to replace <|fim_middle|>:\n\n```dropped_frames.py\n# run ffprobe to get frames and check for missing frames\n# minutes/minute3/minute3.mp4\n\nimport subprocess\nimport json\nimport rich\nfrom pathlib import Path\nfrom typing import Any, Callable, Tuple\n\nclass MediaValidationError(ValueError):\n    pass\n\ndef get_format(video_path: Path):\n    #     ffprobe -loglevel warning  -show_format min3dropped.mp4 | bat -l ini\n    # [FORMAT]\n    # filename=min3dropped.mp4\n    # nb_streams=2\n    # nb_programs=0\n    # nb_stream_groups=0\n    # format_name=mov,mp4,m4a,3gp,3g2,mj2\n    # format_long_name=QuickTime / MOV\n    # start_time=0.000000\n    # duration=4.000000\n    # size=1288088\n    # bit_rate=2576176\n    # probe_score=100\n    # TAG:major_brand=isom\n    # TAG:minor_version=512\n    # TAG:compatible_brands=isomiso2avc1mp41\n    # TAG:encoder=Lavf62.3.100\n    # [/FORMAT]\n<|fim_middle|>\n\ndef get_streams(video_path: Path):\n    # FYI to review:\n    #   ffprobe -loglevel warning  -show_streams min3dropped.mp4 | bat -l ini\n    cmd = [\n        \"ffprobe\",\n        \"-loglevel\",\n        \"error\",\n        \"-show_streams\",\n        \"-of\",\n        \"json\",\n        str(video_path),\n    ]\n    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n    data = json.loads(result.stdout)\n\n    # * get ONE audio stream\n    audio_streams = [s for s in data.get(\"streams\", []) if s.get(\"codec_type\") == \"audio\"]\n    if not audio_streams:\n        raise MediaValidationError(\"No audio streams found\")\n    if len(audio_streams) > 1:\n        raise MediaValidationError(f\"Multiple audio streams found, only one allowed: {len(audio_streams)}\")\n    audio = audio_streams[0]\n\n    # * get ONE video stream:\n    video_streams = [s for s in data.get(\"streams\", []) if s.get(\"codec_type\") == \"video\"]\n    if not video_streams:\n        raise MediaValidationError(\"No video streams found\")\n    if len(video_streams) > 1:\n        raise MediaValidationError(f\"Multiple video streams found, only one allowed: {len(video_streams)}\")\n    video = video_streams[0]\n\n    return audio, video\n\ndef throw_if_unexpected(data: dict, key: str, expected: str | int | float, convert: Callable[[Any], Any] | None = None):\n    actual = data.get(key)\n    if convert is not None:\n        actual = convert(actual)\n\n    if actual != expected:\n        rich.inspect(actual)\n        raise MediaValidationError(f\"{key} is {actual}, expected {expected}\")\n\ndef warn_if_unexpected(data: dict, key: str, expected: str | int | float, convert: Callable[[Any], Any] | None = None):\n    actual = data.get(key)\n    if convert is not None:\n        actual = convert(actual)\n    if actual != expected:\n        rich.inspect(actual)\n        rich.print(f\"WARNING: {key} is not {expected}, should be fine but just a heads up: {actual}\")\n\ndef verify_streams(video_path: Path) -> None:\n    audio, video = get_streams(video_path)\n\n    # * audio stream\n    throw_if_unexpected(audio, \"channels\", 1)\n    throw_if_unexpected(audio, \"channel_layout\", \"mono\")\n    #\n    # not show stoppers but that I might want to know, b/c they don't match what I tested with initially\n    warn_if_unexpected(audio, \"sample_rate\", 48000, int)  # str in my testing\n    warn_if_unexpected(audio, \"codec_name\", \"aac\")\n    #\n    throw_if_unexpected(audio, \"start_pts\", 0)\n    throw_if_unexpected(audio, \"start_time\", 0.0, float)  # str in my testing\n    # r_frame_rate=0/0\n    # avg_frame_rate=0/0\n    # time_base=1/48000\n    # duration_ts=2880000\n    # duration=60.000000\n    # nb_frames=2814\n    #\n    # PRN? pass -count_frames/packets and then compare nb_frames to nb_read_frames?\n    # nb_read_frames=N/A\n    # nb_read_packets=N/A\n\n    # * video stream\n    throw_if_unexpected(video, \"codec_name\", \"h264\")\n    # prn can add other resolutions but actually I have things coded for 4k IIRC in fcpxml builder\n    warn_if_unexpected(video, \"width\", 3840)\n    warn_if_unexpected(video, \"height\", 2160)\n    # ? has_b_frames=2\n    # pix_fmt=yuv420p\n    # r_frame_rate=30/1\n    # avg_frame_rate=29/1\n    # time_base=1/15360\n    #\n    throw_if_unexpected(video, \"start_pts\", 0)\n    throw_if_unexpected(video, \"start_time\", 0.0, float)\n    # nb_frames=1799 # duration=59.966667 # duration_ts=921088\n    #\n    # pass -count_frames/packets to get these too:\n    # nb_read_frames=N/A\n    # nb_read_packets=N/A\n\n    # PRN compare across streams?\n    audio_duration = audio.get(\"duration\")\n    video_duration = video.get(\"duration\")\n    if not (audio_duration == video_duration):\n        raise MediaValidationError(f\"Audio and video durations differ: {audio_duration} vs {video_duration}\")\n\ndef get_frame_timestamps(video_path: Path) -> list[float]:\n    cmd = [\n        \"ffprobe\",\n        \"-loglevel\",\n        \"error\",\n        \"-select_streams\",\n        \"v:0\",\n        \"-show_entries\",\n        \"frame=pts,pts_time,nb_samples,duration_time\",\n        # ? pkt_dts/pkt_dts_time\n        #   ? would these always match pts in my case? any use in verifying they match pts to avoid another set of problems?\n        #   ? likewise with best_effort_timestamp/best_effort_timestamp_time\n        \"-of\",\n        \"json\",\n        str(video_path),\n    ]\n    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n    data = json.loads(result.stdout)\n    timestamps = [float(frame[\"pts_time\"]) for frame in data.get(\"frames\", [])]\n    return timestamps\n\ndef find_missing_frames(timestamps: list[float], tolerance: float = 0.034) -> list[Tuple[int, int]]:\n    missing = []\n    for i in range(1, len(timestamps)):\n        if timestamps[i] - timestamps[i - 1] > tolerance:\n            missing.append((i - 1, i))\n    return missing\n\ndef report_missing_frames(video_path: Path) -> None:\n```\n\n## Reminders about the cursor line:\n",
        "role":"user"
      }],
    "max_tokens":4096,
    "stream":true
  },
  "last_sse":{
    "created":1769999344,
    "object":"chat.completion.chunk",
    "timings":{
      "prompt_n":1492,
      "prompt_ms":191.457,
      "prompt_per_token_ms":0.12832238605898,
      "predicted_ms":622.596,
      "cache_n":923,
      "predicted_per_second":218.44020841766,
      "predicted_n":136,
      "prompt_per_second":7792.8725510167,
      "predicted_per_token_ms":4.5779117647059
    },
    "model":"ggml-org/gpt-oss-120b-GGUF",
    "system_fingerprint":"b7785-1c7cf94b2",
    "choices":[{
        "index":0,
        "delta":[],
        "finish_reason":"stop"
      }],
    "id":"chatcmpl-kjtZeqElJv5QEgxjWs1oQLvlAibEY8gY"
  },
  "response_message":{
    "reasoning_content":"We need to fill after get_format function. Probably should implement get_format similar to get_streams. Return format dict. Provide cmd and parsing. Let's write code.",
    "role":"assistant",
    "content":"    cmd = [\n        \"ffprobe\",\n        \"-loglevel\",\n        \"error\",\n        \"-show_format\",\n        \"-of\",\n        \"json\",\n        str(video_path),\n    ]\n    result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n    data = json.loads(result.stdout)\n    format_info = data.get(\"format\")\n    if not format_info:\n        raise MediaValidationError(\"No format information found\")\n    return format_info",
    "finish_reason":"stop"
  }
}