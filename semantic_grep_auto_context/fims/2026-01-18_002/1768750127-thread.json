{
  "request_body":{
    "options":[],
    "messages":[{
        "content":"You are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n",
        "role":"developer"
      },{
        "content":"Here is context that's automatically provided, that MAY be relevant.\nrepo: auto-edit-suggests\n\n## General project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n\n## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n\n## Python Code Preferences\n\nNaming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\nType Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n\n## Recent yanks across all files in the project:\n.. yanked from auto_edit/new_silence/tests/integration_tests.py:\n        assert win11_2s.first_min.seconds == pytest.approx(11.96, 0.1)\n\n.. yanked from auto_edit/new_silence/tests/integration_tests.py:\n        assert win11_2s.first_min.seconds == pytest.approx(11.96, 0.1)\n        assert win11_2s.first_min.seconds == win11_2s.last_min.seconds\n\n\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/auto-edit-suggests/auto_edit/new_silence/ranges_tests.py:208-225\ndef test_window_with_no_speech(self):\n        # this is not really that useful...\n        # why would I have a recording with no speaking? and then want to edit it?\n        # certainly I wouldn't need careful silence gap analysis and segmenting...\n        # if anything, I'd want segmenting based on visual changes (visual equivalent of silence splitting)\n        # nonetheless, good edge case to consider (doesn't pressure anything not already covered in other tests)\n\n        win = GapWindow(\n            left_speech=None,\n            gap=NonSpeechGap(segments=[silence_seg(1, 2)]),\n            right_speech=None,\n        )\n        analysis = fake_analysis_for([win])\n\n        ranges = get_ranges(analysis)\n\n        assert ranges[0].start_frame == 30\n        assert ranges[0].end_frame == 60\n\n## ~/repos/github/g0t4/auto-edit-suggests/auto_edit/new_silence/ranges_tests.py:187-206\ndef test_window_without_right_speech(self):\n        win = GapWindow(\n            left_speech=speech_seg(0, 1),\n            gap=NonSpeechGap(segments=[silence_seg(1, 2)]),\n            right_speech=None,\n            first_min=SimpleNamespace(frame_aligned_at_seconds=1),\n            last_min=SimpleNamespace(frame_aligned_at_seconds=2),\n        )\n        analysis = fake_analysis_for([win])\n\n        ranges = get_ranges(analysis)\n\n        # speech at the start\n        assert ranges[0].start_frame == 0\n        assert ranges[0].end_frame == 30\n        assert type(ranges[0]) == ContentRange\n        # following silence segment\n        assert ranges[1].start_frame == 30\n        assert ranges[1].end_frame == 60\n        assert type(ranges[1]) == SilenceRange\n\n## ~/repos/github/g0t4/auto-edit-suggests/auto_edit/new_silence/player/segment_plotter.py:606-611\ndef gap_is_visible(win: GapWindow):\n                if win.gap.end_seconds() < visible_start_seconds:\n                    return False\n                if visible_end_seconds < win.gap.start_seconds():\n                    return False\n                return True\n\n## ~/repos/github/g0t4/auto-edit-suggests/auto_edit/new_silence/player/segment_plotter.py:488-494\ndef zoom_to_gap(self, window: GapWindow | None) -> None:\n        if window is None:\n            return\n        # fixed zoom level with gap centered (not full window, just the gap of silence)...\n        middle = (window.gap.start_seconds() + window.gap.end_seconds()) / 2\n        width_seconds = 2  # fixed width in seconds\n        self.set_x_limits(middle - width_seconds / 2, middle + width_seconds / 2)\n\n## ~/repos/github/g0t4/auto-edit-suggests/auto_edit/new_silence/player/segment_plotter.py:513-517\ndef shift_center_to_gap(self, win: GapWindow | None):\n        if not win:\n            return\n        middle = win.gap.middle_seconds()\n        self.shift_center_to(middle)\n",
        "role":"user"
      },{
        "content":"Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\n    ):\n        self.win = win\n        self.gap_rms = gap_rms\n        self.analysis = analysis\n        self.plotting = plotting\n        self.journal = []\n\n    @property\n    def crosses(self):\n        return self.win.gap.crossovers\n\n    def rms_at(self, seconds) -> float:\n        hops = self.analysis.to_hops(seconds)\n        return self.analysis.rms_db[hops]\n\n    def note(self, what):\n        self.journal.append(str(what))\n\n    def reject(self, why):\n        self.journal.append(f\"rejected: {why}\")\n\nclass BreathingDetector:\n\n    def not_breathing(self, context: GapContext) -> bool:\n        return False\n\n# TODO DETECTORS / SegmentsBuilder?\n# double bounce => smaller first one < 100ms => treat as taper\n\nclass ApplyNotesAsLabelSegments:\n    # key reminders I have taken down in notes here\n    # should be applied to test cases and shown on segment plotters\n\n    def __init__(self, plotter: SegmentPlotter):\n        self.plotter = plotter\n\n    def apply(self, c: GapContext):\n        if not c.plotting:\n            return\n\n        y_db = self.plotter.get_y_limits().top - 2\n\n        def label(video_and_time: str, text: str) -> None:\n            # split \"minute7@30s\" → (\"minute7.mp4\", 30.0)\n            video_part, time_part = video_and_time.split(\"@\")\n            video_name = video_part if video_part.endswith(\".mp4\") else f\"{video_part}.mp4\"\n            x_seconds = float(time_part.rstrip(\"s\").rstrip(\"sec\"))\n\n            if c.analysis.path.name == video_name and c.win.gap.contains(x_seconds):\n                self.plotter.ax.text(\n                    x_seconds, y_db, \\\n                    text,\n                    ha=\"center\", va=\"bottom\", \\\n                    fontsize=12, color=\"red\", style=\"italic\",\n                )\n\n        label(\"minute3@30s\", \"mis-speaking (don't fret over rules)\")\n        # speech + breathing double humps identified in integration tests\n        label(\"minute7@2.5s\", \"tex(t) t_taper + breathing\")\n        label(\"minute7@57.3s\", \"loo(k) k_taper + breathing\")\n        label(\"minute4@7s\", \"reques(t) t_taper + breathing\")\n\n# TODO => maybe this is some sort of SegmentClassifier?\n#   TODO or maybe I need to make detectors just all classify various subsegments and not just \"reject\" as breathing/not?\n# look for left_speech taper! and then we can shift the left_speech segment's end_seconds()\n#   in theory, later I can find how to incorprate this detection logic\n\n# - is diff(rms) negative until the first crossover? => this is taper\n#    basically I should move the edit point b/w left_speech and gap ... to the first crossover's corresponding minima\nclass LeftSpeechTaper_WithOptionalBreathe_Locator():\n\n    def locate(self, c: GapContext):\n        # TODO what to return? NOTE this is NOT just a breathing check\n        crosses, note, reject, win, gap = c.crosses, c.note, c.reject, c.win, c.win.gap\n\n        if win.left_speech is None:\n            return reject(\"no left_speech to taper\")\n\n        if len(crosses) == 1:\n            # PRN this should apply to most detectors/locators\n            win.gap.<|fim_middle|>\n            return note(\"one crossover = speech\")\n\n        # * Step 1 - mark first_min/last_min as first/last critical points\n        #  FYI replaces legacy first_min/last_min\n        #     TODO! fully replace and get rid of old first/last min detection (not as accurate)\n        #       TODO legacy relied on absolute change in dB not rising up much b/w hops in diff1\n        #       TODO no ability to handle taper humps after a first_min\n        #  setting first_min/last_min is about marking the first/last critical points\n        #  - and always treating that segment before/after as taper/rampup\n        #  - gap[start] ➜ min[0] - downward segment\n        #      gap_start.rms > min[0].rms by definition...\n        #      ... b/c gap_start is RMS right when it crosses below speech threshold\n        #      btw (min[0] == first critical point == cp0 == min0)\n        #      this s/b flagged as taper\n        #      => hence, set left_taper_end (where left_speech's taper ends, into the gap)\n        #  - min[-1] ➜ gap[end] - upward segment\n        #      gap_end.rms > min[-1].rms (also by definition, same threshold reason)\n        #      this s/b flagged as rampup (taper)\n        #      => hence, set right_taper_start (rampup start where right_speech ramps up)\n        #         think of reverse taper, or just \"tapering up\"\n        #  * thus every clip at least has taper to first/last critical point\n        #     until I find a case where that doesn't work\n        #     these are local minima critical points\n        #     the reason they work well for taper, is b/c cut points work best at minimums!\n        #        even if not super quiet volume level, mins are good places to slice audio and avoid clicks\n        #        clicks can happen when cutting anywhere but the minimums!\n        #          not always, but often\n        #  upward segment [end of gap from last CP => end of gap\n\n        # * first_min assumptions\n        cross0 = crosses[0]\n        cp0 = cross0.critical_point\n        gap_start_rms = c.gap_rms.values[0]\n        if gap_start_rms < cp0.rms:\n            return reject(f\"assumption violated {gap_start_rms=} must be greater than {cp0.rms=} (first critical point s/b a min below gap_start.rms)\")\n        if not cross0.is_local_min():\n            return reject(\"first crossover must contain a local minimum\")\n        # FYI virt_seg[0] would make WAY more sense here...\n\n        # * last_min assumptions\n        cross_last = crosses[-1]\n        cp_last = cross_last.critical_point\n        gap_end_rms = c.gap_rms.values[-1]\n        if gap_end_rms < cp_last.rms:\n            return reject(f\"assumption violated {gap_end_rms=} must be greater than {cp0.rms=}\")\n        if not cross_last.is_local_min():\n            return reject(\"last crossover must contain a local minimum\")\n\n        # * mark taper through first_min, and after last_min\n        gap.left_taper_end = cp0\n        gap.right_taper_start = cp_last\n\n        # * STEP 2 - check for further taper beyond first/last_min... in the form of waveform humps\n        # - IOTW first_min (aka min0) => max1 => min2 - this is a candidate hump (if present) for extending left_speech's left_taper_end\n        #        min[-3] => max[-2] => last_min (aka min[-1]) - candidate hump (if present) for extending right_speech's right_taper_start (rampup)\n        #\n        #   ** generally speaking the taper is over when minimums bottom out... if a subsequent minimum rises, the taper is over (in my experience)\n        #    - why? b/c a rise in subsequent minimums (critical points) only happens with a material sound source, i.e. typing/breathing/talking...\n        #    - and taper by definition is the trailing sound as you finish a sentence, in which case volume often drops while still speaking\n        #    - and that drop in volume falls below normal speech thresholds... and so we want to detect that at the end of speech and make sure not to cut that off!\n        #    - we want to cut right after the taper stops (or close to it) to avoid clicks\n\n        def is_double_hump():\n            return len(crosses) == 5\n\n        def check_for_further_left_taper_hump():\n            if len(crosses) < 5:\n                # FYI 5 minimum so we have two humps\n                # if you think less would work, find real examples and add them as integration tests before modifying the rules here\n                return None\n\n            # also this verifies min/max/min/max/min layout (beyond making sure it has 5+ CPs)\n            at_least_two_humps = cross0.is_local_min() \\\n                and crosses[1].is_local_max() \\\n                and crosses[2].is_local_min() \\\n                and crosses[3].is_local_max() \\\n                and crosses[4].is_local_min()\n            if not at_least_two_humps:\n                return None\n",
        "role":"user"
      }],
    "model":"gpt-oss:120b",
    "top_p":1,
    "chat_template_kwargs":{
      "reasoning_effort":"low"
    },
    "temperature":1,
    "raw":false,
    "max_tokens":4096,
    "stream":true
  },
  "last_sse":{
    "timings":{
      "predicted_ms":1414.295,
      "predicted_per_token_ms":4.7143166666667,
      "predicted_per_second":212.11981941533,
      "predicted_n":300,
      "prompt_per_second":8784.2774864609,
      "prompt_n":3270,
      "cache_n":0,
      "prompt_ms":372.256,
      "prompt_per_token_ms":0.11383975535168
    },
    "object":"chat.completion.chunk",
    "created":1768750127,
    "id":"chatcmpl-8YNBqmwzPCa7mRLL7agGVySMW5Sagain",
    "system_fingerprint":"b7616-18ddaea2a",
    "choices":[{
        "index":0,
        "delta":[],
        "finish_reason":"stop"
      }],
    "model":"ggml-org/gpt-oss-120b-GGUF"
  },
  "response_message":{
    "reasoning_content":"We need to fill after win.gap. at line with single crossover. Likely want to set something like win.gap.left_taper_end = None? Actually when only one crossover, just note speech. Probably want to set gap.left_taper_end = crosses[0].critical_point? But later code uses left_taper_end and right_taper_start. For one crossover, maybe set both? Simpler: win.gap.left_taper_end = crosses[0].critical_point; win.gap.right_taper_start = crosses[0].critical_point; then note. Return note. So fill: win.gap.left_taper_end = crosses[0].critical_point; win.gap.right_taper_start = crosses[0].critical_point. Return note. But note already after. So just assign. Provide code line. Probably need semicolon? Python separate lines. We have single line placeholder. Should write two lines? The placeholder is within if block expecting code. Could put both assignments then note. But note after placeholder line. So we replace placeholder with something like:\n\nwin.gap.left_taper_end = crosses[0].critical_point\nwin.gap.right_taper_start = crosses[0].critical_point\n\nThus two lines. Ensure indentation matches. Return note afterwards.",
    "role":"assistant",
    "finish_reason":"stop",
    "content":"win.gap.left_taper_end = crosses[0].critical_point\nwin.gap.right_taper_start = crosses[0].critical_point"
  }
}