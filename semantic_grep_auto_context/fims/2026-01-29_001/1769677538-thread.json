{
  "last_sse":{
    "timings":{
      "predicted_per_second":207.94874579216,
      "predicted_n":383,
      "prompt_per_second":3321.0984549117,
      "cache_n":903,
      "prompt_ms":469.423,
      "prompt_per_token_ms":0.30110519563823,
      "predicted_ms":1841.8,
      "predicted_per_token_ms":4.8088772845953,
      "prompt_n":1559
    },
    "model":"ggml-org/gpt-oss-120b-GGUF",
    "id":"chatcmpl-6CIFyBMMiTEYsO7B5or6onUSsvcyhssI",
    "object":"chat.completion.chunk",
    "created":1769677538,
    "choices":[{
        "delta":[],
        "index":0,
        "finish_reason":"stop"
      }],
    "system_fingerprint":"b7785-1c7cf94b2"
  },
  "response_message":{
    "reasoning_content":"We need to insert code that adds something to system_message_instructions when mcp_tool has run_process or run_command. Probably similar to inprocess part: get instructions from tool. Search repo? Likely mcp_tool has get_system_message_instructions method? Look at mcp tool definitions. Probably mcp_tool has field \"run_process\" referencing a script; need to read its system message. Maybe use mcp_tool.run_process.get_system_message_instructions()? Actually apply_patch_tool is separate. For mcp, maybe there is a function to get instructions: require(\"ask-openai.tools.mcp\").get_system_message_instructions? Already used earlier. So within loop, if mcp_tool.run_process or run_command then add system_message_instructions from mcp_tool? Might be mcp_tool.get_system_message_instructions()? Check file mcp init for such. Search mental: Not seen. Might be mcp_tool.run_process? Probably a path to run_process folder containing commits.md etc. The system message is common for all mcp tools, not per tool. So maybe just insert system_message_instructions from M.get_system_message_instructions(). So code: table.insert(system_message_instructions, M.get_system_message_instructions())? But M is router module, not mcp. Use mcp.get_system_message_instructions()? In mcp/init.lua defines M.get_system_message_instructions. So call mcp.get_system_message_instructions(). So insert: table.insert(system_message_instructions, mcp.get_system_message_instructions()).\n\nThus completion line with proper indent: `table.insert(system_message_instructions, mcp.get_system_message_instructions())`. Ensure indentation matches 12 spaces? The cursor line has 12 spaces before. So output exactly that line.",
    "role":"assistant",
    "content":"            table.insert(system_message_instructions, mcp.get_system_message_instructions())",
    "finish_reason":"stop"
  },
  "request_body":{
    "options":[],
    "chat_template_kwargs":{
      "reasoning_effort":"low"
    },
    "raw":false,
    "model":"gpt-oss:120b",
    "top_p":1,
    "max_tokens":4096,
    "messages":[{
        "content":"You are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position: <|fim_middle|>\n\nThe surrounding code is limited, it may not be the full file. Focus on the code near <|fim_middle|>\nDo NOT explain your decisions. Do NOT return markdown blocks ```\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace. Especially on the cursor line!\nYOU ARE ONLY INSERTING CODE. DO NOT REPEAT PREFIX. DO NOT REPEAT SUFFIX.\nComplete as little or as much code as is necessary to help the user. That means part of a line, a full line or even multiple lines! Goal is to help the user as much as is possible and reasonable.\n\nHere are a few examples of tricky completions:\n\n## Example: suggest middle of line (cursor has existing code before and after it)\n\n```python\ndef area(width, height):\n    return <|fim_middle|> * height\n```\n\nSay this is your desired result:\n```python\ndef area(width, height):\n    return width * height\n```\n\n1. then the CORRECT completion is (do not include backticks, those are just to delimit included whitespace):\n`width`\n\n2. WRONG (because repeats the suffix):\n`width * height`\nresults in:\n`    return width * height * height`\n\n3. WRONG (because repeats both suffix and prefix):\n`    return width * height`\nresults in:\n`    return     return width * height * height`\n\n\n## Example: cursor is indented\n\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n    <|fim_middle|>\n    end\nend\n```\n\n*Keep in mind, the indent will be there before the suggested code too.*\n\nSay this is your desired result:\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n    else\n        print(\"Non‑positive\")\n    end\nend\n```\n\n1. then the CORRECT completion is:\n```lua\nelse\n        print(\"Non‑positive\")\n```\n\n2. WRONG (`else` ends up double indented when it should be single):\n```lua\n    else\n        print(\"Non‑positive\")\n```\nresults in:\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n        else\n        print(\"Non‑positive\")\n    end\nend\n```\n\n3. WRONG (`print` ends up single indented when it should be double):\n```lua\nelse\n    print(\"Non‑positive\")\n```\nresults in:\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n    else\n    print(\"Non‑positive\")\n    end\nend\n```\n\n\n",
        "role":"developer"
      },{
        "content":"Here is context that's automatically provided, that MAY be relevant.\nrepo: ask-openai.nvim\n\n## General project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n\n## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n\n## Lua Code Preferences\n\nNaming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\nType Hints\n- Prefer EmmyLua/LuaLS style annotations\n- Always annotate when type inference would be ambiguous, or for public APIs.\n\nExamples:\n```lua\n---@param names string[]\n---@param checker fun(name: string): boolean\n---@return table<string, integer>\nfunction process_names(names, checker) end\n\n---@class WindowController\n---@field window hs.axuielement\n---@field title? string\n---@field size { w: number, h: number }\nlocal WindowController = {}\n```\n\n\n\n## Recent yanks (copy to clipboard):\n```lua/ask-openai/tools/mcp/init.lua\nget_system_message_instructions\n```\n\n",
        "role":"user"
      },{
        "content":"# Semantic Grep matches: 5\n\nThis is automatic context based on my request. These may or may not be relevant.\n## ~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/tools/mcp/init.lua:244-265\nfunction M.get_system_message_instructions()\n    if M._cached_instructs then\n        return M._cached_instructs\n    end\n    -- PRN could get these from a named MCP prompt resource?\n\n    local files = require(\"ask-openai.helpers.files\")\n    local mcp_dir = \"~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/tools/mcp\"\n    local run_process_dir = mcp_dir .. \"run_process\"\n\n    -- TODO where should I get placeholder values? (i.e COAUTHOR_NAME)\n    local commits = files\n        .read_text(run_process_dir .. \"/commits.md\")\n        :gsub(\"<<COAUTHOR_NAME>>\", \"gptoss120b\")\n\n    local commands = files.read_text(run_process_dir .. \"/commands.md\")\n\n    -- PRN have a checker that looks at blank lines at end/start of join sections then adds \\n only if needed\n    M._cached_instructs = commits .. \"\\n\\n\" .. commands\n\n    return M._cached_instructs\nend\n\n## ~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/tools/mcp/init.lua:177-203\nfunction openai_tool(mcp_tool)\n    -- OpenAI docs for tools: https://platform.openai.com/docs/api-reference/chat/create#chat-create-tools\n\n    -- effectively a deep clone\n    params = {}\n    params.required = mcp_tool.inputSchema.required\n    params.type = mcp_tool.inputSchema.type\n    params.properties = {}\n    for k, v in pairs(mcp_tool.inputSchema.properties) do\n        params.properties[k] = {}\n        for k2, v2 in pairs(v) do\n            params.properties[k][k2] = v2\n        end\n        params.properties[k] = v\n    end\n\n    return {\n        type = \"function\",\n        [\"function\"] = {\n            name = mcp_tool.name,\n            -- FYI mcp-server-commands doesn't currently set a desc (won't see that in testing)\n            description = mcp_tool.description,\n            parameters = params,\n            -- strict = false -- default is false... should I set true?\n        }\n    }\nend\n\n## ~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/tools/mcp/init.lua:175-194\n\n\nfunction openai_tool(mcp_tool)\n    -- OpenAI docs for tools: https://platform.openai.com/docs/api-reference/chat/create#chat-create-tools\n\n    -- effectively a deep clone\n    params = {}\n    params.required = mcp_tool.inputSchema.required\n    params.type = mcp_tool.inputSchema.type\n    params.properties = {}\n    for k, v in pairs(mcp_tool.inputSchema.properties) do\n        params.properties[k] = {}\n        for k2, v2 in pairs(v) do\n            params.properties[k][k2] = v2\n        end\n        params.properties[k] = v\n    end\n\n    return {\n        type = \"function\",\n\n\n## ~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/tools/mcp/init.lua:240-259\n    tool.server.tools_call(tool_call.id, name, args_decoded, vim.schedule_wrap(callback))\nend\n\nM._cached_instructs = nil\nfunction M.get_system_message_instructions()\n    if M._cached_instructs then\n        return M._cached_instructs\n    end\n    -- PRN could get these from a named MCP prompt resource?\n\n    local files = require(\"ask-openai.helpers.files\")\n    local mcp_dir = \"~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/tools/mcp\"\n    local run_process_dir = mcp_dir .. \"run_process\"\n\n    -- TODO where should I get placeholder values? (i.e COAUTHOR_NAME)\n    local commits = files\n        .read_text(run_process_dir .. \"/commits.md\")\n        :gsub(\"<<COAUTHOR_NAME>>\", \"gptoss120b\")\n\n    local commands = files.read_text(run_process_dir .. \"/commands.md\")\n\n\n## ~/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/tools/mcp/init.lua:155-166\n                   function(msg)\n        if msg.error then\n            log:error(\"tools/list@\" .. name .. \" error:\", vim.inspect(msg))\n            return\n        end\n        -- log:luaify_trace(\"tools/list:\", msg)\n        for _, tool in ipairs(msg.result.tools) do\n            -- log:trace(\"found \" .. tool.name)\n            tool.server = mcp\n            M.tools_available[tool.name] = tool\n        end\n    end\n",
        "role":"user"
      },{
        "content":"Please suggest text to replace <|fim_middle|>:\n\n```lua/ask-openai/tools/router.lua\nlocal mcp = require(\"ask-openai.tools.mcp\")\nlocal inprocess = require(\"ask-openai.tools.inprocess\")\nlocal plumbing = require(\"ask-openai.tools.plumbing\")\nlocal apply_patch_tool = require(\"ask-openai.tools.inproc.apply_patch\")\n\nlocal M = {}\n\nfunction M.openai_tools()\n    local tools = {}\n    local system_message_instructions = {}\n    for _, mcp_tool in pairs(mcp.tools_available) do\n        table.insert(tools, openai_tool(mcp_tool))\n        if mcp_tool[\"run_process\"] or mcp_tool[\"run_command\"] then\n            <|fim_middle|>\n        end\n    end\n    for _, inprocess_tool in pairs(inprocess.tools_available) do\n        table.insert(tools, inprocess_tool)\n\n        -- hack to inject instructions, will revisit later\n        if inprocess_tool[\"function\"].name == \"apply_patch\" then\n            -- TODO move this down into inprocess module to aggregate?\n            table.insert(system_message_instructions, apply_patch_tool.get_system_message_instructions())\n        end\n    end\n    return tools, system_message_instructions\nend\n\n---@alias ToolCallDoneCallback fun(call_output: table|MCPToolCallOutputResult|MCPToolCallOutputError)\n\n---@param tool_call table\n---@param callback ToolCallDoneCallback\nfunction M.send_tool_call_router(tool_call, callback)\n    local tool_name = tool_call[\"function\"].name\n    -- local tool_name = \"no_way\" -- FYI test tool call failure plumbing (callbacks)\n\n    if mcp.handles_tool(tool_name) then\n        mcp.send_tool_call(tool_call, callback)\n        return\n    end\n\n    if inprocess.handles_tool(tool_name) then\n        inprocess.send_tool_call(tool_call, callback)\n        return\n    end\n\n    callback(plumbing.create_tool_call_output_for_error_message(\"Invalid tool name: \" .. tool_name))\nend\n\nreturn M\n```\n\n## Reminders about the cursor line:\nText before cursor: `            `\nText before cursor is all whitespace (do not ignore this)",
        "role":"user"
      }],
    "stream":true,
    "temperature":1
  }
}