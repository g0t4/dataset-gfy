{
  "request_body":{
    "options":[],
    "messages":[{
        "content":"You are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position: <|fim_middle|>\n\nThe surrounding code is limited, it may not be the full file. Focus on the code near <|fim_middle|>\nDo NOT explain your decisions. Do NOT return markdown blocks ```\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace. Especially on the cursor line!\nYOU ARE ONLY INSERTING CODE. DO NOT REPEAT PREFIX. DO NOT REPEAT SUFFIX.\nComplete as little or as much code as is necessary to help the user. That means part of a line, a full line or even multiple lines! Goal is to help the user as much as is possible and reasonable.\n\nHere are a few examples of tricky completions:\n\n## Example: suggest middle of line (cursor has existing code before and after it)\n\n```python\ndef area(width, height):\n    return <|fim_middle|> * height\n```\n\nSay this is your desired result:\n```python\ndef area(width, height):\n    return width * height\n```\n\n1. then the CORRECT completion is (do not include backticks, those are just to delimit included whitespace):\n`width`\n\n2. WRONG (because repeats the suffix):\n`width * height`\nresults in:\n`    return width * height * height`\n\n3. WRONG (because repeats both suffix and prefix):\n`    return width * height`\nresults in:\n`    return     return width * height * height`\n\n\n## Example: cursor is indented\n\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n    <|fim_middle|>\n    end\nend\n```\n\n*Keep in mind, the indent will be there before the suggested code too.*\n\nSay this is your desired result:\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n    else\n        print(\"Non‑positive\")\n    end\nend\n```\n\n1. then the CORRECT completion is:\n```lua\nelse\n        print(\"Non‑positive\")\n```\n\n2. WRONG (`else` ends up double indented when it should be single):\n```lua\n    else\n        print(\"Non‑positive\")\n```\nresults in:\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n        else\n        print(\"Non‑positive\")\n    end\nend\n```\n\n3. WRONG (`print` ends up single indented when it should be double):\n```lua\nelse\n    print(\"Non‑positive\")\n```\nresults in:\n```lua\nfunction print_sign(number)\n    if number > 0 then\n        print(\"Positive\")\n    else\n    print(\"Non‑positive\")\n    end\nend\n```\n\n\n",
        "_logged":true,
        "role":"developer"
      },{
        "content":"Here is context that's automatically provided, that MAY be relevant.\nrepo: auto-edit-suggests\n\n## General project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n\n## General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n\n## Python Code Preferences\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer `list[]` over `List[]` to mimimize imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n",
        "_logged":true,
        "role":"user"
      },{
        "content":"# Semantic Grep matches: 5\n\nThis is automatic context based on my request. These may or may not be relevant.\n## ~/repos/github/g0t4/auto-edit-suggests/auto_edit/new_silence/ranges_tests.py:17-27\ndef silence_seg(start_seconds, end_seconds):\n    global id_counter\n    seg = DetectedSegment(\n        id=id_counter,\n        start_seconds=start_seconds,\n        end_seconds=end_seconds,\n        label=SegmentLabel.SILENCE,\n        rms_values=np.array([id_counter]),\n    )\n    id_counter += 1\n    return seg\n\n## ~/repos/github/g0t4/auto-edit-suggests/auto_edit/new_silence/detect_tests.py:26-36\ndef silence_seg(start, end):\n    global id_counter\n    seg = DetectedSegment(\n        id=id_counter,\n        start_seconds=start,\n        end_seconds=end,\n        label=SegmentLabel.SILENCE,\n        rms_values=np.array([id_counter]),\n    )\n    id_counter += 1\n    return seg\n\n## ~/repos/github/g0t4/auto-edit-suggests/auto_edit/silences/detect_raw.py:50-69\n\n\n# FYI typing on mechanical keyboard is picked up >  50dB so that would bust silence areas, so might have to do multi pass and/or gauge silence levels though I don't mind leaving typing in during silent periods as long as rules for max length are adhered to.\ndef ffmpeg_detect_silence(input_media, silence_threshold=-50, silence_duration=0.5):\n    \"\"\"\n    Returns:\n    - list of tuples containing start and end times of silence periods.\n    \"\"\"\n    command = ['ffmpeg', '-i', input_media, '-af', f'silencedetect=n={silence_threshold}dB:d={silence_duration}', '-f', 'null', '-']\n\n    result = subprocess.run(command, stderr=subprocess.PIPE, universal_newlines=True, check=True)\n    output = result.stderr\n\n    silence_start_pattern = re.compile(r'silence_start: (-?\\d+\\.?\\d*)')\n    silence_end_pattern = re.compile(r'silence_end: (-?\\d+\\.?\\d*)')\n\n    silence_starts = silence_start_pattern.findall(output)\n    silence_ends = silence_end_pattern.findall(output)\n\n    assert len(silence_starts) == len(silence_ends)\n\n\n## ~/repos/github/g0t4/auto-edit-suggests/auto_edit/fcpxml/builder.py:112-142\n    def add_silence(self, silence: SilenceRange, is_first_silence: bool):\n        name = \"\"\n\n        max_silence_frames = round(0.5 * self.fps)\n        if is_first_silence:\n            if silence.duration_frames() > max_silence_frames:\n                name += \"trim-\"\n                silence = silence.trim_start(keep_frames=max_silence_frames)  # limit to last 0.5s\n\n        if silence.duration_frames() > max_silence_frames:\n            name += \"trim-\"\n            silence = silence.trim_end(keep_frames=max_silence_frames)\n\n        name += f\"silent{silence.start_frame}-{silence.end_frame} / {self.show_seconds(silence.start_frame)}-{self.show_seconds(silence.end_frame)}\"\n\n        clip = ET.SubElement(\n            self.spine,\n            \"asset-clip\",  # https://developer.apple.com/documentation/professional-video-applications/asset-clip\n            name=name,\n            ref=\"r2\",\n            start=self.frames_to_fraction(silence.start_frame),\n            duration=self.frames_to_fraction(silence.duration_frames()),\n            audioRole=\"dialogue\",\n        )\n\n        if silence.dampen:\n            # adjust_volume(clip, -30) # loud breathing will kinda be heard (barely)\n            # adjust_volume(clip, -96) # or just mute it\n            add_noise_gate(clip)\n        # if silence.mute:\n        #     adjust_volume(clip, -96)\n\n## ~/repos/github/g0t4/auto-edit-suggests/auto_edit/new_silence/detect.py:0-19\nfrom io import StringIO\nfrom rich.console import Console\nfrom rich.text import Text\nfrom traitlets.config.configurable import SingletonConfigurable\nfrom auto_edit.new_silence.gaps import build_gap_decisions\nfrom auto_edit.new_silence.prober import raise_if_video_has_nonzero_timing_start_offsets\nfrom auto_edit.new_silence.timer import DurationPrinter\n\nfrom auto_edit.new_silence.detects.segments import (\n    MAX_POSSIBLE_VALUE_NORMALIZED_AUDIO,\n    LoadedAudio,\n    SegmentLabel,\n    MonoAudioSamplesArray,\n    SampleRate,\n    RMSValues,\n    Float32Array,\n    DetectThresholds,\n    AudioAnalysisResult,\n    DetectedSegment,\n    CombinedSegments,\n\n",
        "_logged":true,
        "role":"user"
      },{
        "content":"Please suggest text to replace <|fim_middle|>:\n\n```generate_fcpxml_notebook.py\n#!/usr/bin/env python\n# use ipython API so magic commands don't break YAPF\n# * autoreload changed modules (both `import` and `from` style imports)\nget_ipython().extension_manager.load_extension(\"autoreload\")  # pyright: ignore\nget_ipython().run_line_magic('autoreload', 'complete --print')  # pyright: ignore\n\nfrom rich.traceback import install\n\ninstall(show_locals=False)\n\nimport rich\nimport os\nimport sys\nfrom pathlib import Path\nfrom moviepy.editor import VideoFileClip\nfrom auto_edit.new_silence.ranges import get_ranges\nfrom auto_edit.ranges import Ranges\nfrom auto_edit.tests.test_files import gptoss_fim_video\nfrom auto_edit.fcpxml.builder import FcpXml\nfrom auto_edit.new_silence.player.segment_plotter import SegmentPlotter\nfrom auto_edit.new_silence.detect import <|fim_middle|>\nfrom auto_edit.transcribe import WhisperSegment\nfrom auto_edit.new_silence.detects.breathing import mark_breathing\nfrom auto_edit.new_silence.player.mpl_helpers import move_to_primary_screen, move_to_secondary_screen\nfrom auto_edit.transcribe import transcribe\nfrom auto_edit.ai.suggests import which_ranges_to_remove\nfrom auto_edit.silences.legacy_silence_detect import add_legacy_ffmpeg_overlays\n\nif os.getenv(\"NVIM\"):\n    which_video = str(gptoss_fim_video.minute3)  # minute3 is great for testing AI suggested segment removals (retakes) for segments 2,5,13\n    # which_video = '~dbox/Movies/apply_patch/raw_originals/combined.shifted100ms.cfr_and_start.mp4'\nelse:\n    if len(sys.argv) != 2:\n        print(f\"ERROR, you must pass a video file CLI arg\")\n        exit(1)\n    which_video = sys.argv[1]\n\nwhich_video = Path(which_video)\n\n# %% * file paths and params\n\nif which_video.name.endswith('.mkv'):\n    raise Exception(f\"ERROR: video file extension is .mkv, which is not supported by Final Cut Pro X. Please convert to .mp4 first. {which_video}\")\n\noriginal = VideoFileClip(which_video.as_posix())\nprint(f\"duration: {original.duration}s, fps: {original.fps}, size: {original.size}, frames: {original.fps*original.duration}\")\n\n# %% *** NEW silence detect!\n\nanalysis = full_analysis(which_video)\n\n# %%\nPLOTTING = True\nplotter = None\n\nif PLOTTING:\n    plt.close(\"all\")\n    plotter = SegmentPlotter.for_entire(analysis)\n    plotter.show()\n\n    add_legacy_ffmpeg_overlays(which_video, original)\n\nmark_breathing(analysis, plotter=plotter)  # always do breathing analysis, plotter deterines if it plots too\nall = sorted(get_ranges(analysis))\nuse_ranges = Ranges(all)\n\nif PLOTTING:\n    # plotter.set_x_limits(2, 3)\n    plotter.zoom_to_gap_at_seconds(346)\n    # move_to_secondary_screen(plotter.fig)\n    move_to_primary_screen(plotter.fig)\n\n# %% * transcribe\n\ntranscribe(which_video, use_ranges, original.fps)\n\n# %%\n\nsuggested_ranges_to_remove = {}\nsuggested_ranges_to_remove = which_ranges_to_remove(use_ranges)\n\n# %%\n\n# TODO cleanup after moving output_dir etc to top of FcpXml ctor\nfcpxml = FcpXml(original, which_video)\nfcpxml.build(use_ranges, suggested_ranges_to_remove)\n```\n\n## Reminders about the cursor line:\nText before cursor: `from auto_edit.new_silence.detect import `",
        "_logged":true,
        "role":"user"
      }],
    "raw":false,
    "max_tokens":4096,
    "model":"gpt-oss:120b",
    "top_p":1,
    "stream":true,
    "chat_template_kwargs":{
      "reasoning_effort":"low"
    },
    "temperature":1
  },
  "last_sse":{
    "object":"chat.completion.chunk",
    "id":"chatcmpl-oyyYbCqjSVKEjByJLDqCvZhrauxfH3f6",
    "model":"ggml-org/gpt-oss-120b-GGUF",
    "created":1771191238,
    "system_fingerprint":"b7785-1c7cf94b2",
    "choices":[{
        "finish_reason":"stop",
        "delta":[],
        "index":0
      }],
    "timings":{
      "cache_n":2108,
      "prompt_ms":121.624,
      "prompt_per_token_ms":0.200699669967,
      "predicted_ms":321.617,
      "predicted_per_token_ms":4.0711012658228,
      "predicted_per_second":245.63378179636,
      "predicted_n":79,
      "prompt_per_second":4982.5692297573,
      "prompt_n":606
    }
  },
  "response_message":{
    "finish_reason":"stop",
    "content":"full_analysis",
    "reasoning_content":"We need to import something. Likely full_analysis function. Search context: earlier they used full_analysis which likely from detect module. So import full_analysis. Also maybe other names. In script they call full_analysis(which_video). So line should be: from auto_edit.new_silence.detect import full_analysis\n\nThus completion: full_analysis",
    "role":"assistant",
    "_logged":true
  }
}