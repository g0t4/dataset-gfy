{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765626235,
  "id": "chatcmpl-f22YyglOQSA5X9X5xskc72ldNgQQtT5I",
  "model": "",
  "system_fingerprint": "b7089-38e2c1b41",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 0,
    "prompt_n": 1512,
    "prompt_ms": 289.683,
    "prompt_per_token_ms": 0.1915892857142857,
    "prompt_per_second": 5219.498555317365,
    "predicted_n": 348,
    "predicted_ms": 1582.745,
    "predicted_per_token_ms": 4.5481178160919535,
    "predicted_per_second": 219.87117318329865
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 1,
    "stop": true,
    "model": "",
    "tokens_predicted": 348,
    "tokens_evaluated": 1512,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-13\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are an expert coder. Ground rules:\n- Follow the user's instructions. \n- DO NOT wrap answers in markdown code blocks, which means no triple backticks like ``` nor single backtick like ` .\n- Do not explain answers, just give me code. \n- Never add comments to the end of a line. \n- Never add comments.\n- Preserve indentation. \n- If rewriting code, preserve unrelated code. \n- Prefer readable code over of comments. \n\n<|end|><|start|>user<|message|># General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n<|end|><|start|>user<|message|># Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n<|end|><|start|>user<|message|># Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/librosa_rms.py:112-121\ndef show_rms():\n    plt.close()\n    hops_match_time_axis = np.arange(len(rms)) / 100  # 10ms gap b/w hops\n    plt.plot(hops_match_time_axis, rms)\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"rms\")\n    plt.title(\"Audio Waveform\")\n\n    plt.tight_layout()\n    plt.show()\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/librosa_rms.py:127-137\ndef show_rms_db():\n    plt.close()\n    hops_match_time_axis = np.arange(len(rms)) / 100  # 10ms gap b/w hops => 3 sec recording => 302 db/rms readings (10ms hops)\n    plt.plot(hops_match_time_axis, rms_db)\n    # plt.plot(hops_match_time_axis, rms)\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"db or rms\")\n    plt.title(\"Audio Waveform\")\n\n    plt.tight_layout()\n    plt.show()\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/librosa_rms.py:85-104\ndef show_power_squared():\n    plt.close()\n\n    time_axis = np.arange(len(audio_samples)) / sample_rate\n    plt.figure(figsize=(10, 4))\n    # plt.plot(time_axis, audio_samples)\n\n    hops_match_time_axis = np.arange(len(rms)) / 100  # 10ms gap b/w hops => 3 sec recording => 302 db/rms readings (10ms hops)\n    power = rms**2\n    power_db = librosa.power_to_db(power, ref=np.max)\n    plt.plot(hops_match_time_axis, power_db)  # power is slightly more exaggerated (deeper for breathing, silence... more of a gap vs RMS while talking)\n    amp_db = librosa.amplitude_to_db(rms, ref=np.max)\n    plt.plot(hops_match_time_axis, amp_db)\n\n    plt.xlabel(\"Time (s)\")\n    plt.ylabel(\"RMS power dB vs RMS amplitude dB\")\n    plt.title(\"Audio Waveform\")\n\n    plt.tight_layout()\n    plt.show()\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/librosa_rms.py:30-49\n    plt.figure(figsize=(10, 4))\n    plt.plot(time_axis, audio_samples)\n\n    # FYI look at detect.py module... you appear to be leaning toward hop_length smaller for better power waveform resolution\n    #  and bigger frame_length for better smoothing (IIUC)\n    #  and dropping medfilter (not sure if you used it here)\n    hops_match_time_axis = np.arange(len(rms)) / 100  # 10ms gap b/w hops => 3 sec recording => 302 db/rms readings (10ms hops)\n    # plt.plot(hops_match_time_axis, rms)  # OR show RMS\n    plt.plot(hops_match_time_axis, rms_db / 100)  # show RMS dB instead\n\n    rms.min()\n    rms.max()\n\n    rms_db.min()\n    rms_db.max()\n\n    audio_samples.min()\n    audio_samples.max()\n\n    plt.xlabel(\"Time (s)\")\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/librosa_rms.py:160-172\ndef show_rms_vs_rms_db():\n    plt.close()\n    hops_match_time_axis = np.arange(len(rms)) / 100  # 10ms gap b/w hops => 3 sec recording => 302 db/rms readings (10ms hops)\n    # plt.plot(hops_match_time_axis, rms)\n    # plt.plot(hops_match_time_axis, [math.log(r, 2) for r in rms])\n    plt.plot(hops_match_time_axis, rms_db)\n    # plt.plot(hops_match_time_axis, [math.log(r**10) + 16 for r in rms], 9)\n    plt.xlabel(\"time (s)\")\n    plt.ylabel(\"rms, rms_db\")\n    plt.title(\"audio waveform\")\n\n    plt.tight_layout()\n    plt.show()\n<|end|><|start|>user<|message|>merge the two plots into one and add right speech too\nHere is code I selected (with carefully preserved indentation) from auto_edit/new_silence/player.py:\n    @staticmethod\n    def plot_window_gap(window: \"GapWindow\") -> None:\n        left_speech = window.left_speech\n        if left_speech:\n            times = np.linspace(left_speech.start, left_speech.end, len(left_speech.rms_values))\n            plt.plot(times, left_speech.rms_values, label=f\"{left_speech.id} ({left_speech.label.value})\")\n\n        gap_segs: list[DetectedSegment] = window.gap.segments\n        gap = window.gap\n        if not gap_segs:\n            return\n        plt.figure(figsize=(10, 4))\n        for seg in gap_segs:\n            times = np.linspace(seg.start, seg.end, len(seg.rms_values))\n            plt.plot(times, seg.rms_values, label=f\"{seg.id} ({seg.label.value})\")\n        plt.xlabel(\"Time (s)\")\n        plt.ylabel(\"RMS\")\n        plt.title(\"Gap RMS Plot\")\n        plt.legend()\n        plt.grid(True)\n        plt.tight_layout()\n        plt.show()<|end|><|start|>assistant",
    "has_new_line": true,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 1859,
    "timings": {
      "cache_n": 0,
      "prompt_n": 1512,
      "prompt_ms": 289.683,
      "prompt_per_token_ms": 0.1915892857142857,
      "prompt_per_second": 5219.498555317365,
      "predicted_n": 348,
      "predicted_ms": 1582.745,
      "predicted_per_token_ms": 4.5481178160919535,
      "predicted_per_second": 219.87117318329865
    }
  }
}
