{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765261785,
  "id": "chatcmpl-Xsbw3MiauzKYDrfyzRCpNoRD1Lyblb44",
  "model": "gpt-oss:120b",
  "system_fingerprint": "b7089-38e2c1b41",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 0,
    "prompt_n": 3068,
    "prompt_ms": 438.25,
    "prompt_per_token_ms": 0.14284550195567144,
    "prompt_per_second": 7000.570450656018,
    "predicted_n": 69,
    "predicted_ms": 363.963,
    "predicted_per_token_ms": 5.274826086956522,
    "predicted_per_second": 189.5797100254696
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 2,
    "stop": true,
    "model": "gpt-oss:120b",
    "tokens_predicted": 69,
    "tokens_evaluated": 3068,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-09\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n\n\n<|end|><|start|>user<|message|>Here is context that's automatically provided, that MAY be relevant.\nrepo: ask-openai.nvim\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n## Recent yanks across all files in the project:\n.. yanked from lua/ask-openai/predictions/prefix_suffix_tests.lua:\nrag_cursor_line_before_cursor\n\n\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Lua Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Prefer EmmyLua/LuaLS style annotations\n- Always annotate when type inference would be ambiguous, or for public APIs.\n\nExamples:\n---@param names string[]\n---@param checker fun(name: string): boolean\n---@return table<string, integer>\nfunction process_names(names, checker) end\n\n---@class WindowController\n---@field window hs.axuielement\n---@field title? string\n---@field size { w: number, h: number }\nlocal WindowController = {}\n\n\n# Semantic Grep matches: 5\n\n## /Users/wesdemos/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/backends/models/fim_harmony.lua:138-158\n---@param request FimBackend\nfunction HarmonyFimPromptBuilder.fim_prompt(request)\n    -- * user message\n    local current_file_relative_path = request.inject_file_path_test_seam()\n    local file_prefix = \"\"\n    if current_file_relative_path == nil then\n        log:warn(\"current_file_name is nil\")\n        current_file_relative_path = \"\"\n        file_prefix = \"I am editing this file: \" .. current_file_relative_path .. \"\\n\\n\"\n    end\n\n    --  TODO try PSM format anyways! I think it might help with repeating the suffix?\n    --    might want to find a fine tune too that actually has training for PSM/SPM\n    --    would need to reword some instructions above (including examples)\n    local fim_user_message = file_prefix\n        .. \"Please complete \" .. qwen.FIM_MIDDLE .. \" in the following code (which has carefully preserved indentation):\\n\"\n        .. request.ps_chunk.prefix\n        .. qwen.FIM_MIDDLE\n        .. request.ps_chunk.suffix\n    return fim_user_message\nend\n\n## /Users/wesdemos/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/backends/models/tests/fim.tests.lua:15-30\n\n    it(\"get_fim_prompt\", function()\n        -- USE example:\n        --   https://github.com/QwenLM/Qwen2.5-Coder/blob/main/examples/Qwen2.5-Coder-repolevel-fim.py\n\n        local ps_chunk = PrefixSuffixChunk:new()\n        ps_chunk.prefix = \"foo\\nthe\\nprefix\"\n        ps_chunk.suffix = \"bar\\nbaz\"\n        -- TODO set lines if needed for test?\n        local request = {\n            ps_chunk = ps_chunk,\n            context = {\n                yanks = { filename = \"nvim-recent-yanks.txt\", content = \"yanks\" },\n                includes = { yanks = true },\n            },\n            inject_file_path_test_seam = \n\n## /Users/wesdemos/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/backends/models/fim_harmony.lua:145-159\n        current_file_relative_path = \"\"\n        file_prefix = \"I am editing this file: \" .. current_file_relative_path .. \"\\n\\n\"\n    end\n\n    --  TODO try PSM format anyways! I think it might help with repeating the suffix?\n    --    might want to find a fine tune too that actually has training for PSM/SPM\n    --    would need to reword some instructions above (including examples)\n    local fim_user_message = file_prefix\n        .. \"Please complete \" .. qwen.FIM_MIDDLE .. \" in the following code (which has carefully preserved indentation):\\n\"\n        .. request.ps_chunk.prefix\n        .. qwen.FIM_MIDDLE\n        .. request.ps_chunk.suffix\n    return fim_user_message\nend\n\n\n\n## /Users/wesdemos/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/backends/models/fim.lua:157-176\n---@param request FimBackend\nfunction M.bytedance_seed_coder.get_fim_prompt_file_level_only(request)\n    -- FYI file level works well for Seed-Coder\n\n    local tokens = M.bytedance_seed_coder.sentinel_tokens\n    -- * SPM\n    local file_level_prompt_only = ''\n        -- PRN show FIM file path commented out?\n        -- tokens.file_sep\n        -- .. current_file_relative_path\n        -- .. \"\\n\"\n        --\n        .. tokens.FIM_SUFFIX\n        .. request.ps_chunk.suffix\n        .. tokens.FIM_PREFIX\n        .. request.ps_chunk.prefix\n        .. tokens.FIM_MIDDLE\n\n    return file_level_prompt_only\nend\n\n## /Users/wesdemos/repos/github/g0t4/ask-openai.nvim/lua/ask-openai/predictions/prefix_suffix_tests.lua:54-77\nfunction()\n        local bufnr = buffers.new_buffer_with_lines(seven_lines)\n        local line_base1 = 7\n        local col_base0 = 5\n        vim.api.nvim_win_set_cursor(0, { line_base1, col_base0 })\n\n        local take_lines = 2\n        local ps_chunk = ps.get_prefix_suffix_chunk(2)\n\n        -- to make this consistent I probably should make line range take 3 to 7 here\n        --  like with start of doc, which takes 1 to 5\n        --   right now this takes 4 lines only when it s/b 2 on either side of cursor line\n        --   thus in this case all 4 before cursor line so 3 to 7 (5 lines)\n        assert.same({\n            prefix = \"line 4\\nline 5\\nline 6\\nline \",\n            suffix = \"7\\n\",\n            cursor_line = {\n                before_cursor = \"line \", -- cursor is on the last char of the line, so that would be the number in this case\n            },\n            few_lines_before = { \"line 4\", \"line 5\", \"line 6\" },\n            start_line_base1 = 4,\n            end_line_base1 = 7,\n        }, ps_chunk)\n    end\n<|end|><|start|>user<|message|>Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\n    M.rag_extensions = files.list_directories(dot_rag_dir)\n    log:info(\"RAG is supported for: \" .. vim.inspect(M.rag_extensions))\nend\ncheck_supported_dirs()\n\nfunction M.get_filetypes_for_workspace()\n    -- FYI vim filetypes for enabling the LSP client for RAG purposes\n    local ext_to_filetype = {\n        -- extension = filetype\n        bash = \"sh\", -- *\n        clj = \"clojure\",\n        coffee = \"coffeescript\",\n        conf = \"cfg\",\n        cs = \"csharp\",\n        h = \"c\",\n        hh = \"cpp\",\n        hpp = \"cpp\",\n        hs = \"haskell\",\n        htm = \"html\",\n        jade = \"pug\",\n        js = \"javascript\", -- *\n        julia = \"julia\",\n        kt = \"kotlin\",\n        lhs = \"lhaskell\",\n        m = \"objc\", -- others for objc?\n        mm = \"objc\",\n        md = \"markdown\", -- *\n        pl = \"perl\",\n        pm = \"perl\",\n        py = \"python\", -- *\n        rb = \"ruby\",\n        rs = \"rust\",\n        scm = \"scheme\",\n        shtml = \"html\",\n        swift = \"swift\",\n        ts = \"typescript\",\n        tsx = \"typescriptreact\",\n        vimrc = \"vim\",\n        yml = \"yaml\", -- *\n    }\n\n    return vim.iter(M.rag_extensions or {})\n        :map(function(ext) return ext_to_filetype[ext] or ext end)\n        :totable()\nend\n\nfunction M.is_rag_supported()\n    if M.rag_yaml and not M.rag_yaml.enabled then\n        -- FYI this was a rushed addition, to toggle RAG on/off in .rag.yaml...\n        --   don't be surprised if you have to fix some bugs\n        --   I didn't care to spend too much time making sure this was done \"right\"\n        return false\n    end\n    return M.is_rag_indexed_workspace == true\nend\n\nfunction M.is_rag_supported_in_current_file()\n    -- TODO add a virtual toggle so LSP failure stops requests too\n    --   can I detect non-connected LSP (w/o hugh perf hit?)\n\n    if not M.is_rag_supported() then\n        return false\n    end\n\n    local current_file_extension = vim.fn.expand(\"%:e\")\n    return vim.tbl_contains(M.rag_extensions, current_file_extension)\nend\n\n---@param str string\n---@return string\nfunction trim(str)\n    return (str:gsub(\"^%s*(.-)%s*$\", \"%1\"))\nend\n\n---@param ps_chunk PrefixSuffixChunk\n---@returns string? -- FIM query string, or nil to disable FIM Semantic Grep\nlocal function fim_concat(ps_chunk)\n    -- FYI see fim_query_notes.md for past and future ideas for Semantic Grep selection w.r.t. RAG+FIM\n\n    -- * TESTING FIM+RAG with cursor line ONLY for query\n    local query = ps_chunk.<|fim_middle|>\n\n    if trim(query) == \"\" then\n        local few_before_text = table.concat(ps_chunk.few_lines_before or {}, \"\\n\") or \"\"\n        if vim.trim(few_before_text) ~= \"\" then\n            query = few_before_text\n        else\n            log:trace(ansi.white_bold(ansi.red_bg(\"SKIPPING RAG in FIM b/c cursor line is empty (before cursor) and nothing in a few lines above either\")))\n            -- PRN allow suffix if empty prefix line? OR take a few lines around it?\n            -- PRN previous line? with a non-empty value? if so, pass all lines or a subset from ps_chunk builder (on ps_chunk)\n            return nil\n        end\n    end\n\n    log:trace(string.format(\"fim_concat: query=%q\", query))\n    return query\nend\n\n---@enum ChunkType\nlocal ChunkType = {\n    LINES = \"lines\",\n    TREESITTER = \"ts\",\n    UNCOVERED_CODE = \"uncovered\",\n}\n\n---@class LSPSemanticGrepRequest\n---@field query string\n---@field vimFiletype string\n---@field currentFileAbsolutePath string\n---@field instruct? string\n---@field languages? string\n---@field skipSameFile? boolean\n---@field topK? integer\n---@field embedTopK? integer\n_G.LSPSemanticGrepRequest = {}\n\n\n---@class LSPSemanticGrepResult\n---@field matches LSPRankedMatch[]\n---@field error? string\n_G.LSPSemanticGrepResult = {}\n\n---@class LSPRankedMatch\n---@field text string\n---@field file string\n---@field start_line_base0 integer\n---@field start_column_base0 integer\n---@field end_line_base0 integer\n---@field end_column_base0 integer|nil\n---@field type ChunkType\n---@field embed_score number\n---@field rerank_score number\n---@field embed_rank integer\n---@field rerank_rank integer\n---@field signature string\n_G.LSPRankedMatch = {}\n\n---@param user_prompt string\n---@param code_context string\n---@param callback fun(matches: LSPRankedMatch[], failed: boolean)\nfunction M.context_query_rewrites(user_prompt, code_context, callback)\n    -- FYI use user message for now as Instruct and selected code as the Query\n    local query = code_context\n    local instruct = user_prompt\n    -- TODO! pass line ranges for limiting same file skips\n    return M._context_query(query, instruct, callback)\nend\n\n---@param ps_chunk PrefixSuffixChunk\n---@param callback fun(matches: LSPRankedMatch[], failed: boolean)\n---@param skip_rag fun()\nfunction M.context_query_fim(ps_chunk, callback, skip_rag)\n    local fim_specific_instruct = \"Complete the missing portion of code (FIM) based on the surrounding context (Fill-in-the-middle)\"\n    local query = fim_concat(ps_chunk)\n    if query == nil then\n        skip_rag()\n        return\n    end\n    -- PRN pass fim.semantic_grep.all_files settings (create an options object and pass that instead of a dozen args)\n    -- PRN pass ps_chunk start/end lines to limit same file skips\n    return M._context_query(query, fim_specific_instruct, callback)<|end|><|start|>assistant",
    "has_new_line": false,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 3136,
    "timings": {
      "cache_n": 0,
      "prompt_n": 3068,
      "prompt_ms": 438.25,
      "prompt_per_token_ms": 0.14284550195567144,
      "prompt_per_second": 7000.570450656018,
      "predicted_n": 69,
      "predicted_ms": 363.963,
      "predicted_per_token_ms": 5.274826086956522,
      "predicted_per_second": 189.5797100254696
    }
  }
}
