{
  "stream": true,
  "raw": false,
  "chat_template_kwargs": {
    "reasoning_effort": "low"
  },
  "messages": [
    {
      "role": "developer",
      "content": "You are completing code from a Neovim plugin.\nAs the user types, the plugin suggests code completions based on their cursor position marked with: <|fim_middle|>\nThe surrounding code is limited to X lines above/below the cursor, so it may not be the full file. Focus on the code near <|fim_middle|>Do NOT explain your decisions. Do NOT return markdown blocks ```\nDo NOT repeat surrounding code (suffix/prefix)\nONLY return valid code at the <|fim_middle|> position\nPAY attention to existing whitespace.\nYOU ARE ONLY INSERTING CODE, DO NOT REPEAT PREFIX/SUFFIX. Think about overlap before finishing your thoughts.\n\nFor example, if you see this in a python file:\ndef adder(a, b):\n    return <|fim_middle|> + b\n\nThe correct completion is:\na\n\nNOT:\na + b\n\nand NOT:\n    return a + b\n\nMake sure to practice the code change before you return a suggestion. Take the cursor line (at least) and type it out with the new code and make sure it is valid, correct code.\n"
    },
    {
      "role": "user",
      "content": "Here is context that's automatically provided, that MAY be relevant.\nrepo: private-auto-edit-suggests\n\nGeneral project code rules:\n- Never add comments to the end of a line.\n- NEVER add TODO comments for me.\n## Recent yanks across all files in the project:\n.. yanked from auto_edit/new_silence/player.py:\ngetattr(win, \"first_min_seconds\", None)\n\n\n# General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n\n# Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n\n# Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/gap.py:64-83\n        second_argmin = second_half.argmin()\n        # rich.print(f'{first_argmin=}, {second_argmin=}')\n\n        mins_gap_hops = second_argmin - first_argmin\n        hops_per_second = analysis.sample_rate / RMS_HOP_LENGTH\n        mins_gap_seconds = mins_gap_hops / hops_per_second\n        # rich.print(f'{mins_gap_hops=}, {mins_gap_seconds=}')\n\n        # FYI I am going to use these as proxies for understanding when left speech is for sure complete (safe zone)\n        #   BTW you will need to adjust algorithms for this, especially for non-breathing intervals that are not going to behave the same\n        #   TODO DRIVE THAT WITH UNIT TESTS\n        window.left_speech_for_sure_done_seconds = (window.gap.segments[0].start + first_argmin / hops_per_second).item()\n        window.right_speech_about_to_start_seconds = (window.gap.segments[0].start + (num_half + second_argmin) / hops_per_second).item()\n\n        window.first_min = first_half[first_argmin].item()\n        window.second_min = second_half[second_argmin].item()\n\n        # search for first minimum from left side (this will be the taper of left_speech)\n        first_min_idx = 0\n        first_min = all_rms_values[0]\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/gap.py:51-120\ndef mark_safe_speech_boundaries(window: GapWindow):\n\n        all_rms_values = np.concatenate([v.rms_values for v in window.gap.segments])\n\n        num_half = int(np.floor(len(all_rms_values) / 2))\n        first_half = all_rms_values[:num_half]\n        second_half = all_rms_values[num_half:]\n\n        if first_half.size == 0 or second_half.size == 0:\n            return\n\n        # idea => each min should be w/in the first half of the silence (regradless the shape of the silence period)\n        first_argmin = first_half.argmin()\n        second_argmin = second_half.argmin()\n        # rich.print(f'{first_argmin=}, {second_argmin=}')\n\n        mins_gap_hops = second_argmin - first_argmin\n        hops_per_second = analysis.sample_rate / RMS_HOP_LENGTH\n        mins_gap_seconds = mins_gap_hops / hops_per_second\n        # rich.print(f'{mins_gap_hops=}, {mins_gap_seconds=}')\n\n        # FYI I am going to use these as proxies for understanding when left speech is for sure complete (safe zone)\n        #   BTW you will need to adjust algorithms for this, especially for non-breathing intervals that are not going to behave the same\n        #   TODO DRIVE THAT WITH UNIT TESTS\n        window.left_speech_for_sure_done_seconds = (window.gap.segments[0].start + first_argmin / hops_per_second).item()\n        window.right_speech_about_to_start_seconds = (window.gap.segments[0].start + (num_half + second_argmin) / hops_per_second).item()\n\n        window.first_min = first_half[first_argmin].item()\n        window.second_min = second_half[second_argmin].item()\n\n        # search for first minimum from left side (this will be the taper of left_speech)\n        first_min_idx = 0\n        first_min = all_rms_values[0]\n        for idx, value in enumerate(all_rms_values):\n            if value < first_min:\n                first_min = value\n                first_min_idx = idx  # track separately so I can capture when first_min is first encountered\n                continue\n            if value > first_min + 3:  # jump in 3dB == reversed course, is this sufficient?\n                break\n            # PRN find range over which local_min is encountered (first encountered, last encountered)... if it helps to round frames\n\n        last_min_idx_backwards = 0\n        last_min = all_rms_values[-1]\n        for idx, value in enumerate(np.flip(all_rms_values)):\n            if value < last_min:\n                last_min = value\n                last_min_idx_backwards = idx\n                continue\n            if value > last_min + 3:\n                break\n\n        # if first_idx != first_argmin:\n        same_first_idx = first_min_idx == first_argmin\n        same_first_value = first_half[first_argmin].item() == first_min.item()\n        rich.print(f'{same_first_value=} {same_first_idx=}      {first_min_idx=}={first_min} {first_argmin=}={first_half[first_argmin]}')\n        window.first_min_seconds = window.gap.segments[0].start + first_min_idx / hops_per_second\n\n        last_min_idx_forwards = len(all_rms_values) - 1 - last_min_idx_backwards\n        same_last_idx = last_min_idx_forwards == (num_half + second_argmin)\n        same_last_value = last_min.item() == second_half[second_argmin].item()\n        rich.print(f'{same_last_value=} {same_last_idx=}      {last_min_idx_forwards=}={last_min} {num_half + second_argmin=}={second_half[second_argmin]}')\n\n        window.last_min_seconds = window.gap.segments[-1].end - last_min_idx_backwards / hops_per_second\n\n        # _100ms = 0.1\n        # _400ms = 0.4\n        # if mins_gap_seconds > _100ms and mins_gap_seconds < _400ms:\n        #     # AND if rises up and down\n        #     #  then assume is breathing and just be careful about rounding inward... for now I don't think this is even needed though!\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detector_notebook.py:30-49\n# %% \n# * noteworthy speech endings and gaps (fodder for test cases):\n#   from minute1 video\n#\n# 45: 24:05.20 => 25:05.88 (left speech cut off early ... simple pattern of breathing (down => up => crest => down => up (start right speech))  \n#\n# 71: speech ending at 33:03.20 => wild, longish gap after this... min(first_half) doesn't work \n#\n# 85: speech ending at 37:04.22 => very short break =>  0.126s total ... interesting first_min s/b == last_min b/c gap is down and up \n#      is it possible that first_min == last_min (and short duration) ==> signal to to merge the gap into the speech segments?\n#\n# 89: speech ending at 38:05.27 => erratic... first_min approach works where as old min(first_half) doesn't\n#\n# 135: speech ending at 55:20.27.. that next gap if you do first half it's wrong... first_min works nicely \n#\n# 47: speech ending at 25:05.20 => pretty normal breathing section BUT it has a slow decay in left_speech so this is good for testing cut points with my new approach \n#\n\n# * noteworthy stellar breathing test cases (fit my pattern of double dip w/ bounce):\n#   from minute1 video too\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/gap.py:49-68\n\n\n    def mark_safe_speech_boundaries(window: GapWindow):\n\n        all_rms_values = np.concatenate([v.rms_values for v in window.gap.segments])\n\n        num_half = int(np.floor(len(all_rms_values) / 2))\n        first_half = all_rms_values[:num_half]\n        second_half = all_rms_values[num_half:]\n\n        if first_half.size == 0 or second_half.size == 0:\n            return\n\n        # idea => each min should be w/in the first half of the silence (regradless the shape of the silence period)\n        first_argmin = first_half.argmin()\n        second_argmin = second_half.argmin()\n        # rich.print(f'{first_argmin=}, {second_argmin=}')\n\n        mins_gap_hops = second_argmin - first_argmin\n        hops_per_second = analysis.sample_rate / RMS_HOP_LENGTH\n\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect.py:0-19\nfrom io import StringIO\nfrom rich.console import Console\nfrom rich.text import Text\nfrom traitlets.config.configurable import SingletonConfigurable\nfrom auto_edit.new_silence.timer import DurationPrinter\nfrom auto_edit.tests.test_files import gptoss_fim_video\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom numpy.typing import NDArray\nfrom pathlib import Path\nfrom typing import Any\nimport cv2\nimport librosa\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport rich\nimport scipy.signal as sps\nimport sounddevice as sd\n\n\n"
    },
    {
      "role": "user",
      "content": "Please complete <|fim_middle|> in the following code (which has carefully preserved indentation):\n#\n# 128 ~= 5.80ms (5.68 per video frame)\n# 256 ~= 11.61ms (2.84 per video frame)\n# 512 ~= 23.22ms (1.42 per video frame)\n#\n# FYI video FPS = 30 ==> 33.333ms per frame (at least want to sample once per frame... => hop_length=734.999265 (once per frame)\n#   but lower helps smooth out sharp changes (nearly instantaneous in waveform, i.e. when start talking)... so I will use much smaller so I can see the full \"power form\" (think waveform but for RMS dB)...\n#   b/c I use transition shapes to find bounce/breathing sections reliably (so far!)\n# PRN do a timing analysis of perf difference w/ smaller hop_length values vs bigger (closer to 512)\n#\n# REASONS I LIKE SMALLER HOP_LENGTH\n# - more points helps connect dots at extreme transitions (i.e. nearly instantaneous jumps when speech starts)\n# - more points == easier to see breathing bounce!!! and it often ends up as one segment\n#    I do need to update tests to look for bounce in the middle of a W but that's fine!\n# - fewer segments in final analysis! yes, more rms_values... but\n#    once aggregated there are fewer segments, especially gaps b/w speech...\n#    and that means fewer small segments!\n#    often very clear when breathing from a glance!!!\n#    and when not!\n#\n\nclass SegmentLabel(Enum):\n    SILENCE = \"silenc\"\n    BREATH = \"breath\"\n    SPEECH = \"speech\"\n\nlabel_color_map = {\n    SegmentLabel.SILENCE: \"blue\",\n    SegmentLabel.BREATH: \"magenta\",\n    SegmentLabel.SPEECH: \"red\",\n}\n\ndef colorize(text, style):\n    buf = StringIO()\n    console = Console(file=buf, force_terminal=True, color_system=\"truecolor\")\n    console.print(Text(text, style=style), end=\"\")\n    return buf.getvalue()\n\n@dataclass(frozen=True)\nclass DetectedSegment:\n    id: int\n    start: float\n    end: float\n    label: SegmentLabel\n    rms_values: RMSValues\n    labels: list[str] = field(default_factory=list)\n\n    @property\n    def duration(self) -> float:\n        return self.end - self.start\n\n    @property\n    def rms_summary(self) -> str:\n        rms = self.rms_values\n        min_val = float(rms.min())\n        mean_val = float(rms.mean())\n        max_val = float(rms.max())\n        # 5.1 ==> b/c one digit for - sign, two for tens/ones before decimal, one for decimal and one after decimal == 5 chars padding (notably to left pad single digit dB values so columns line up across segments when list is printed)\n        return f\"min={round(min_val, 1):5.1f} mean={round(mean_val, 1):5.1f} max={round(max_val, 1):5.1f} len={len(rms)}\"\n\n    def __repr__(self) -> str:\n        return self.__str__()\n\n    def __str__(self, no_color=False) -> str:\n\n        label = self.label.value.lower()\n        if not no_color:\n            label = colorize(self.label.value.lower(), self.plot_color())\n\n        # 4 for left padding id\n        return f\"{self.id:4} {label}: [{self.start:.3f}->{self.end:.3f}) {self.duration:.3f}s {self.rms_summary}\"\n\n    def get_plot_message(self) -> str:\n        fps = VIDEO_FPS  # hardcode for now is fine # PRN pass later\n\n        start = seconds_to_timecode(self.start, fps)\n        end = seconds_to_timecode(self.end, fps)\n\n        rms = self.rms_values\n        min_val = float(rms.min())\n        mean_val = float(rms.mean())\n        max_val = float(rms.max())\n        rms_repr = f\"min={round(min_val, 1):5.1f} mean={round(mean_val, 1):5.1f} max={round(max_val, 1):5.1f}\"\n\n        return f\"{self.id:4} \" \\\n                f\"[{start}âžœ{end}) \" \\\n                f\"{self.label.value.lower():6} {self.duration:.3f}s \" \\\n                + rms_repr\n\n    def plot_color(self) -> str:\n        if \"bounce\" in self.labels:\n            return \"yellow\"\n        return label_color_map.get(self.label, \"green\")\n\n    def dump_code_to_recreate_me(self) -> str:\n        parts = [\n            f\"id={self.id}\",\n            f\"start={self.start}\",\n            f\"end={self.end}\",\n            f\"label=SegmentLabel.{self.label.name}\",\n            f\"rms_values=np.array({self.rms_values.tolist()})\",\n            f\"labels={self.labels!r}\",\n        ]\n        return f\"DetectedSegment({', '.join(parts)})\"\n\nclass CombinedSegments(DetectedSegment):\n    # store originals for later comparison (i.e. testing/troubleshooting)\n    originals: list[DetectedSegment]\n\n@dataclass\nclass NonSpeechGap:\n    segments: list[DetectedSegment]\n\n@dataclass\nclass GapWindow:\n    left_speech: DetectedSegment | None\n    gap: NonSpeechGap\n    right_speech: DetectedSegment | None\n\n    left_speech_for_sure_done_seconds: float | None = None\n    right_speech_about_to_start_seconds: float | None = None\n    first_min: float | None = None\n    second_min: float | None = None\n    <|fim_middle|>\n\n    def all_segments(self) -> list[DetectedSegment]:\n        segments: list[DetectedSegment] = []\n        if self.left_speech:\n            segments.append(self.left_speech)\n        segments.extend(self.gap.segments)\n        if self.right_speech:\n            segments.append(self.right_speech)\n        return segments\n\n    def get_window_start(self) -> float:\n        if self.left_speech:\n            return self.left_speech.start\n        return self.gap.segments[0].start\n\n    def get_window_end(self) -> float:\n        if self.right_speech:\n            return self.right_speech.end\n        return self.gap.segments[-1].end\n\n@dataclass\nclass AudioAnalysisResult:\n    audio_samples: MonoAudioSamplesArray\n    sample_rate: int | float\n    segments: list[DetectedSegment]\n    rms_db: Float32Array\n    time_stamps: Float32Array\n    thresholds: DetectThresholds\n    merged: list[DetectedSegment] = field(default_factory=list)\n    windows: list[GapWindow] = field(default_factory=list)\n    fps: int = VIDEO_FPS\n\n    def list_by_label(self, label_type: SegmentLabel) -> None:\n        for segment in self.segments:\n            if segment.label == label_type:\n                print(segment)"
    }
  ],
  "options": [],
  "top_p": 1,
  "temperature": 1,
  "model": "gpt-oss:120b",
  "max_tokens": 4096
}
