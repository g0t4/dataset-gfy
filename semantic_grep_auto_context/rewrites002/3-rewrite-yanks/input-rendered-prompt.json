{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "delta": {}
    }
  ],
  "created": 1765583997,
  "id": "chatcmpl-7HBJKNRa6E6U7Xjj3VefsvGed7NbwbjO",
  "model": "",
  "system_fingerprint": "b7089-38e2c1b41",
  "object": "chat.completion.chunk",
  "timings": {
    "cache_n": 0,
    "prompt_n": 2901,
    "prompt_ms": 429.982,
    "prompt_per_token_ms": 0.14821854532919684,
    "prompt_per_second": 6746.79405184403,
    "predicted_n": 62,
    "predicted_ms": 269.021,
    "predicted_per_token_ms": 4.339048387096774,
    "predicted_per_second": 230.4652796621825
  },
  "__verbose": {
    "index": 0,
    "content": "",
    "tokens": [],
    "id_slot": 1,
    "stop": true,
    "model": "",
    "tokens_predicted": 62,
    "tokens_evaluated": 2901,
    "generation_settings": {
      "seed": 4294967295,
      "temperature": 1.0,
      "dynatemp_range": 0.0,
      "dynatemp_exponent": 1.0,
      "top_k": 40,
      "top_p": 1.0,
      "min_p": 0.05000000074505806,
      "top_n_sigma": -1.0,
      "xtc_probability": 0.0,
      "xtc_threshold": 0.10000000149011612,
      "typical_p": 1.0,
      "repeat_last_n": 64,
      "repeat_penalty": 1.0,
      "presence_penalty": 0.0,
      "frequency_penalty": 0.0,
      "dry_multiplier": 0.0,
      "dry_base": 1.75,
      "dry_allowed_length": 2,
      "dry_penalty_last_n": 131072,
      "dry_sequence_breakers": [
        "\n",
        ":",
        "\"",
        "*"
      ],
      "mirostat": 0,
      "mirostat_tau": 5.0,
      "mirostat_eta": 0.10000000149011612,
      "stop": [],
      "max_tokens": 4096,
      "n_predict": 4096,
      "n_keep": 0,
      "n_discard": 0,
      "ignore_eos": false,
      "stream": true,
      "logit_bias": [],
      "n_probs": 0,
      "min_keep": 0,
      "grammar": "",
      "grammar_lazy": false,
      "grammar_triggers": [],
      "preserved_tokens": [
        200003,
        200005,
        200006,
        200007,
        200008
      ],
      "chat_format": "GPT-OSS",
      "reasoning_format": "deepseek",
      "reasoning_in_content": false,
      "thinking_forced_open": false,
      "samplers": [
        "penalties",
        "dry",
        "top_n_sigma",
        "top_k",
        "typ_p",
        "top_p",
        "min_p",
        "xtc",
        "temperature"
      ],
      "speculative.n_max": 16,
      "speculative.n_min": 0,
      "speculative.p_min": 0.75,
      "timings_per_token": false,
      "post_sampling_probs": false,
      "lora": []
    },
    "prompt": "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2025-12-12\n\nReasoning: low\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.<|end|><|start|>developer<|message|># Instructions\n\nYou are an expert coder. Ground rules:\n- Follow the user's instructions. \n- DO NOT wrap answers in markdown code blocks, which means no triple backticks like ``` nor single backtick like ` .\n- Do not explain answers, just give me code. \n- Never add comments to the end of a line. \n- Never add comments.\n- Preserve indentation. \n- If rewriting code, preserve unrelated code. \n- Prefer readable code over of comments. \n\n<|end|><|start|>user<|message|>## Recent yanks across all files in the project:\n.. yanked from auto_edit/new_silence/detector_notebook.py:\nspeech_analysis\n\n.. yanked from auto_edit/new_silence/detector_notebook.py:\n    analysis = speech_analysis(what_file)\n    # hop_length=25 => 1.114s vs hop_length=256 => 608.54ms ... NBD either way\n\nwith DurationPrinter(f\"merge_close_speech_segments\"):\n    analysis.merged = merge_close_speech_segments(analysis, max_gap=0.1)\n\n.. yanked from auto_edit/new_silence/detector_notebook.py:\nwith DurationPrinter(f\"speech_analysis with {title_addon}\"):\n\n<|end|><|start|>user<|message|># General Code Preferences\n\n- When rewriting code, leave unrelated code and unrelated comments as is.\n- When an if statement has an AMBIGUOUS condition, extract a variable to meaningfully name it, for example:\n```lua\nlocal is_blank_line = line:match(\"^%s*$\")\nif is_blank_line then\n    -- ...\nend\n```\n<|end|><|start|>user<|message|># Python Code Preferences\n\n## Naming\n- Use snake_case for functions and variables.\n- Use PascalCase for classes.\n\n## Type Hints\n- Use type hints to clear up ambiguity and improve code completion.\n- prefer list[] over List[] to mimimizes imports\n- Avoid docstrings, ABSOLUTELY NO trivial comments.\n<|end|><|start|>user<|message|># Semantic Grep matches: 5\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect_tests.py:66-193\nclass TestMerging:\n\n    def test_only_speech__merges_nothing(self):\n        seg = speech_seg(0, 1)\n        merged = merge_close_speech_segments(analysis_for(seg))\n        assert merged == [seg]\n\n    def test_only_non_speech__merges_nothing(self):\n        seg = silence_seg(0, 1)\n        merged = merge_close_speech_segments(analysis_for(seg))\n        assert merged == [seg]\n\n    def test_only_one_speech_in_middle__merges_nothing(self):\n        seg1 = silence_seg(0, 0.4)\n        seg2 = speech_seg(0.4, 0.6)\n        seg3 = silence_seg(0.6, 1.0)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2, seg3]))\n        assert merged == [seg1, seg2, seg3]\n\n    def test_ends_with_speech__merges_nothing(self):\n        seg1 = silence_seg(0, 0.4)\n        seg2 = speech_seg(0.4, 0.6)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2]))\n        assert merged == [seg1, seg2]\n\n    def test_starts_with_speech__merges_nothing(self):\n        seg1 = speech_seg(0, 0.2)\n        seg2 = silence_seg(0.2, 1.0)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2]))\n        assert merged == [seg1, seg2]\n\n    def test_two_speech_back_to_back__merged_into_one(self):\n        seg1 = speech_seg(0.0, 0.5)\n        seg2 = speech_seg(0.5, 1.0)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2]))\n\n        assert len(merged) == 1\n        combined = merged[0]\n        assert isinstance(combined, CombinedSegments)\n        assert combined.start == 0.0\n        assert combined.end == 1.0\n        assert combined.label == SegmentLabel.SPEECH\n        assert np.array_equal(combined.rms_segment, [0, 1])\n\n    def test_three_speech_back_to_back__merges_into_one(self):\n        seg1 = speech_seg(0.0, 0.3)\n        seg2 = speech_seg(0.3, 0.6)\n        seg3 = speech_seg(0.6, 1.0)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2, seg3]))\n\n        assert len(merged) == 1\n        combined = merged[0]\n        assert isinstance(combined, CombinedSegments)\n        assert combined.start == 0.0\n        assert combined.end == 1.0\n        assert combined.label == SegmentLabel.SPEECH\n        assert np.array_equal(combined.rms_segment, [0, 1, 2])\n\n    def test_speech_then_multiple_silents_to_end__merges_nothing(self):\n        seg1 = speech_seg(0.0, 0.3)\n        seg2 = silence_seg(0.3, 0.5)\n        seg3 = silence_seg(0.5, 0.7)\n        seg4 = silence_seg(0.7, 1.0)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2, seg3, seg4]))\n\n        assert merged == [seg1, seg2, seg3, seg4]\n\n    def test_speech_tiny_silence_speech__merges(self):\n        seg1 = speech_seg(0.0, 0.3)\n        seg2 = silence_seg(0.3, 0.31)  # tiny silence shorter than max_gap=0.10\n        seg3 = speech_seg(0.31, 0.6)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2, seg3]))\n\n        assert len(merged) == 1\n        combined = merged[0]\n        assert isinstance(combined, CombinedSegments)\n        assert combined.start == 0.0\n        assert combined.end == 0.6\n        assert combined.label == SegmentLabel.SPEECH\n        # key part of test is that the RMS of the silence periods are copied too:\n        assert np.array_equal(combined.rms_segment, [0, 1, 2])\n\n    def test_speech_long_silence_speech__merges_nothing(self):\n        seg1 = speech_seg(0.0, 0.3)\n        seg2 = silence_seg(0.3, 0.5)  # longer than max_gap=0.10\n        seg3 = speech_seg(0.5, 0.8)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2, seg3]))\n\n        assert merged == [seg1, seg2, seg3]\n\n    def test_speech__then_multi_silences_that_are_under_max_gap_then_speech__merges(self):\n        seg1 = speech_seg(0.0, 0.3)\n        #\n        # total: 0.02 which is way under max_gap (0.1 default) => hence merges\n        seg2 = silence_seg(0.3, 0.31)  # tiny silence\n        seg3 = silence_seg(0.31, 0.32)  # tiny silence\n        #\n        seg4 = speech_seg(0.32, 0.4)\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2, seg3, seg4]))\n        assert len(merged) == 1\n        combined = merged[0]\n        assert isinstance(combined, CombinedSegments)\n        assert combined.start == 0.0\n        assert combined.end == 0.4\n        assert combined.label == SegmentLabel.SPEECH\n        # RMS should include all original segments (speech and silences)\n        assert np.array_equal(combined.rms_segment, [0, 1, 2, 3])\n\n    def test_speech__then_multi_silences_that_are_too_long_then_speech__merges_nothing(self):\n        seg1 = speech_seg(0.0, 0.3)\n        #\n        # total gap: 0.3\n        seg2 = silence_seg(0.3, 0.35)\n        seg3 = silence_seg(0.35, 0.6)\n        #\n        seg4 = speech_seg(0.6, 0.9)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2, seg3, seg4]))\n\n        assert merged == [seg1, seg2, seg3, seg4]\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect_tests.py:114-127\ndef test_three_speech_back_to_back__merges_into_one(self):\n        seg1 = speech_seg(0.0, 0.3)\n        seg2 = speech_seg(0.3, 0.6)\n        seg3 = speech_seg(0.6, 1.0)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2, seg3]))\n\n        assert len(merged) == 1\n        combined = merged[0]\n        assert isinstance(combined, CombinedSegments)\n        assert combined.start == 0.0\n        assert combined.end == 1.0\n        assert combined.label == SegmentLabel.SPEECH\n        assert np.array_equal(combined.rms_segment, [0, 1, 2])\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect_tests.py:100-112\ndef test_two_speech_back_to_back__merged_into_one(self):\n        seg1 = speech_seg(0.0, 0.5)\n        seg2 = speech_seg(0.5, 1.0)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2]))\n\n        assert len(merged) == 1\n        combined = merged[0]\n        assert isinstance(combined, CombinedSegments)\n        assert combined.start == 0.0\n        assert combined.end == 1.0\n        assert combined.label == SegmentLabel.SPEECH\n        assert np.array_equal(combined.rms_segment, [0, 1])\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect_tests.py:139-153\ndef test_speech_tiny_silence_speech__merges(self):\n        seg1 = speech_seg(0.0, 0.3)\n        seg2 = silence_seg(0.3, 0.31)  # tiny silence shorter than max_gap=0.10\n        seg3 = speech_seg(0.31, 0.6)\n\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2, seg3]))\n\n        assert len(merged) == 1\n        combined = merged[0]\n        assert isinstance(combined, CombinedSegments)\n        assert combined.start == 0.0\n        assert combined.end == 0.6\n        assert combined.label == SegmentLabel.SPEECH\n        # key part of test is that the RMS of the silence periods are copied too:\n        assert np.array_equal(combined.rms_segment, [0, 1, 2])\n\n## ~/repos/github/g0t4/private-auto-edit-suggests/auto_edit/new_silence/detect_tests.py:164-180\ndef test_speech__then_multi_silences_that_are_under_max_gap_then_speech__merges(self):\n        seg1 = speech_seg(0.0, 0.3)\n        #\n        # total: 0.02 which is way under max_gap (0.1 default) => hence merges\n        seg2 = silence_seg(0.3, 0.31)  # tiny silence\n        seg3 = silence_seg(0.31, 0.32)  # tiny silence\n        #\n        seg4 = speech_seg(0.32, 0.4)\n        merged = merge_close_speech_segments(analysis_for([seg1, seg2, seg3, seg4]))\n        assert len(merged) == 1\n        combined = merged[0]\n        assert isinstance(combined, CombinedSegments)\n        assert combined.start == 0.0\n        assert combined.end == 0.4\n        assert combined.label == SegmentLabel.SPEECH\n        # RMS should include all original segments (speech and silences)\n        assert np.array_equal(combined.rms_segment, [0, 1, 2, 3])\n<|end|><|start|>user<|message|>bring bck the duration printer timer\nHere is code I selected (with carefully preserved indentation) from auto_edit/new_silence/detect.py:\n    analysis = speech_analysis(path)\n    analysis.merged = merge_close_speech_segments(analysis)<|end|><|start|>assistant",
    "has_new_line": true,
    "truncated": false,
    "stop_type": "eos",
    "stopping_word": "",
    "tokens_cached": 2962,
    "timings": {
      "cache_n": 0,
      "prompt_n": 2901,
      "prompt_ms": 429.982,
      "prompt_per_token_ms": 0.14821854532919684,
      "prompt_per_second": 6746.79405184403,
      "predicted_n": 62,
      "predicted_ms": 269.021,
      "predicted_per_token_ms": 4.339048387096774,
      "predicted_per_second": 230.4652796621825
    }
  }
}
